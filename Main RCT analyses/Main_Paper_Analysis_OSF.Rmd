---
title: 'Main Paper Analysis'
author: "Chelsie Parker at the BCC"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyr)
library(table1)
library(car) # type III anova
library(ggplot2)
library(gridExtra)
library(Metrics) # for rmse and other metrics
library(kableExtra) #beautiful kable tables
library(gtsummary) # for model summary tables 
library(emmeans)
library(moments)
library(tidyverse)
library(modelsummary)

# Analysis on imputation data
library(mice)
library(plyr) # MI model pooling
library(papeR) # MI pooled tables
library(moments) # residual normality + skewness

# ANCOVA
library(tidyverse)
library(ggpubr)
library(rstatix)
library(broom)

# LMM Sensitivity
library(lme4)
library(lmerTest)

# save tables to excel for formatting
library(openxlsx)
library(expss)

library(BayesFactor)



###############
## Load Data ##
###############

raw_data <- read.csv(here::here("Main RCT analyses/analytic_raw_ns_data.csv"))
# 
# imputed_long_1 <- read.csv("../Data/11 MI Runs - February/DQ 1 MI/imputed_39_long_by_Trt_DQ1_2024-02-19.csv")
# imputed_long_2 <- read.csv("../Data/11 MI Runs - February/DQ 2 MI/imputed_41_long_by_Trt_DQ2_2024-02-20.csv") 
# imputed_long_3 <- read.csv("../Data/11 MI Runs - February/WL MI/imputed_38_long_by_Trt_WL_2024-02-20.csv") 
# imputed_long_4 <- read.csv("../Data/May MI Runs/Behavioral 1 MI/imputed_35_long_by_Trt_B1_2024-05-26.csv") 
# imputed_long_5 <- read.csv("../Data/11 MI Runs - February/Behavioral 2 MI/imputed_57_long_by_Trt_B2_2024-02-20.csv") 
# imputed_long_6 <- read.csv("../Data/11 MI Runs - February/Behavioral 3 MI/imputed_187_long_by_Trt_B3_2024-02-20.csv") 



#######################
## Unblind Treatment ##
#######################

raw_data$Treatment[raw_data$Treatment == 1] = "Weight Watchers"
raw_data$Treatment[raw_data$Treatment == 2] = "Control"
raw_data$Treatment <- factor(raw_data$Treatment,
                                  levels = c("Weight Watchers",
                                             "Control"),
                                  ordered = TRUE)

########################
## Homemade Functions ##
########################

# To get more significant figures in table 1:
for.cont.variables <- function(x) {
    with(stats.default(x), 
         c("",
           
          "Mean (SD)" = sprintf("%s (%s)",
                                round_pad(MEAN, 2),
                                round_pad(SD, 2)))
    )
}

for.cont.variables1 <- function(x) {
    with(stats.default(x), 
         c("",
           
          "Mean (SD)" = sprintf("%s (%s)",
                                round_pad(MEAN, 1),
                                round_pad(SD, 1)))
    )
}


# Set reference levels:

imputed_references <- function(imputed.analysis.data){
  imputed.analysis.data$Treatment <- relevel(factor(imputed.analysis.data$Treatment),
                                             ref = "1") # Treatment
  
  imputed.analysis.data$Sex_bcf <- relevel(factor(imputed.analysis.data$Sex_bcf),
                                           ref = "Male")
  
  imputed.analysis.data$Race2_bcf <- as.character(imputed.analysis.data$Race2_bcf)
  imputed.analysis.data$Race2_bcf[imputed.analysis.data$Race2_bcf == "Native Hawaiian or other Pacific Islander, Multiracial, Other or Prefer not to say"] = "Other"
  imputed.analysis.data$Race2_bcf[imputed.analysis.data$Race2_bcf == "Black or African-American"] = "Black"
  imputed.analysis.data$Race2_bcf <- relevel(factor(imputed.analysis.data$Race2_bcf),
                                             ref = "White")
  
  
  imputed.analysis.data$Education_grouped <- relevel(factor(imputed.analysis.data$Education_grouped),
                                                     ref = ">=Masters")
  
  imputed.analysis.data$Ethnicity_bcf <- relevel(factor(imputed.analysis.data$Ethnicity_bcf),
                                                 ref =  "No")
  return(imputed.analysis.data)
}

# Function to remove leading 0 in p-values
leading_zeros = function(X1)gsub("0\\.","\\.", X1)

# remove negative sign in instances of -0.0
change_negative_zero <- function(df) {
  df[] <- lapply(df, function(x) {
    if (is.character(x)) {
      # List of all the replacements
      replacements <- c(
        "-0.0" = "0.0",
        "-0.0 (0.0)" = "0.0 (0.0)",
        "-0.0 (0.1)" = "0.0 (0.1)",
        "-0.0 (0.2)" = "0.0 (0.2)",
        "-0.0 (0.3)" = "0.0 (0.3)",
        "(-0.2, -0.0)" = "(-0.2, 0.0)",
        "(-0.8, -0.0)" = "(-0.8, 0.0)",
        "(-0.0, 0.6)" = "(0.0, 0.6)",
        "(-0.7, -0.0)" = "(-0.7, 0.0)"
      )
      
      # Apply replacements
      for (pattern in names(replacements)) {
        x <- gsub(pattern, replacements[pattern], x)
      }
    }
    return(x)
  })
  return(df)
}

```

With significant helpful contributions from Beate Henschel and Stephanie Dickinson.


# Measures

```{r}
# Save outcomes and their labels at top for tables, plots, and analysis

outcome_pairs = as.data.frame(outcomes <- rbind(
  # Dietary quality
  # Change in ASA24 HEI Diet Quality Scores (Total and Subscores)  1:14
  c("HEI2015_TOTAL_SCORE_change",  "HEI Total Score"),
  c("HEI2015C1_TOTALVEG_change", "Total Vegetable"),
  c("HEI2015C2_GREEN_AND_BEAN_change",  "Greens and Beans"),
  c("HEI2015C3_TOTALFRUIT_change","Total Fruit"),
  c("HEI2015C4_WHOLEFRUIT_change", "Whole Fruit"),
  c("HEI2015C5_WHOLEGRAIN_change", "Whole Grains"),
  c("HEI2015C6_TOTALDAIRY_change", "Total Dairy"),
  c("HEI2015C7_TOTPROT_change", "Total Protein Foods"),
  c("HEI2015C8_SEAPLANT_PROT_change", "Seafood and Plant Proteins"),
  c("HEI2015C9_FATTYACID_change", "Fatty Acids"),
  c("HEI2015C10_SODIUM_change", "Sodium"),
  c("HEI2015C11_REFINEDGRAIN_change", "Refined Grains"),
  c("HEI2015C12_SFAT_change","Saturated Fats"),
  c("HEI2015C13_ADDSUG_change","Added Sugars"),
  # Other Dietary Quality Measures 15
  c("amed_change", "AMED Score"),
  # Change in Average Micro and Macro Nutrients Between Endline and Baseline 16:24
  c("KCAL_ave_change", "Average Total Energy"),
  c("TFAT_ave_change", "Average Total Fat"),
  c("CARB_ave_change", "Average Total Carbohydrates"),
  c("SODI_ave_change", "Average Sodium"),
  c("SFAT_ave_change", "Average Saturated Fats"),
  c("SUGR_ave_change", "Average Total Sugars"),
  c("ADD_SUGARS_ave_change", "Average Added Sugars"),
  c("CHOLE_ave_change", "Average Total Cholesterol"),
  c("FIBE_ave_change", "Average Fiber"),
  # Weight loss
  # Weight Loss Measures 25:30
  c("weightkg_change", "Body Weight (kg)"),
  c("BMI_change", "BMI"),
  c("changekg_percent_body_wt", "Percent Body Weight Change"),
  c("achieve_3_percent_wl", "Achieved 3% Weight Loss"),
  c("achieve_5_percent_wl", "Achieved 5% Weight Loss"),
  c("achieve_10_percent_wl","Achieved 10% Weight Loss"),
  # Behavioral
  # Change in Physical Activity 31:34
  c("METS_change","Total Physical Activity MET"),
  c("sendentary_change", "Sedentary"),
  c("moderate_change", "Moderate"),
  c("vigorous_change", "Vigorous"),
  # Change in Self-Reported Sleep 35:37
  c("sleep_quality_change", "Sleep Quality"),
  c("sleep_amount_change",  "Usual Sleep Amount"),
  c("wake_episodes_change","Wake Episodes"),
  # Change in Habit Strength (for each behavior assessed, then grouped healthy and unhealthy) 38:52
  c("SRBAI_change", "SRBAI Habit Strength"),
  c("Avg1_change", "Considering Portion Sizes"),
  c("Avg2_change", "Tracking Food Consumption"),
  c("Avg3_change", "Consider WW Points"),
  c("Avg4_change", "Frequency of Eating Vegetables"),
  c("Avg5_change", "Frequency of Weighing Self"),
  c("Avg6_change", "Frequency of Physical Activity"),
  c("Avg7_change", "Talking Kindly to Self After Setback"),
  c("Avg8_change", "Arranging Healthy Foods for Easy Access"),
  c("Avg9_change", "Frequency of Fried Foods"),
  c("Avg10_change", "Frequency of Sweets"),
  c("Avg11_change", "Frequency of Sugary Beverages"),
  c("Avg12_change", "Snacking When Not Hungry"),
  c("UnhSRBAI_change", "Unhealthy Grouped"),
  c("healSRBAI_change","Healthy Grouped")
))

colnames(outcome_pairs) = c("outcomes", "outcome_labels")
outcomes <- outcome_pairs$outcomes

# indices:
# 1:15, 16:24, 25:30, 31:34, 35:37, 38:52
```

Note: Change scores are calculated as endline minus baseline measurements.

## Outcomes

### Dietary Quality

* **Change in Diet Quality** (difference between baseline and 6-mo HEI-2015 total and sub scores): Diet quality is calculated with the Healthy Eating Index-2015 (HEI-2015). The HEI-2015, is a valid and reliable composite measure that assesses overall diet quality and compliance with the DGA-2015. This tool can help assess diet quality from U.S. populations and racial and ethnic subgroups. The HEI-2015 scores 13 key dietary components to obtain a total score ranging from 0-100. Higher scores reflect greater dietary quality/greater adherence to the Dietary Guidelines (USDA, HEI-2015). Diet quality scores will be calculated by combining across 3 unannounced 24h dietary recalls collected using the Automated Self-Administered 24-Hour Dietary Assessment Tool (ASA-2413). HEI-2015 total scores will be calculated using the “Simple HEI Scoring Algorithm – Per Person” method using the instructions and SAS macro (hei2015.score.macro.sas) (https://epi.grants.cancer.gov/hei/sas-code.html).


* **Change in Alternative Mediterranean Diet Score**: The alternative Mediterranean diet score (AMED) score was modified and adapted to the Mediterranean diet scale designed by Trichopoulou et al. The AMED score is made up of 9 components: seven "healthy" components: a. fruits, b. vegetables, c. fish, d. legumes, e. nuts, f. whole grains, and g. ratio of monounsaturated fat to saturated fat, and two additional components: h. red and processed meat, and i. alcohol consumption as described by Dr. Zhilei Shan et al. Each component, except alcohol, will be categorized into quintiles (Q). Positive scores to the seven healthy components will be assigned as follows: (Q1=1, Q2=2, Q3=3, Q4=4, Q5=5). Reverse scores to red and processed meat will be assigned as follows: (Q5=1, Q4=2, Q3=3, Q2=4, Q1=5). For alcohol consumption (g/d), points will be assigned as follows: 5-15=5, 0-5 or 15-25=4, 0 or 25-30=3, 30-35=2, and ≥35=1 for females and 10-30=5, 0-10 or 30-40=4, 0 or 40-45=3, 45-50=2, and ≥50=1 for males. The analysis will use the total AMED composite score, ranging from 9 to 45, with a higher score representing closer resemblance to a healthy Mediterranean diet. Data collected at baseline and 6-months; outcome is change in scores.

* **Dietary Intake**: Macro- and micro-nutrient intakes measured with the validated Automated Self-Administered 24-hour (ASA24®) Dietary Assessment Tool (averaged across the number of recalls) including total energy, total fat, total carbohydrates, sodium, saturated fats, total and added sugars, total cholesterol, and fiber.

### Weight Loss

* **Body weight change (kg)**

* **Change in BMI**, where BMI = $\text{weight} / \text{height_bl}^2 \times 703$

* **Percent (%) Body Weight Loss**: Weight (lb); % body weight loss defined as baseline to 6-month weight change divided by baseline weight multiplied by 100.

* **Achievement of 3, 5, and 10% Weight Loss**: Participants that achieve at least 3/5/10% body weight loss at 6 months or not.


### Behavioral

* **Change in Self-Reported Physical Activity Over the Past 7 Days**: Measured using the Global Physical Activity Questionnaire (GPAQ) which collects information on physical activity participation in the following domains: activity at work, travel to-and from- places, recreational activities, and sedentary behavior. From these inputs, the MET minutes per week spent in moderate activity, vigorous activity, moderate and vigorous activity, and sedentary behavior can be calculated. Data collected at baseline and 6-months; outcome is change in scores.


* **Self-Reported Sleep Quality**: Measured with the sleep assessment module from the validated Automated Self-Administered 24-hour (ASA24®) Dietary Assessment Tool.

    * Sleep Quality is measured on a scale from 1-5 where 1 means very good sleep quality and 5 is very poor sleep quality.
    
    * Usual Sleep Amount is measured on a scale of 1-3 where 1 means much more sleep than usual, 2 is usual amount of sleep, and 3 means much less sleep than usual.
    
    * Wake Episodes measured how many times a participant woke up, not counting final time they woke up.
    
    
* **Change in Habit Strength**: Measured using the Self-Reported Behavioral Automaticity Index (SRBAI), which captures habitual patterns of behavior. Each behavior of interest is assessed by 4 items rated on a Likert scale 1-strongly disagree to 7-strongly agree. Scores are calculated for each behavior by taking an average of the response, creating a possible score range between 1 and 7. Higher scores indicate greater habit strength for the behavior being measured. Data collected at baseline and 6-months; outcome is change in scores.


Note: Change scores are calculated as endline minus baseline measurements.


## Covariates

* Age, yrs

* Self-reported Race (American Indian/Alaska Native, Asian,  Black or African-American, Multiracial, White, Other Not Listed, Prefer not to say, White)

* Self-identified as Hispanic, Latinx, Latine, or Spanish (Yes, No)

* Sex assigned at birth (Male or Female)

* Education (highest level achieved): Some high school, High school degree/GED/equivalent, Trade school or specialty training, Some college, Associates degree, Bachelor's degree, Some graduate school, Master's degree, Professional degree or doctorate.


## Additional Variables

* Self-reported Gender (Female, Male, Trans/Non-Binary/Third Gender)

* Self-reported total household income (before taxes): <\$10,000, \$10,000-\$19,999, \$20,000-\$29,999, \$30,000-\$39,999, \$40,000-\$49,999, \$50,000-\$59,999, \$60,000-\$69,999, \$70,000-\$79,999, \$80,000-\$89,999, \$90,000-\$99,999, \$100,000-\$149,999, >\$150,000    

* Weight and BMI at baseline, endline, and change scores as well as total calories at baseline from DietID were considered for inclusion in imputation to help inform the data, but were not used in any analysis models.

* Food insecurity in the past 12 month, measured only at endline.



# Descriptive Statistics 

Descriptive statistics will include means and standard deviations for each continuous variable, as well as counts and proportions for the categorical variables. All Descriptive Statistics in this section are based on raw/observed (unimputed) data.

## Table 1 - Baseline

Sociodemographic characteristics of study participants at baseline

```{r}
# save data for table separately for tables without throwing off models:
data_tab <- raw_data

# Order factor levels and change labels:
data_tab$Income_grouped <- factor(data_tab$Income_grouped,
                                  levels = c("<$60k",
                                             ">=$60k to <$100K", ">=$100k"),
                                  labels = c(" $59,999 or under", 
                                             "Between $60,000 and $99,999",
                                             "$100,000 or above"),
                                  ordered = TRUE)

data_tab$Education_grouped <- factor(data_tab$Education_grouped,
                                     levels = c("<=Associates",
                                                "Bach/Some Grad", ">=Masters"),
                                     labels = c("Associate degree or below",
                                                "Bachelor’s degree and some graduate school",
                                                "Masters or above"),
                                     ordered = TRUE)

data_tab$Race2_bcf <- factor(data_tab$Race2_bcf,
                             levels = c("Asian", "Black or African-American",
                                        "White",
                                        "Native Hawaiian or other Pacific Islander, Multiracial, Other or Prefer not to say"),
                             ordered = TRUE)

data_tab$foodinsec <- factor(data_tab$foodinsec, 
                             levels = c(0, 1),
                             labels = c("No", "Yes")) 

# Add nice labels for table:
table1::label(data_tab$Age_years) <- "Age, years"
table1::label(data_tab$Sex_bcf) <- "Sex assigned at birth"
table1::label(data_tab$Gender_grouped) <- "Self-identified gender"
table1::label(data_tab$Race2_bcf) <- "Self-identified race"
table1::label(data_tab$Ethnicity_bcf) <- "Self-identified as Hispanic, Latinx, Latine, or Spanish"
table1::label(data_tab$Income_grouped) <- "Household Income, USD"
table1::label(data_tab$Education_grouped) <- "Highest level of education achieved"
table1::label(data_tab$BMI_bl) <- "BMI"
table1::label(data_tab$HEI2015_TOTAL_SCORE_bl) <- "Diet quality, HEI-2015"
table1::label(data_tab$amed_bl) <- "aMED"
table1::label(data_tab$foodinsec) <- "Food insecurity"


# generate table 1:
# table1(~ Age_years + Sex_bcf + Gender_grouped + Race2_bcf + Ethnicity_bcf + Income_grouped + Education_grouped + BMI_bl + HEI2015_TOTAL_SCORE_bl + amed_bl + foodinsec | Treatment, data = data_tab,
#        render.continuous = for.cont.variables)
table1(~ Age_years + Sex_bcf + Race2_bcf + Ethnicity_bcf + Income_grouped + Education_grouped + BMI_bl + HEI2015_TOTAL_SCORE_bl + foodinsec | Treatment, data = data_tab,
       render.continuous = for.cont.variables)
```

Diet Quality, HEI-2015 was collected from three ASA24 dietary recalls.

Food insecurity was captured at endline because it was not asked at baseline. BMI and diet quality are baseline measurements. 


Note: When variables are included as covariates in the analysis, they're grouped as has been done in Table 1. Age, race, ethnicity, sex assigned at birth, and education are included as covariates in the models as well as a baseline measure of the outcome being analyzed and treatment as the exposure variable.

Significance tests for baseline differences will not be conducted per CONSORT guidelines (Schulz, 2010).
 
 <br>



**Race x Hispanic Status**

Let's take a closer look at the breakdown of race and ethnicity overall:

```{r}
kable(xtabs(~ Race_bcf + Ethnicity_bcf, raw_data)) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 1, "Ethnicity" = 2)) %>%
  pack_rows(index = c("Race" = 7)) 
```


Simply divide these by the total sample size (n=376) to get percents. 

## Table 2 - Outcomes

Outcomes tables for Descriptive Statistics by Outcome 

Note: Change scores are calculated as endline minus baseline measurements.

```{r}
# Reformat data with timepoint variable for bl, el, and ch (3 rows per applicable outcome)
outcomes_tab_data <- data_tab %>% dplyr::select(!c(Income_grouped, Race2_bcf,
                                                   Age_years, Sex_bcf,
                                                   Ethnicity_bcf, Education_grouped,
                                                   Income_grouped, foodinsec, 
                                                   changekg_percent_body_wt,
                                                   achieve_3_percent_wl, 
                                                   achieve_5_percent_wl, 
                                                   achieve_10_percent_wl, Treatment))
colnames(outcomes_tab_data) = gsub("_change", "_ch", colnames(outcomes_tab_data))

outcomes_tab_data_long<-pivot_longer(outcomes_tab_data, cols=-1, names_pattern = "(.*)_(..)$", names_to = c("Outcome", "Timepoint")) 

outcomes_tab_data_wide <-pivot_wider(outcomes_tab_data_long, id_cols = c(WINS.ID, Timepoint), names_from = Outcome, values_from = value)

# add outcomes only at endline after:
add_on <- data_tab %>% dplyr::select(WINS.ID, foodinsec, changekg_percent_body_wt, 
                              achieve_3_percent_wl, achieve_5_percent_wl, achieve_10_percent_wl) %>% mutate(Timepoint = "el")

outcomes_tab_data_wide = merge(outcomes_tab_data_wide, add_on, by = c("WINS.ID", "Timepoint"), all = TRUE)
outcomes_tab_data_wide = merge(outcomes_tab_data_wide, raw_data[,c("WINS.ID", "Treatment")], 
                          by = c("WINS.ID"), all = TRUE)

# change to nice labels and order for appearance in table
outcomes_tab_data_wide$Timepoint[outcomes_tab_data_wide$Timepoint == "bl"] = "Baseline"
outcomes_tab_data_wide$Timepoint[outcomes_tab_data_wide$Timepoint == "el"] = "Endline"
outcomes_tab_data_wide$Timepoint[outcomes_tab_data_wide$Timepoint == "ch"] = "Change"
outcomes_tab_data_wide$Timepoint <- factor(outcomes_tab_data_wide$Timepoint, 
                                           levels = c("Baseline", "Endline", "Change"))
```


### Dietary quality

```{r}

# Change in HEI Diet Quality Scores

# Nice labels for table
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015_TOTAL_SCORE"] = "HEI Total Score"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C1_TOTALVEG"] = "Total Vegetable"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C2_GREEN_AND_BEAN"] = "Greens and Beans"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C4_WHOLEFRUIT"] = "Whole Fruit"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C5_WHOLEGRAIN"] = "Whole Grains"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C6_TOTALDAIRY"] = "Total Dairy"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C7_TOTPROT"] = "Total Protein Foods"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C8_SEAPLANT_PROT"] = "Seafood and Plant Proteins"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C9_FATTYACID"] = "Fatty Acids"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C10_SODIUM"] = "Sodium"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C11_REFINEDGRAIN"] = "Refined Grains"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C12_SFAT"] = "Saturated Fats"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "HEI2015C13_ADDSUG"] = "Added Sugars"

datasummary(
  (`HEI Total Score` + `Total Vegetable` + `Greens and Beans` +`Whole Fruit`+`Whole Grains`+`Total Dairy`+
  `Total Protein Foods`+`Seafood and Plant Proteins`+`Fatty Acids`+`Sodium`+`Refined Grains`+`Saturated Fats`+`Added Sugars`
   )*Timepoint ~ Treatment * (N + Mean + SD),
  data = outcomes_tab_data_wide, title = "Change in ASA24 HEI Diet Quality Scores (Total and Subscores)"
)
```


The first nine subcomponents (Total Vegetable to Fatty Acids) are adequacy components where higher component scores indicate higher consumption (higher ratio for fatty acids). The last four components (Sodium to Added Sugars) are moderation components where higher component scores indicate lower consumption.


```{r}
# additional diet quality measure

# Nice labels for table
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "amed"] = "AMED Score"

datasummary(
  (`AMED Score`
   )*Timepoint ~ Treatment * (N + Mean + SD),
  data = outcomes_tab_data_wide, title = "Other Dietary Quality Measures"
)
```


```{r}
# Change ASA24 Micro- and Macro Nutrients

# Nice labels for table
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "KCAL_ave"] = "Average Total Energy"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "TFAT_ave"] = "Average Total Fat"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "CARB_ave"] = "Average Total Carbohydrates"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "SODI_ave"] = "Average Sodium"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "SFAT_ave"] = "Average Saturated Fats"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "SUGR_ave"] = "Average Total Sugars"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "ADD_SUGARS_ave"] = "Average Added Sugars"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "CHOLE_ave"] = "Average Total Cholesterol"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "FIBE_ave"] = "Average Fiber"

datasummary(
  (`Average Total Energy`+`Average Total Fat`+`Average Total Carbohydrates` +
     `Average Sodium` + `Average Saturated Fats` + `Average Total Sugars` + 
    `Average Added Sugars` +  `Average Total Cholesterol` + `Average Fiber` 
  )*Timepoint ~ Treatment * (N + Mean + SD),
  data = outcomes_tab_data_wide,        
  title = "Change in Average Micro and Macro Nutrients Between Endline and Baseline", 
  note = "These measurements were averaged across the ASA24 recalls at endline and baseline, and then the difference was taken (endline - baseline)."
)
```
  


### Weight loss 


```{r}
# Percent body weight change

# Nice labels for table
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "weightkg"] = "Body Weight (kg)"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "weight"] = "Body Weight (lb)"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "BMI"] = "BMI"

datasummary(
  (`Body Weight (kg)` + `Body Weight (lb)` + `BMI`
   )*Timepoint ~ Treatment * (N + Mean + SD),
  data = outcomes_tab_data_wide,
  title = "Weight Loss Measures"
)
```


```{r}
# Measures only at endline
outcomes_tab_data_wide_el <- subset(outcomes_tab_data_wide, Timepoint == "Endline")
outcomes_tab_data_wide_el$Timepoint <- as.character(outcomes_tab_data_wide_el$Timepoint)

# Nice labels for table
colnames(outcomes_tab_data_wide_el)[colnames(outcomes_tab_data_wide_el) == "achieve_3_percent_wl"] = "Achieved 3% Weight Loss"
colnames(outcomes_tab_data_wide_el)[colnames(outcomes_tab_data_wide_el) == "achieve_5_percent_wl"] = "Achieved 5% Weight Loss"
colnames(outcomes_tab_data_wide_el)[colnames(outcomes_tab_data_wide_el) == "achieve_10_percent_wl"] = "Achieved 10% Weight Loss"
colnames(outcomes_tab_data_wide_el)[colnames(outcomes_tab_data_wide_el) == "changekg_percent_body_wt"] = "Change in Body Weight (%)"

# make binary 0/1 factors
outcomes_tab_data_wide_el$`Achieved 3% Weight Loss` <- as.character(outcomes_tab_data_wide_el$`Achieved 3% Weight Loss`)
outcomes_tab_data_wide_el$`Achieved 5% Weight Loss` <- as.character(outcomes_tab_data_wide_el$`Achieved 5% Weight Loss`)
outcomes_tab_data_wide_el$`Achieved 10% Weight Loss` <- as.character(outcomes_tab_data_wide_el$`Achieved 10% Weight Loss`)

outcomes_tab_data_wide_el$`Achieved 10% Weight Loss`[outcomes_tab_data_wide_el$`Achieved 10% Weight Loss` == "0"] = "No"
outcomes_tab_data_wide_el$`Achieved 10% Weight Loss`[outcomes_tab_data_wide_el$`Achieved 10% Weight Loss` == "1"] = "Yes"
outcomes_tab_data_wide_el$`Achieved 5% Weight Loss`[outcomes_tab_data_wide_el$`Achieved 5% Weight Loss` == "0"] = "No"
outcomes_tab_data_wide_el$`Achieved 5% Weight Loss`[outcomes_tab_data_wide_el$`Achieved 5% Weight Loss` == "1"] = "Yes"
outcomes_tab_data_wide_el$`Achieved 3% Weight Loss`[outcomes_tab_data_wide_el$`Achieved 3% Weight Loss` == "0"] = "No"
outcomes_tab_data_wide_el$`Achieved 3% Weight Loss`[outcomes_tab_data_wide_el$`Achieved 3% Weight Loss` == "1"] = "Yes"

table1(~ `Change in Body Weight (%)` + `Achieved 3% Weight Loss`+`Achieved 5% Weight Loss` + `Achieved 10% Weight Loss` | Treatment, data = outcomes_tab_data_wide_el, caption = "Captured at Endline Only", overall = FALSE, render.continuous = for.cont.variables)
```


### Behavioral 

```{r}
# Change in Physical Activity (Sedentary, Moderate and Vigorous) 
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "sendentary"] = "Sedentary"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "moderate"] = "Moderate"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "vigorous"] = "Vigorous"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "METS"] = "Total Physical Activity MET"

datasummary(
  (`Total Physical Activity MET`+`Sedentary`+`Moderate`+`Vigorous`
   )*Timepoint ~ Treatment * (N + Mean + SD),
  data = outcomes_tab_data_wide, title = "Change in Physical Activity"
)


# Self-reported sleep quality
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "sleep_quality"] = "Sleep Quality"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "sleep_amount"] = "Usual Sleep Amount"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "wake_episodes"] = "Wake Episodes"

datasummary(
  (`Sleep Quality`+`Usual Sleep Amount`+`Wake Episodes`
   )*Timepoint ~ Treatment * (N + Mean + SD),
  data = outcomes_tab_data_wide, title = "Change in Self-Reported Sleep"
)
```

For sleep quality, lower numbers are better where 1 is very good sleep quality and 5 is very poor sleep quality so higher number of change in sleep quality is worse. Recall for sleep amount 1 is more than usual, 2 is usual, and 3 is much less sleep than usual. 

```{r}
# Change in habit strength
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "SRBAI"] = "SRBAI Habit Strength"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg1"] = "Considering Portion Sizes"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg2"] = "Tracking Food Consumption"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg3"] = "Consider WW Points"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg4"] = "Frequency of Eating Vegetables"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg5"] = "Frequency of Weighing Self"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg6"] = "Frequency of Physical Activity"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg7"] = "Talking Kindly to Self After Setback"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg8"] = "Arranging Healthy Foods for Easy Access"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg9"] = "Frequency of Fried Foods"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg10"] = "Frequency of Sweets"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg11"] = "Frequency of Sugary Beverages"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "Avg12"] =  "Snacking When Not Hungry"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "UnhSRBAI"] = "Unhealthy Grouped"
colnames(outcomes_tab_data_wide)[colnames(outcomes_tab_data_wide) == "healSRBAI"] = "Healthy Grouped"

datasummary(
  (`SRBAI Habit Strength` + `Considering Portion Sizes` + `Tracking Food Consumption`+`Consider WW Points`+
     `Frequency of Eating Vegetables`+`Frequency of Weighing Self`+`Frequency of Physical Activity`+
     `Talking Kindly to Self After Setback`+`Arranging Healthy Foods for Easy Access`+`Frequency of Fried Foods`+
     `Frequency of Sweets`+`Frequency of Sugary Beverages`+ `Snacking When Not Hungry`+`Unhealthy Grouped`+`Healthy Grouped`
   )*Timepoint ~ Treatment * (N + Mean + SD),
  data = outcomes_tab_data_wide, title = "Change in Habit Strength (for each behavior assessed, then grouped healthy and unhealthy)"
)

```


## Missingness

### Completeness by Demographics

We explored the completion rate of the study by demographic subgroups.

```{r}
# completers and non completers by demographics
completers_df <- raw_data %>% 
  dplyr::select(
    WINS.ID, 
    # demographics from model
    Sex_bcf, Age_years, Race2_bcf, Ethnicity_bcf, Education_grouped, BMI_bl, Treatment,
    # additional variables requested by team
    weightkg_bl, HEI2015_TOTAL_SCORE_bl,
    # variables to determine completers
    HEI2015_TOTAL_SCORE_el, weightkg_el
  ) %>%
  dplyr:::mutate(
    ASA24_completers = 
      case_when(is.na(HEI2015_TOTAL_SCORE_el) ~ "No", 
                !is.na(HEI2015_TOTAL_SCORE_el) ~ "Yes"),
    Qualtrics_completers = 
      case_when(is.na(weightkg_el) ~ "No", 
                !is.na(weightkg_el) ~ "Yes")
  )

# Nice labels for table
colnames(completers_df)[colnames(completers_df) == "ASA24_completers"] = "ASA24 Completers"
colnames(completers_df)[colnames(completers_df) == "Qualtrics_completers"] = "Qualtrics Completers"

colnames(completers_df)[colnames(completers_df) == "Sex_bcf"] = "Sex assigned at birth"
colnames(completers_df)[colnames(completers_df) == "Age_years"] = "Age, years"
colnames(completers_df)[colnames(completers_df) == "Race2_bcf"] = "Self-identified race"
colnames(completers_df)[colnames(completers_df) == "Ethnicity_bcf"] = "Self-identified as Hispanic, Latinx, Latine, or Spanish"
colnames(completers_df)[colnames(completers_df) == "Education_grouped"] = "Highest level of education achieved"
colnames(completers_df)[colnames(completers_df) == "BMI_bl"] = "BMI at baseline"
colnames(completers_df)[colnames(completers_df) == "weightkg_bl"] = "Body weight at baseline (kg)"
colnames(completers_df)[colnames(completers_df) == "HEI2015_TOTAL_SCORE_bl"] = "HEI-2015 total score at baseline"


ASA24_col <- completers_df %>% dplyr::select(`Sex assigned at birth`,
                                      `Age, years`,
                                      `Self-identified race`,
                                      `Self-identified as Hispanic, Latinx, Latine, or Spanish`,
                                      `Highest level of education achieved`,
                                      `BMI at baseline`,
                                      `Treatment`,
                                      `Body weight at baseline (kg)`,
                                      `HEI-2015 total score at baseline`,
                                      `ASA24 Completers`) %>% 
  tbl_summary(by = `ASA24 Completers`,
              statistic = list(all_continuous() ~ "{mean} [{sd}]", 
                               all_categorical() ~ "{n} ({p}%)"), 
              percent = "row") 

Qualtrics_col <- completers_df %>% dplyr::select(`Sex assigned at birth`,
                                          `Age, years`,
                                          `Self-identified race`,
                                          `Self-identified as Hispanic, Latinx, Latine, or Spanish`,
                                          `Highest level of education achieved`,
                                          `BMI at baseline`,
                                          `Treatment`,
                                          `Body weight at baseline (kg)`,
                                          `HEI-2015 total score at baseline`,
                                          `Qualtrics Completers`) %>% 
  tbl_summary(by = `Qualtrics Completers`,
              statistic = list(all_continuous() ~ "{mean} [{sd}]", 
                               all_categorical() ~ "{n} ({p}%)"), 
              percent = "row")

tbl_merge(
    list(ASA24_col, Qualtrics_col),
    tab_spanner = c("**ASA-24 Completers**", "**Qualtrics Completers**")
  )
```


ASA24 completion is determined by the HEI Total Score at endline variable and Qualtrics completion is determined by the body weight (kg) variable at endline.

# Main Models

Our primary analysis is ANCOVA on change-scores from baseline to 6-months, using Multiply Imputed (MI) data to include all participants randomized (ITT) even where lost to follow-up. Covariates are described below.

## Primary Analysis

### Imputation

Prior to analysis, all outcomes were grouped in 6 batches of similar type to run multiple imputation (MI) on separately, stratified by treatment (Austin 2021). All outcome variables (change scores) in each batch and their respective baseline measures were included in each imputation data set as well as model covariates (e.g. demographics). Additional auxiliary variables were considered to help inform the missing data imputations in each batch (Allison 2009). Candidate auxiliary variables included all baseline, endline, and outcomes (e.g. change scores) across the full dataset as well as a few additional “proxy” variables (e.g. income). Auxiliary variables were included in an imputation data set when two conditions were met: (1) their correlation with the outcomes in that imputation data set were at least |cor| > 0.4 and (2) including those auxiliary variables provided additional observations where the outcomes of interest contained missing values (Allison 2009, Hardt et al 2012, Madley-Dowd et al, 2023). For example, if change scores were missing due to drop out on an outcome variable of interest but baseline data on another variable with complete data were correlated >0.4 (e.g. HEI total score and ADD_SUGARS_ave_bl), this will add precision to the imputation.

The 6 imputation batches/runs and the variables they included are listed below:


1. Dietary Quality Group 1:
    
    * 16 Outcomes: Change in ASA24 HEI diet quality scores (total and subscores), Diet ID total score, as well as aMED score. 
        
    * Covariates: baseline outcome measures, participant’s biological sex at birth, age, race/ethnicity, and education.
        
    * Auxiliary variables: ADD_SUGARS_ave_bl
        
        
2. Dietary Quality Group 2:
    
    * 9 Outcomes: Change in ASA24 average micro and macro nutrients
        
    * Covariates: baseline outcome measures, participant’s biological sex at birth, age, race/ethnicity, and education.
        
    * Auxiliary variables: HEI2015C13_ADDSUG_bl
        
3. Weight Loss:
    
    * 6 Outcomes: Change in body weight (kg), BMI, percent body weight, as well as three percent body weight achievement outcomes.
        
    * Covariates: baseline weight (kg), participant’s biological sex at birth, age, race/ethnicity, and education.
        
    * Auxiliary variables: Weightlbs_dietid_change, BMI_dietid_change, BMI_el


4. Behavioral Group 1:
    
    * 4 Outcomes: Change in physical activity.
        
    * Covariates: baseline outcome measures, participant’s biological sex at birth, age, race/ethnicity, and education.


5. Behavioral Group 2:
    
    * 3 Outcomes: Change in self-reported sleep.
        
    * Covariates: baseline outcome measures, participant’s biological sex at birth, age, race/ethnicity, and education.
        

6. Behavioral Group 3:
    
    * 15 Outcomes: Change in habit strength (for each behavior assessed, then grouped healthy and unhealthy). 
        
    * Covariates: baseline outcome measures, participant’s biological sex at birth, age, race/ethnicity, and education.


Multiple imputation was performed in R using the `mice` package (van Buuren and Groothuis-Oudshoorn 2011) where the number of imputations was determined according to the `howManyImputations` package (von Hippel 2020). Imputations were run with the `mice()` function with 10 iterations each, using the predictive mean matching (PMM) method. 

The line of R code that implements the imputation is:

`imputed <- mice(data.imputation, maxit = 10, m = max.runs, predictorMatrix = predM, method = "pmm", print = TRUE)`

where `max.runs` is the largest number of iterations recommended across all the outcomes of interest in that imputation run.


### Statistical Modeling

For primary outcome of HEI-2015 score:
  
  * Analysis of covariance (ANCOVA) will be used to test baseline to 6-month changes in HEI-2015 total scores for Diet Quality between the WW group and control. Covariates will be included for baseline HEI-2015 total score, participant’s biological sex at birth, age, race/ethnicity, and education.

For secondary outcomes:

  * For percent weight loss, ANCOVA will be used to test the WW group vs control. Covariates will be included for participant’s biological sex at birth, age, race/ethnicity, education, and baseline weight.

* Achievement of 3/5/10 % weight loss is only observed at the 6-month follow-up and is a binary variable. Logistic regression will be used, and covariates will be included for participant’s biological sex at birth, age, race/ethnicity, education, and baseline weight.

* The remaining secondary outcomes are measured at baseline and the 6-month post-intervention as continuous scores. ANCOVA will be used to test the baseline to 6-month changes in scores between WW and control groups. Covariates will be included for baseline outcome measures, participant’s biological sex at birth, age, race/ethnicity, and education.

$$
Outcome = Baseline + Sex + Age + Race + Ethnicity + Education + Treatment 
$$


After analyses were performed for each of the `r length(outcome_pairs$outcomes)` outcomes across 6 imputed data sets, results were pooled across all imputations according to Rubin's rules using the `pool()` function provided in the `mice` package in R.

**Cohen's d** unadjusted and adjusted effect sizes are also calculated. Cohen's d "unadjusted" is a standard measure of d = (Mean 1 - Mean 2) / (pooled SD) $= \text{(Mean 1 - Mean 2)} / \sqrt{\frac{ ( \text{n}_1 - 1) s_1^2  \ + \ ( \text{n}_2 - 1) s_2^2  }{ \text{n}_1 + \text{n}_2 -2 }}$, where here the mean and SD are calculated on the outcome of interest for each treatment group, and the d values are averaged across all imputations. Cohen's d "adjusted" is based on the model output adjusted for covariates, and is calculated using the `eff_size` function in the R package `emmeans` (Lenth 2023).

**Note: Change scores are calculated as endline minus baseline measurements.**



```{r, eval = FALSE}
# declare baseline/reference levels for imputed data sets
imputed_long_1 <- imputed_references(imputed_long_1)
imputed_long_2 <- imputed_references(imputed_long_2)
imputed_long_3 <- imputed_references(imputed_long_3)
imputed_long_4 <- imputed_references(imputed_long_4)
imputed_long_5 <- imputed_references(imputed_long_5)
imputed_long_6 <- imputed_references(imputed_long_6)


# make output shell table to save results for each outcome in the analysis loop
cols <- c("Outcome", "Outcome_label", "Mean1", "SE1", "Mean2", "SE2", "Mean_Diff", 
          "Mean_Diff_LB", "Mean_Diff_UB",
          "SE_Diff", "Estimate", "SE", "t", "df", "p_value", "Mean_Skewness", "Min_Skewness", 
          "Max_Skewness", "Mean_Kurtosis","Min_Kurtosis",  "Max_Kurtosis", "Levene_Pvalue", 
          "Min_Levene","Max_Levene", "Variance_Residual_Ratio", "Variance_Residual_Ratio_Min", 
          "Variance_Residual_Ratio_Max", "Variance_Outcome_Ratio", "Variance_Outcome_Ratio_Min",
          "Variance_Outcome_Ratio_max", "Number of Participants", "Cohens_d_unadjusted", "Cohens_d_adjusted")
output = matrix(nrow = length(outcomes), ncol = length(cols))
colnames(output) = cols

# In order to save OR CI, let's separate ancova and logistic model output:
cols <- c("Outcome", "Outcome_label", "Mean1", "SE1", "Mean2", "SE2", "Mean_Diff",
          "Mean_Diff_LB", "Mean_Diff_UB",
          "SE_Diff", "Estimate", "SE", "t", "df", "p_value", "Mean_Skewness", "Min_Skewness", 
          "Max_Skewness", "Mean_Kurtosis","Min_Kurtosis",  "Max_Kurtosis", "Levene_Pvalue", 
          "Min_Levene","Max_Levene", "Variance_Residual_Ratio", "Variance_Residual_Ratio_Min", 
          "Variance_Residual_Ratio_Max", "Variance_Outcome_Ratio", "Variance_Outcome_Ratio_Min",
          "Variance_Outcome_Ratio_max", "Number of Participants", "Cohens_d_unadjusted", "Cohens_d_adjusted")
output.ancova = matrix(nrow = length(outcomes)-3, ncol = length(cols))
colnames(output.ancova) = cols
ancova.outcome_pairs = subset(outcome_pairs, outcomes %in% setdiff(outcome_pairs$outcomes,  c("achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl")))

logistic_cols <- c("Outcome", "Outcome_label", "Prob1", "SE1", "Prob2", "SE2", "OR",
                   "OR_LCL", "OR_UCL", "OR_SE",
                   "Estimate", "SE", "z", "df", "p_value", "Mean_Skewness", "Min_Skewness", 
                   "Max_Skewness", "Mean_Kurtosis","Min_Kurtosis",  "Max_Kurtosis", "Levene_Pvalue", 
                   "Min_Levene","Max_Levene", "Variance_Residual_Ratio", "Variance_Residual_Ratio_Min", 
                   "Variance_Residual_Ratio_Max", "Variance_Outcome_Ratio", "Variance_Outcome_Ratio_Min",
                   "Variance_Outcome_Ratio_max", "Number of Participants", "Cohens_d_unadjusted", "Cohens_d_adjusted")
output.logistic = matrix(nrow = 3, ncol = length(logistic_cols))
colnames(output.logistic) =  logistic_cols
logistic.outcome_pairs = subset(outcome_pairs, outcomes %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl"))
# originally this was done to save OR CI for the logistic and not ANCOVAs
# but reviewers later asked for Mean diff CIs as well, so could have just done 
# one output with same number of columns.

##############
## Modeling ##
##############

# models
# "achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl", "weight_change"
# get weight_bl as baseline measurement

# Primary will be ITT with multiple imputation
# Formulas could be printed for verification purposes, but it's long.

# save all residuals:
residual_list_dietqual1 <- data.frame()
residual_list_dietqual2 <- data.frame()
residual_list_weightloss <- data.frame()
residual_list_behavioral1 <- data.frame()
residual_list_behavioral2 <- data.frame()
residual_list_behavioral3 <- data.frame()
# ^ used for sensitivity

for (out in outcomes){
  
  # establish which of the imputed data sets contains the outcome of interest:
  if(out %in% colnames(imputed_long_1)){
    imputed.analysis.data = imputed_long_1
  } else if(out %in% colnames(imputed_long_2)){
    imputed.analysis.data = imputed_long_2
  } else if(out %in% colnames(imputed_long_3)){
    imputed.analysis.data = imputed_long_3
  } else if(out %in% colnames(imputed_long_4)){
    imputed.analysis.data = imputed_long_4
  } else if(out %in% colnames(imputed_long_5)){
    imputed.analysis.data = imputed_long_5
  } else if(out %in% colnames(imputed_long_6)){
    imputed.analysis.data = imputed_long_6
  } 
  
  # setup model formula:
  if (out %in%  c("changekg_percent_body_wt", "achieve_3_percent_wl", "achieve_5_percent_wl", 
                  "achieve_10_percent_wl" # weight loss
  )){ # these outcomes dont match the _change, _bl structure
    formula = paste0(" ~ weightkg_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment")
  } else{formula = paste0("~ ", gsub("_change", "_bl", out), # everything else
                          " + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment")} 
  
  # setup model:
  if (out %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", 
                 "achieve_10_percent_wl")){
    # logistic for binary outcomes
    primary.model <- plyr::dlply(imputed.analysis.data, ".imp", function(df)
      glm(as.formula(paste(out, formula)), data = df, family = "binomial"))
    
  } else{
    # ANCOVA for continuous outcomes
    primary.model <- plyr::dlply(imputed.analysis.data, ".imp", function(df)
      lm(as.formula(paste(out, formula)), data = df))
    
  }
  
  # Difference between groups:
  emm.model <- as.mira(primary.model)
  # this command is used so that the emmeans packages recognizes that emm.model is a list of imputed models.
  # this is necessary so that the results are pooled using rubin's rules (https://github.com/rvlenth/emmeans/issues/80)
  
  # emmeans is different for logistic vs lm: 
  if (out %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", 
                 "achieve_10_percent_wl")){
    # logistic
    emm <- emmeans::emmeans(emm.model, "Treatment", type = "response")  # prob, SE, df, asymp.LCL asymp.UCL
    
    # pairs or pairwise
    emm.pairs = pairs(emmeans(emm.model, "Treatment", type = "response")) # T1 / T2,  OR SE df null z p 
    # pairs(emmeans(emm.model, "Treatment"), reverse = TRUE) # T2 - T1
    
    # to get OR CI:
    emm.pairs.CI = confint( pairs(emmeans(emm.model, "Treatment", type = "response")))
    
  } else{
    # ANCOVA
    emm <- emmeans::emmeans(emm.model, "Treatment") # estimate, SE, df, z, p
    
    # pairs or pairwise
    emm.pairs = pairs(emmeans(emm.model, "Treatment")) # T1 - T2 estiamte SD df z p
    # pairs(emmeans(emm.model, "Treatment"), reverse = TRUE) # T2 - T1
    
    # to get OR CI:
    emm.pairs.CI = confint( pairs(emmeans(emm.model, "Treatment")))
  }
  
  
  ## Diagnostics:
  ####################
  skewness.mean <- mean(moments::skewness(sapply(primary.model, rstandard)))
  # calculate skewness
  skewness.max <- max( abs( moments::skewness(sapply(primary.model, rstandard)) ) ) 
  skewness.min <- min(moments::skewness(sapply(primary.model, rstandard)))
  
  # save the residuals from the imputed models back onto the data set
  # by adding a new column for the standardized residuals from each model
  imputed.data.resids <- cbind(imputed.analysis.data,
                               data.frame(residuals = unlist(llply(primary.model, rstandard), use.names = FALSE)))
  # factor treatment to group by later
  imputed.data.resids$Treatment = factor(imputed.data.resids$Treatment)

  # have to save as several data frames because too large for one
  if(out %in% colnames(imputed_long_1)){
    residual_list_dietqual1 <- rbind(residual_list_dietqual1, 
                                     cbind(imputed.data.resids, 
                                           outcome = out)) 
  }
  if(out %in% colnames(imputed_long_2)){
    residual_list_dietqual2 <- rbind(residual_list_dietqual2, 
                                     cbind(imputed.data.resids, 
                                           outcome = out)) 
  }
  if(out %in% colnames(imputed_long_3)){
    residual_list_weightloss <- rbind(residual_list_weightloss, 
                                      cbind(imputed.data.resids, 
                                            outcome = out)) 
  }
  if(out %in% colnames(imputed_long_4)){
    residual_list_behavioral1 <- rbind(residual_list_behavioral1, 
                                       cbind(imputed.data.resids, 
                                             outcome = out)) 
  }
  if(out %in% colnames(imputed_long_5)){
    residual_list_behavioral2 <- rbind(residual_list_behavioral2, 
                                       cbind(imputed.data.resids, 
                                             outcome = out)) 
  }
  if(out %in% colnames(imputed_long_6)){
    residual_list_behavioral3 <- rbind(residual_list_behavioral3, 
                                       cbind(imputed.data.resids, 
                                             outcome = out)) 
  }
  
  # run the levene's test on each dataset individually, then extract just the p-value
  levene <- dlply(imputed.data.resids, ".imp", function(df)
    car::leveneTest(residuals ~ Treatment, data = df)$`Pr(>F)`[1])
  # mean, min, max
  levene.pval <- mean(unlist(levene))
  levene.min <- min(unlist(levene))
  levene.max <- max(unlist(levene))
  
  # calculate the ratio of residual variance
  # first calculate the variance of residuals by group, by imputation.
  imputed.data.resids <- imputed.data.resids %>% group_by(.imp, Treatment) %>% 
    dplyr::summarise(variance.resids = var(residuals), .groups = "keep")
  # then group by just imputation to compare the two variances
  imputed.data.resids <- imputed.data.resids %>%
    group_by(.imp) %>% 
    dplyr::summarise(ratio.var.resid = 
                       variance.resids[Treatment == rownames(table(imputed.analysis.data$Treatment))[1]]/
                       variance.resids[Treatment == rownames(table(imputed.analysis.data$Treatment))[2]])
  # mean, min, max
  variance.residual.ratio.mean <- mean(imputed.data.resids$ratio.var.resid)
  variance.residual.ratio.min <- min(imputed.data.resids$ratio.var.resid)
  variance.residual.ratio.max <- max(imputed.data.resids$ratio.var.resid)
  # and above to take the mean across all imputation sets
  
  # calculate kurtosis mean, max, min
  kurtosis.mean <- mean(moments::kurtosis(sapply(primary.model, rstandard)))
  kurtosis.max <- max(moments::kurtosis(sapply(primary.model, rstandard)))
  kurtosis.min <- min(moments::kurtosis(sapply(primary.model, rstandard)))
  
  # calculate the ratio of outcome variance
  # first calculate the variance of outcome by group, by imputation
  variance.outcome.ratios <- imputed.analysis.data %>% group_by(.imp, Treatment) %>% 
    dplyr::summarise(variance.outcome = var(.data[[out]]), .groups = "keep")
  # then group by just imputation to compare the two variances
  variance.outcome.ratios <- variance.outcome.ratios %>% group_by(.imp) %>% 
    dplyr::summarise(variance.outcome.ratio = 
                       variance.outcome[Treatment == rownames(table(imputed.analysis.data$Treatment))[1]]/
                       variance.outcome[Treatment == rownames(table(imputed.analysis.data$Treatment))[2]])
  # mean, min, max
  variance.outcome.ratio.mean <- mean(variance.outcome.ratios$variance.outcome.ratio)
  variance.outcome.ratio.min <- min(variance.outcome.ratios$variance.outcome.ratio)
  variance.outcome.ratio.max <- max(variance.outcome.ratios$variance.outcome.ratio)
  
  
  # Report measure of effect size, Cohen's d 
  # on imputed for each imputed data set, then average across for all outcomes
  
  # Cohen’s d is calculated from means and SD for differences between groups, 
  # where d=(Mean1-Mean2)/pooled_SD
  
  # Calculate effect size components by imputation and treatment (for non-binary):
  # first calculate components by imputation and treatment
  effect_size <- imputed.analysis.data %>% group_by(.imp, Treatment) %>% 
    dplyr::summarise(Mean = mean(.data[[out]]),
                     SD = stats:::sd(.data[[out]]),
                     n = length(.data[[out]]),
                     .groups = "keep")
  
  # then calculate effect size by imputation (no longer grouping by treatment)
  effect_size2 <- effect_size %>% group_by(.imp) %>%
    dplyr::summarise(cohensd = (Mean[Treatment == 1] - Mean[Treatment == 2]) / 
                       sqrt( ((n[Treatment == 1] - 1) * SD[Treatment == 1]^2 +
                                (n[Treatment == 2] - 1) * SD[Treatment == 2]^2) / 
                               (n[Treatment == 1] + n[Treatment == 2] - 2)
                       ),
                     .groups = "keep")
  
  
  # Calculate cohens d from model, adjusting for covariates:
  effect_size2$cohensd2 <- NA
  # emmeans is different for logistic vs lm: 
  if (out %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", 
                 "achieve_10_percent_wl")){
    
    # for logistic the effect size is the odds ratio
    
    # logistic
    # emm <- emmeans::emmeans(emm.model, "Treatment", type = "response")  # prob, SE, df, asymp.LCL asymp.UCL
    
    # pairs or pairwise
    # emm.pairs = pairs(emmeans(emm.model, "Treatment", type = "response")) # T1 / T2,  OR SE df null z p 
    # pairs(emmeans(emm.model, "Treatment"), reverse = TRUE) # T2 - T1
    
    effect_size2$cohensd2  = data.frame(emm.pairs)$odds.ratio
    
  } else{
    
    for (iter in 1:max(imputed.analysis.data$.imp)){
      # ANCOVA
      emm_iter <- emmeans::emmeans(primary.model[[iter]], "Treatment") # estimate, SE, df, z, p
      
      # pairs or pairwise
      emm.pairs_iter = pairs(emmeans(primary.model[[iter]], "Treatment")) # T1 - T2 estiamte SD df z p
      
      contrast = data.frame(emm.pairs_iter)
      effect_size2[iter, "cohensd2"] <- data.frame(eff_size(emm_iter, 
                                                            sigma = sigma(primary.model[[iter]]), 
                                                            edf = contrast[, "df"]))$effect.size
    }
  }
  
  n_participants <- length(rstandard(primary.model[[1]]))
  
  
  # Save differently for different models:
  if (out %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", 
                 "achieve_10_percent_wl")){
    # logistic
    #emm <- emmeans::emmeans(emm.model, "Treatment", type = "response")  # prob, SE, df, asymp.LCL asymp.UCL
    
    # pairs or pairwise
    #emm.pairs = pairs(emmeans(emm.model, "Treatment", type = "response")) # T1 / T2,  OR SE df null z p 
    
    output[which(outcomes == out),] =
      c(out, outcome_pairs$outcome_labels[which(outcome_pairs$outcomes == out)],
        summary(emm)$prob[1], summary(emm)$SE[1], # prob and SE X
        summary(emm)$prob[2], summary(emm)$SE[2], # prob and SE Y
        # difference in groups treatment groups:
        c(summary(emm.pairs)$odds.ratio, emm.pairs.CI$lower.CL, emm.pairs.CI$upper.CL, summary(emm.pairs)$SE),
        unlist(summary(pool(primary.model))[which(summary(pool(primary.model))$term == "Treatment2"),2:6]),
        skewness.mean, skewness.min, skewness.max, 
        kurtosis.mean, kurtosis.min, kurtosis.max, 
        levene.pval, levene.min, levene.max, 
        variance.residual.ratio.mean, variance.residual.ratio.min, variance.residual.ratio.max,
        variance.outcome.ratio.mean, variance.outcome.ratio.min, variance.outcome.ratio.max,
        n_participants,
        mean(effect_size2$cohensd), mean(effect_size2$cohensd2) # cohens d
      )
    
    output.logistic[which(logistic.outcome_pairs$outcomes == out),] =
      c(out, logistic.outcome_pairs$outcome_labels[which(logistic.outcome_pairs$outcomes == out)],
        summary(emm)$prob[1], summary(emm)$SE[1], # prob and SE X
        summary(emm)$prob[2], summary(emm)$SE[2], # prob and SE Y
        # difference in groups treatment groups:
        c(summary(emm.pairs)$odds.ratio, emm.pairs.CI$lower.CL, emm.pairs.CI$upper.CL, summary(emm.pairs)$SE),
        unlist(summary(pool(primary.model))[which(summary(pool(primary.model))$term == "Treatment2"),2:6]),
        skewness.mean, skewness.min, skewness.max, 
        kurtosis.mean, kurtosis.min, kurtosis.max, 
        levene.pval, levene.min, levene.max, 
        variance.residual.ratio.mean, variance.residual.ratio.min, variance.residual.ratio.max,
        variance.outcome.ratio.mean, variance.outcome.ratio.min, variance.outcome.ratio.max,
        n_participants,
        mean(effect_size2$cohensd), mean(effect_size2$cohensd2) # cohens d
      )
      
  } else{
    # ANCOVA
    #emm <- emmeans::emmeans(emm.model, "Treatment") # estimate, SE, df, z, p
    
    # pairs or pairwise
    #emm.pairs = pairs(emmeans(emm.model, "Treatment")) # T1 - T2 estiamte SD df z p
    
    output[which(outcomes == out),] =
      c(out, outcome_pairs$outcome_labels[which(outcome_pairs$outcomes == out)],
        summary(emm)$emmean[1], summary(emm)$SE[1], # mean and SE X
        summary(emm)$emmean[2], summary(emm)$SE[2], # mean and SE Y
        # difference in groups treatment groups:
        c(summary(emm.pairs)$estimate,  emm.pairs.CI$lower.CL, emm.pairs.CI$upper.CL, summary(emm.pairs)$SE),
        unlist(summary(pool(primary.model))[which(summary(pool(primary.model))$term == "Treatment2"),2:6]),
        skewness.mean, skewness.min, skewness.max, 
        kurtosis.mean, kurtosis.min, kurtosis.max, 
        levene.pval, levene.min, levene.max, 
        variance.residual.ratio.mean, variance.residual.ratio.min, variance.residual.ratio.max,
        variance.outcome.ratio.mean, variance.outcome.ratio.min, variance.outcome.ratio.max,
        n_participants,
        mean(effect_size2$cohensd), mean(effect_size2$cohensd2) # cohens d
      )
    output.ancova[which(ancova.outcome_pairs$outcomes == out),] =
      c(out, ancova.outcome_pairs$outcome_labels[which(ancova.outcome_pairs$outcomes == out)],
        summary(emm)$emmean[1], summary(emm)$SE[1], # mean and SE X
        summary(emm)$emmean[2], summary(emm)$SE[2], # mean and SE Y
        # difference in groups treatment groups:
        c(summary(emm.pairs)$estimate,  emm.pairs.CI$lower.CL, emm.pairs.CI$upper.CL, summary(emm.pairs)$SE),
        unlist(summary(pool(primary.model))[which(summary(pool(primary.model))$term == "Treatment2"),2:6]),
        skewness.mean, skewness.min, skewness.max, 
        kurtosis.mean, kurtosis.min, kurtosis.max, 
        levene.pval, levene.min, levene.max, 
        variance.residual.ratio.mean, variance.residual.ratio.min, variance.residual.ratio.max,
        variance.outcome.ratio.mean, variance.outcome.ratio.min, variance.outcome.ratio.max,
        n_participants,
        mean(effect_size2$cohensd), mean(effect_size2$cohensd2) # cohens d
      )
    
  }
  
  # Optionl returns while loop running:
  #print(paste(out, formula))
  print(paste0(out, " outcome ", which(outcomes == out), " of ", length(outcomes),"."))
}

# Combined model results
output = as.data.frame(output)
output.ancova = as.data.frame(output.ancova)
output.logistic = as.data.frame(output.logistic)


# Save residuals and output table:
save(residual_list_dietqual1, residual_list_dietqual2,
     residual_list_weightloss, 
     residual_list_behavioral1, residual_list_behavioral2, residual_list_behavioral3, 
     output,output.ancova, output.logistic,
     file = paste0("WINS_Main_Analysis_primary_", Sys.Date(), ".RData"))

```


```{r}
# load in results from chunk above:
load("WINS_Main_Analysis_primary_2025-01-28.RData")


output = as.data.frame(output)
output.logistic = as.data.frame(output.logistic)
output.ancova = as.data.frame(output.ancova)

# save for wilcox comparison
primary_results <- output
output.ancova.raw <- output.ancova
output.logistic.raw <- output.logistic

# Format columns:
output.ancova[,3:ncol(output.ancova)] = apply(output.ancova[,3:ncol(output.ancova)], 2, as.numeric)

output.logistic[,3:ncol(output.logistic)] = apply(output.logistic[,3:ncol(output.logistic)], 2, as.numeric)


# format p-values:
output.ancova <- output.ancova %>% 
  mutate(
    p_value = case_when(.data[["p_value"]] < 0.001 ~ sub(" ", "", format.pval(.data[["p_value"]], eps = 0.001, digits = 3, nsmall=3)),
                        TRUE ~ formatC(.data[["p_value"]], digits = 3, format = "f")),
    Levene_Pvalue = case_when(.data[["Levene_Pvalue"]] < 0.001 ~ sub(" ", "", format.pval(.data[["Levene_Pvalue"]], eps = 0.001, digits = 3, nsmall=3)),
                              TRUE ~ formatC(.data[["Levene_Pvalue"]], digits = 3, format = "f")),
    Min_Levene = case_when(.data[["Min_Levene"]] < 0.001 ~ sub(" ", "", format.pval(.data[["Min_Levene"]], eps = 0.001, digits = 3, nsmall=3)),
                           TRUE ~ formatC(.data[["Min_Levene"]], digits = 3, format = "f")),
    Max_Levene = case_when(.data[["Max_Levene"]] < 0.001 ~ sub(" ", "", format.pval(.data[["Max_Levene"]], eps = 0.001, digits = 3, nsmall=3)),
                           TRUE ~ formatC(.data[["Max_Levene"]], digits = 3, format = "f"))
    
  )
output.logistic <- output.logistic %>% 
  mutate(
    p_value = case_when(.data[["p_value"]] < 0.001 ~ sub(" ", "", format.pval(.data[["p_value"]], eps = 0.001, digits = 3, nsmall=3)),
                        TRUE ~ formatC(.data[["p_value"]], digits = 3, format = "f")),
    Levene_Pvalue = case_when(.data[["Levene_Pvalue"]] < 0.001 ~ sub(" ", "", format.pval(.data[["Levene_Pvalue"]], eps = 0.001, digits = 3, nsmall=3)),
                              TRUE ~ formatC(.data[["Levene_Pvalue"]], digits = 3, format = "f")),
    Min_Levene = case_when(.data[["Min_Levene"]] < 0.001 ~ sub(" ", "", format.pval(.data[["Min_Levene"]], eps = 0.001, digits = 3, nsmall=3)),
                           TRUE ~ formatC(.data[["Min_Levene"]], digits = 3, format = "f")),
    Max_Levene = case_when(.data[["Max_Levene"]] < 0.001 ~ sub(" ", "", format.pval(.data[["Max_Levene"]], eps = 0.001, digits = 3, nsmall=3)),
                           TRUE ~ formatC(.data[["Max_Levene"]], digits = 3, format = "f"))
    
  )

# round non-pvalues to 2 decimal places
p_values = which(colnames(output.ancova) %in% c("p_value", "Levene_Pvalue",
                             "Min_Levene", "Max_Levene"))
non_pvals <- setdiff(3:ncol(output.ancova), p_values)
output.ancova[,non_pvals] = apply(output.ancova[,non_pvals], 2, function(x) sprintf("%.2f", x))
  #round(output.ancova[,non_pvals], digits = 2)

# binary outcomes:
p_values = which(colnames(output.logistic) %in% c("p_value", "Levene_Pvalue",
                                      "Min_Levene", "Max_Levene"))
non_pvals <- setdiff(3:ncol(output.logistic), p_values)
output.logistic[,non_pvals] = apply(output.logistic[,non_pvals], 2, function(x) sprintf("%.2f", x))

rownames(output.ancova) = NULL
rownames(output.logistic) = NULL

# to keep outcome pairs indices, combine CI:
temp = outcome_pairs %>% dplyr::rename(Outcome = outcomes) %>% 
  dplyr::rename(Outcome_label = outcome_labels)

output.ancova <- merge(temp, output.ancova, by = c("Outcome", "Outcome_label"), sort = FALSE) #all = TRUE,
output.ancova <- output.ancova %>% mutate(
  Mean_Diff_CI = paste0("(", Mean_Diff_LB, ", ", Mean_Diff_UB, ")")
)  %>%
  select(-Mean_Diff_LB, -Mean_Diff_UB) %>%
  select(
    Outcome, Outcome_label, Mean1, SE1, Mean2, SE2, Mean_Diff, 
    Mean_Diff_CI, SE_Diff, Estimate, SE, t, df, p_value, 
    Mean_Skewness, Min_Skewness, Max_Skewness, Mean_Kurtosis, Min_Kurtosis, 
    Max_Kurtosis, Levene_Pvalue, Min_Levene, Max_Levene, 
    Variance_Residual_Ratio, Variance_Residual_Ratio_Min, 
    Variance_Residual_Ratio_Max, Variance_Outcome_Ratio, 
    Variance_Outcome_Ratio_Min, Variance_Outcome_Ratio_max, 
    `Number of Participants`, Cohens_d_unadjusted, Cohens_d_adjusted
  )

```

### Dietary quality

```{r}
kable(output.ancova[1:14,-c(10, 11, 15:(ncol(output.ancova)-2))],
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"),
      caption = "Change in ASA24 HEI Diet Quality Scores (Total and Subscores)") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))
```


```{r}
temp <- output.ancova[15,-c(10, 11, 15:(ncol(output.ancova)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), 
      caption = "Other Dietary Quality Measures") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))
```

```{r}
temp <- output.ancova[16:24,-c(10, 11, 15:(ncol(output.ancova)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), 
      caption = "Change in Average Micro and Macro Nutrients Between Endline and Baseline") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))
```

These measurements were averaged across the ASA24 recalls at endline and baseline, and then the difference was taken (endline - baseline).



### Weight loss 


```{r}
temp <- output.ancova[25:27,-c(10, 11, 15:(ncol(output.ancova)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), caption = "Weight Loss Measures") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))


temp <- output.logistic[,-c(11, 12, 16:ncol(output.logistic) )]
# combine CIs
temp$CI = paste0("(", formatC(temp$OR_LCL, digits = 2, format = "f"), ", ", formatC(temp$OR_UCL, digits = 2, format = "f"), ")")
temp <- temp[,-which(colnames(temp) %in% c("OR_LCL", "OR_UCL"))]
rownames(temp) = NULL
kable(temp[,c(1:7, 12, 8:11)],
      col.names = c("Variable", "Outcome", "Probability", "SE", "Probability", "SE", "OR", "OR CI", "SE", "z", "df", "p-value"), caption = "Logisitc Weight Loss Measures") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Odds Ratio" = 3, "Model Statistics" = 3))
```

The effect size from the model, adjusted for covariates, would be the odds ratio of the difference for binary outcomes.


### Behavioral 


```{r}
temp <- output.ancova[28:31,-c(10, 11, 15:(ncol(output.ancova)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), caption = "Change in Physical Activity") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))
```


```{r}
temp <- output.ancova[32:34,-c(10, 11, 15:(ncol(output.ancova)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), caption = "Change in Self-Reported Sleep") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))
```


For sleep quality, lower numbers are better where 1 is very good sleep quality and 5 is very poor sleep quality so higher number of change in sleep quality is worse. Recall for sleep amount 1 is more than usual, 2 is usual, and 3 is much less sleep than usual.


```{r}
temp <- output.ancova[35:49,-c(10, 11, 15:(ncol(output.ancova)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), caption = "Change in Habit Strength (for each behavior assessed, then grouped healthy and unhealthy)") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))
```



## Model Assumption Diagnostics

Model assumptions of normality and equal variance of residuals were evaluated for each outcome (Casella 2021, Glass 1996, Glass 1972). Rules of thumb are that data can be considered approximately normal where |skewness| <1; and equal variance can be considered with (0.5<(Var1/Var2)<2) (Blanca 2018, Glass 1972). However, analyses are robust to larger values of skewness (i.e. type-I error rates are maintained) with large sample sizes due to the central limit theorem; and unequal variance can be mitigated with approximately equal sample sizes between groups.



### Histograms

Histograms of residuals from the model of one selected imputation.

#### Dietary quality

Change in ASA24 HEI Diet Quality Scores (Total and Subscores) 

```{r}
# Plot residuals from first imputation
colnames(outcome_pairs)[which(colnames(outcome_pairs) == "outcomes")] = "outcome"

residual_hist_df <- subset(residual_list_dietqual1, .imp == 1) %>% 
  dplyr::select("WINS.ID","residuals", "outcome", "Treatment")

# Unblind treatment groups:
residual_hist_df$Treatment <- as.character(residual_hist_df$Treatment)
residual_hist_df$Treatment[residual_hist_df$Treatment == "1"] = "Weight Watchers"
residual_hist_df$Treatment[residual_hist_df$Treatment == "2"] = "Control"

residual_hist_df <- merge(outcome_pairs, residual_hist_df, by = "outcome", sort = FALSE)

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[1:14])

# highlight values 3 away from 0 as outliers
hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)


ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")
``` 

<br> 

Standardized residuals that are more than 3 away from zero: 

```{r}
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 

```


Other Dietary Quality Measures

```{r}

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[15])

hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")
``` 

<br> 

Standardized residuals that are more than 3 away from zero: 

```{r}

hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 


```

Change in Average Micro and Macro Nutrients Between Endline and Baseline

```{r}
residual_hist_df <- subset(residual_list_dietqual2, .imp == 1) %>% 
  dplyr::select("WINS.ID","residuals", "outcome", "Treatment")

# Unblind treatment groups:
residual_hist_df$Treatment <- as.character(residual_hist_df$Treatment)
residual_hist_df$Treatment[residual_hist_df$Treatment == "1"] = "Weight Watchers"
residual_hist_df$Treatment[residual_hist_df$Treatment == "2"] = "Control"

residual_hist_df <- merge(outcome_pairs, residual_hist_df, by = "outcome", sort = FALSE)

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[16:24])


hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)


ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")
``` 

<br> 

Standardized residuals that are more than 3 away from zero: 

```{r}
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 

```


#### Weight loss

```{r}

residual_hist_df <- subset(residual_list_weightloss, .imp == 1) %>% 
  dplyr::select("WINS.ID","residuals", "outcome", "Treatment")

# Unblind treatment groups:
residual_hist_df$Treatment <- as.character(residual_hist_df$Treatment)
residual_hist_df$Treatment[residual_hist_df$Treatment == "1"] = "Weight Watchers"
residual_hist_df$Treatment[residual_hist_df$Treatment == "2"] = "Control"

residual_hist_df <- merge(outcome_pairs, residual_hist_df, by = "outcome", sort = FALSE)

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[25:30])


hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)


ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")
``` 

<br> 

Standardized residuals that are more than 3 away from zero: 

```{r}
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 

```

#### Behavioral


Change in Physical Activity

```{r}
residual_hist_df <- subset(residual_list_behavioral1, .imp == 1) %>% 
  dplyr::select("WINS.ID","residuals", "outcome", "Treatment")

# Unblind treatment groups:
residual_hist_df$Treatment <- as.character(residual_hist_df$Treatment)
residual_hist_df$Treatment[residual_hist_df$Treatment == "1"] = "Weight Watchers"
residual_hist_df$Treatment[residual_hist_df$Treatment == "2"] = "Control"

residual_hist_df <- merge(outcome_pairs, residual_hist_df, by = "outcome", sort = FALSE)

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[31:34])


hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")
``` 

<br> 

Standardized residuals that are more than 3 away from zero: 

```{r}
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 

```

Change in Self-Reported Sleep


```{r}

residual_hist_df <- subset(residual_list_behavioral2, .imp == 1) %>% 
  dplyr::select("WINS.ID","residuals", "outcome", "Treatment")

# Unblind treatment groups:
residual_hist_df$Treatment <- as.character(residual_hist_df$Treatment)
residual_hist_df$Treatment[residual_hist_df$Treatment == "1"] = "Weight Watchers"
residual_hist_df$Treatment[residual_hist_df$Treatment == "2"] = "Control"

residual_hist_df <- merge(outcome_pairs, residual_hist_df, by = "outcome", sort = FALSE)

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[35:37])

hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")

```


For sleep quality, lower numbers are better where 1 is very good sleep quality and 5 is very poor sleep quality so higher number of change in sleep quality is worse. Recall for sleep amount 1 is more than usual, 2 is usual, and 3 is much less sleep than usual. 

<br> 

Standardized residuals that are more than 3 away from zero: 


```{r}
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 
```



Change in Habit Strength (for each behavior assessed, then grouped healthy and unhealthy)

```{r}

residual_hist_df <- subset(residual_list_behavioral3, .imp == 1) %>% 
  dplyr::select("WINS.ID","residuals", "outcome", "Treatment")

# Unblind treatment groups:
residual_hist_df$Treatment <- as.character(residual_hist_df$Treatment)
residual_hist_df$Treatment[residual_hist_df$Treatment == "1"] = "Weight Watchers"
residual_hist_df$Treatment[residual_hist_df$Treatment == "2"] = "Control"

residual_hist_df <- merge(outcome_pairs, residual_hist_df, by = "outcome", sort = FALSE)

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[38:52])

hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")
``` 

<br> 

Standardized residuals that are more than 3 away from zero: 

```{r}
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 


```


### Diagnostics

Table of diagnostic statistics of standardized model residuals

```{r}
imput_diag_tab = output.ancova %>% 
  dplyr::select(Outcome, Outcome_label, 
                Mean_Skewness,
                #Min_Skewness,
                Max_Skewness,
                Mean_Kurtosis,
                #Min_Kurtosis, 
                Max_Kurtosis,
                Levene_Pvalue, 
                Min_Levene,
                #Max_Levene, 
                Variance_Residual_Ratio,
                Variance_Residual_Ratio_Min,
                Variance_Residual_Ratio_Max)
#Variance_Outcome_Ratio,
#Variance_Outcome_Ratio_Min,
#Variance_Outcome_Ratio_max) 

imput_diag_tab <- imput_diag_tab %>% dplyr::filter(!Outcome %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl")) 

kable(imput_diag_tab,
      row.names = FALSE,
      col.names = c("Outcome", "Label", 
                    "Mean", "Max", #skew
                    "Mean", "Max", #kurt
                    "Mean", "Min", #"Max", #levene
                    "Mean", "Min", "Max" # var resid ratio
      )) %>% # var outcome ratio
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Skewness" = 2, "Kurtosis" = 2, "Levene's P-value"=2,
                     "Ratio of Variance" = 3)) %>%
  pack_rows(index = c("Change ASA24 in HEI Diet Quality Scores" = 14,
                      "Other Dietary Quality Measures" = 1,
                      "Change in Micro and Macro Nutrients" = 9,
                      "Weight Loss Measures" = 3,
                      "Change in Physical Activity" = 4,
                      "Change Self-Reported Sleep" = 3,
                      "Change in Habit Strength" = 15)) 

```

Maximum skewness is maximum |skewness|.

The three logistic models for binary outcomes percent body weight loss achieved are not included in this table.





# Sensitivity Analysis

## Outliers Removed

A sensitivity analysis excluding observations with standardized residuals >|3| was conducted to assess the impact of outliers. 


```{r}
###########
## Setup ##
###########

# First remove all the observations with |resid| > 3.
# Diet quality
for (out in unique(residual_list_dietqual1$outcome)){
  residual_list_dietqual1[which(residual_list_dietqual1$outcome == out & abs(residual_list_dietqual1$residuals) > 3),out] = NA
}
for (out in unique(residual_list_dietqual2$outcome)){
  residual_list_dietqual2[which(residual_list_dietqual2$outcome == out & abs(residual_list_dietqual2$residuals) > 3),out] = NA
}

# Weight loss
for (out in unique(residual_list_weightloss$outcome)){
      # 3 logistic models had no |residuals|>3 so use percent weight change flags (else results same as primary)
    if (out %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl")){
        residual_list_weightloss[which(residual_list_weightloss$outcome == "changekg_percent_body_wt" & abs(residual_list_weightloss$residuals) > 3),out] = NA
    } else{
  residual_list_weightloss[which(residual_list_weightloss$outcome == out & abs(residual_list_weightloss$residuals) > 3),out] = NA
    }
}

# Behavioral
for (out in unique(residual_list_behavioral1$outcome)){
  residual_list_behavioral1[which(residual_list_behavioral1$outcome == out & abs(residual_list_behavioral1$residuals) > 3),out] = NA
}
for (out in unique(residual_list_behavioral2$outcome)){
  residual_list_behavioral2[which(residual_list_behavioral2$outcome == out & abs(residual_list_behavioral2$residuals) > 3),out] = NA
}
for (out in unique(residual_list_behavioral3$outcome)){
  residual_list_behavioral3[which(residual_list_behavioral3$outcome == out & abs(residual_list_behavioral3$residuals) > 3),out] = NA
}

#####################

# Save reference levels
residual_list_dietqual1 <- imputed_references(residual_list_dietqual1)
residual_list_dietqual2 <- imputed_references(residual_list_dietqual2)
residual_list_weightloss <- imputed_references(residual_list_weightloss)
residual_list_behavioral1 <- imputed_references(residual_list_behavioral1)
residual_list_behavioral2 <- imputed_references(residual_list_behavioral2)
residual_list_behavioral3 <- imputed_references(residual_list_behavioral3)


# setup output shell table
cols <- c("Outcome", "Outcome_label", "Mean1", "SE1", "Mean2", "SE2", "Mean_Diff",
          "Mean_Diff_LB", "Mean_Diff_UB",
          "SE_Diff", "Estimate", "SE", "t", "df", "p_value", "Mean_Skewness", "Min_Skewness", 
          "Max_Skewness", "Mean_Kurtosis","Min_Kurtosis",  "Max_Kurtosis", "Levene_Pvalue", 
          "Min_Levene","Max_Levene", "Variance_Residual_Ratio", "Variance_Residual_Ratio_Min", 
          "Variance_Residual_Ratio_Max", "Variance_Outcome_Ratio", "Variance_Outcome_Ratio_Min",
          "Variance_Outcome_Ratio_max", "Number of Participants", "Cohens_d_unadjusted", "Cohens_d_adjusted")
output_sens = matrix(nrow = length(outcomes), ncol = length(cols))
colnames(output_sens) = cols

# models
# "achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl", "weight_change"
# get weight_bl as baseline measurement
```


```{r, eval = F}
##############
## Modeling ##
##############

# save residuals from one imputation for model assumption checks
residual_list <- data.frame()
print = "no"

for (out in outcomes){
  
    # setup model formula:
  if (out %in%  c("changekg_percent_body_wt", "achieve_3_percent_wl", "achieve_5_percent_wl", 
                  "achieve_10_percent_wl" # weight loss
  )){ # these outcomes dont match the _change, _bl structure
    formula = paste0(" ~ weightkg_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment")
  } else{formula = paste0("~ ", gsub("_change", "_bl", out), # everything else
                          " + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment")} 
  
  # extract data of interest since had to break up data when saving all residuals:
  if(out %in% unique(residual_list_dietqual1$outcome)){
    imputed.analysis.data = dplyr::filter(residual_list_dietqual1, outcome == out)
    imputed.analysis.data <- imputed.analysis.data[, !(colnames(imputed.analysis.data) %in% c("residuals", "outcome"))]
  } else if(out %in% unique(residual_list_dietqual2$outcome)){
    imputed.analysis.data = dplyr::filter(residual_list_dietqual2, outcome == out)
    imputed.analysis.data <- imputed.analysis.data[, !(colnames(imputed.analysis.data) %in% c("residuals", "outcome"))]
  } else if(out %in% unique(residual_list_behavioral1$outcome)){
    imputed.analysis.data = dplyr::filter(residual_list_behavioral1, outcome == out)
    imputed.analysis.data <- imputed.analysis.data[, !(colnames(imputed.analysis.data) %in% c("residuals", "outcome"))]
  } else if(out %in% unique(residual_list_behavioral2$outcome)){
    imputed.analysis.data = dplyr::filter(residual_list_behavioral2, outcome == out)
    imputed.analysis.data <- imputed.analysis.data[, !(colnames(imputed.analysis.data) %in% c("residuals", "outcome"))]
  } else if(out %in% unique(residual_list_behavioral3$outcome)){
    imputed.analysis.data = dplyr::filter(residual_list_behavioral3, outcome == out)
    imputed.analysis.data <- imputed.analysis.data[, !(colnames(imputed.analysis.data) %in% c("residuals", "outcome"))]
  } else if(out %in% unique(residual_list_weightloss$outcome)){
    imputed.analysis.data = dplyr::filter(residual_list_weightloss, outcome == out)
    imputed.analysis.data <- imputed.analysis.data[, !(colnames(imputed.analysis.data) %in% c("residuals", "outcome"))]
  } 
  
  # setup model:
  if (out %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", 
                 "achieve_10_percent_wl")){
    # logistic
    primary.model <- plyr::dlply(imputed.analysis.data, ".imp", function(df)
      glm(as.formula(paste(out, formula)), data = df, family = "binomial"))
    
  } else{
    # ANCOVA
    primary.model <- plyr::dlply(imputed.analysis.data, ".imp", function(df)
      lm(as.formula(paste(out, formula)), data = df))
    
  }
  
  # Difference between groups:
  emm.model <- as.mira(primary.model)
  # this command is used so that the emmeans packages recognizes that emm.model is a list of imputed models.
  # this is necessary so that the results are pooled using rubin's rules (https://github.com/rvlenth/emmeans/issues/80)
  
  # emmeans is different for logistic vs lm: 
  if (out %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", 
                 "achieve_10_percent_wl")){
    # logistic
    emm <- emmeans::emmeans(emm.model, "Treatment", type = "response")  # prob, SE, df, asymp.LCL asymp.UCL
    
    # pairs or pairwise
    emm.pairs = pairs(emmeans(emm.model, "Treatment", type = "response")) # T1 / T2,  OR SE df null z p 
    # pairs(emmeans(emm.model, "Treatment"), reverse = TRUE) # T2 - T1
    
    # to get OR CI:
    emm.pairs.CI = confint( pairs(emmeans(emm.model, "Treatment", type = "response")))
    
  } else{
    # ANCOVA
    emm <- emmeans::emmeans(emm.model, "Treatment", data = imputed.analysis.data) # estimate, SE, df, z, p
    
    # pairs or pairwise
    emm.pairs = pairs(emmeans(emm.model, "Treatment", data = imputed.analysis.data)) # T1 - T2 estiamte SD df z p
    # pairs(emmeans(emm.model, "Treatment"), reverse = TRUE) # T2 - T1
      # to get OR CI:
    emm.pairs.CI = confint( pairs(emmeans(emm.model, "Treatment", data = imputed.analysis.data)))
  }
  
  # Error running stats on residual because lists of uneven lengths:
  s.resids <- lapply(primary.model, rstandard) # list of 200
  s.resids376 <- s.resids
  
  # filling in NAs for participants dropped:
  for (i in 1:length(s.resids)){
    resid.df <- data.frame(row.names = 1:376)
    temp <- as.data.frame(unlist(s.resids[[i]]), row.names = names(s.resids[[i]]))
    colnames(temp) <- "residuals"
    resid.df <- merge(resid.df, temp, by = "row.names", all = TRUE)
    resid.df$Row.names <- as.numeric(resid.df$Row.names)
    resid.df <- resid.df[order(resid.df$Row.names),]
    rownames(resid.df)  = resid.df$Row.names
    resid.df <- resid.df[,-1]
    s.resids376[[i]] <- resid.df
  }

  
  # Diagnostics:
  
  # skewness on standardized residuals
  skewness.mean <- mean(sapply(s.resids, moments::skewness))
  skewness.max <- max( abs( sapply(s.resids, moments::skewness) )) 
  skewness.min <- min(sapply(s.resids, moments::skewness))
  
  # save residuals from the imputed models back onto the data set
  # by adding a new column for the standardized residuals from each model
  imputed.data.resids <- cbind(imputed.analysis.data,
                               data.frame(residuals = unlist(s.resids376, use.names = FALSE)))
  # factor treatment to group by later
  imputed.data.resids$Treatment = factor(imputed.data.resids$Treatment)
  
  # save residuals from first imputation from all outcomes for histograms
  temp <- imputed.data.resids %>% subset(.imp == 1) %>%
    dplyr::select(c(".imp", ".id", "WINS.ID", "Treatment", "residuals")) %>%
    mutate(outcome = out)
  
    residual_list <- rbind(residual_list, 
                           temp) 
  
  
  # run the levene's test on each dataset individually, then extract just the p-value from the test
  levene <- dlply(imputed.data.resids, ".imp", function(df)
    car::leveneTest(residuals ~ Treatment, data = df)$`Pr(>F)`[1])
  
  levene.pval <- mean(unlist(levene))
  levene.min <- min(unlist(levene))
  levene.max <- max(unlist(levene))
  
  # calculate the ratio of residual variance
  # first calculate the variance of residuals by group, by imputation.
  imputed.data.resids <- imputed.data.resids %>% group_by(.imp, Treatment) %>% 
    dplyr::summarise(variance.resids = var(residuals, na.rm = TRUE), .groups = "keep")
  # then group by just imputation to compare the two variances
  imputed.data.resids <- imputed.data.resids %>%
    group_by(.imp) %>% 
    dplyr::summarise(ratio.var.resid = 
                       variance.resids[Treatment == rownames(table(imputed.analysis.data$Treatment))[1]]/
                       variance.resids[Treatment == rownames(table(imputed.analysis.data$Treatment))[2]])
  # mean, min, max
  variance.residual.ratio.mean <- mean(imputed.data.resids$ratio.var.resid)
  variance.residual.ratio.min <- min(imputed.data.resids$ratio.var.resid)
  variance.residual.ratio.max <- max(imputed.data.resids$ratio.var.resid)
  # and above to take the mean across all imputation sets
  
  # calculate kurtosis mean, max, min
  kurtosis.mean <- mean(sapply(s.resids, moments::kurtosis))
  kurtosis.max <- max(sapply(s.resids, moments::kurtosis))
  kurtosis.min <- min(sapply(s.resids, moments::kurtosis))
  
  # calculate the ratio of outcome variance
  # first calculate the variance of outcome by group, by imputation
  variance.outcome.ratios <- imputed.analysis.data %>% group_by(.imp, Treatment) %>% 
    dplyr::summarise(variance.outcome = var(.data[[out]], na.rm = TRUE), .groups = "keep")
  # then group by just imputation to compare the two variances
  variance.outcome.ratios <- variance.outcome.ratios %>% group_by(.imp) %>% 
    dplyr::summarise(variance.outcome.ratio = 
                       variance.outcome[Treatment == rownames(table(imputed.analysis.data$Treatment))[1]]/
                       variance.outcome[Treatment == rownames(table(imputed.analysis.data$Treatment))[2]])
  # mean, min, max
  variance.outcome.ratio.mean <- mean(variance.outcome.ratios$variance.outcome.ratio)
  variance.outcome.ratio.min <- min(variance.outcome.ratios$variance.outcome.ratio)
  variance.outcome.ratio.max <- max(variance.outcome.ratios$variance.outcome.ratio)
  
  # Report measure of effect size, Cohen's d 
  # on imputed for each imputed data set and average across for all outcomes
  
  # Cohen’s d is calculated from means and SD for differences between groups, 
  # where d=(Mean1-Mean2)/SD
  
  # Calculate effect size components by imputation and treatment (for non-binary):
  # first calculate components by imputation and treatment
  effect_size <- imputed.analysis.data %>% group_by(.imp, Treatment) %>% 
    dplyr::summarise(Mean = mean(.data[[out]], na.rm = TRUE),
                     SD = stats:::sd(.data[[out]], na.rm = TRUE),
                     n = sum(!is.na(.data[[out]])),
                     .groups = "keep")
  
  # then calculate effect size by imputation (no longer grouping by treatment)
  effect_size2 <- effect_size %>% group_by(.imp) %>%
    dplyr::summarise(cohensd = (Mean[Treatment == 1] - Mean[Treatment == 2]) / 
                       sqrt( ((n[Treatment == 1] - 1) * SD[Treatment == 1]^2 +
                                (n[Treatment == 2] - 1) * SD[Treatment == 2]^2) / 
                               (n[Treatment == 1] + n[Treatment == 2] - 2)
                       ),
                     .groups = "keep")
  
  
  # Calculate cohens d from model, adjusting for covariates:
  effect_size2$cohensd2 <- NA
  # emmeans is different for logistic vs lm: 
  if (out %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", 
                 "achieve_10_percent_wl")){
    
    # for logistic the effect size is the odds ratio
    
    # logistic
    # emm <- emmeans::emmeans(emm.model, "Treatment", type = "response")  # prob, SE, df, asymp.LCL asymp.UCL
    
    # pairs or pairwise
    # emm.pairs = pairs(emmeans(emm.model, "Treatment", type = "response")) # T1 / T2,  OR SE df null z p 
    # pairs(emmeans(emm.model, "Treatment"), reverse = TRUE) # T2 - T1
    
    effect_size2$cohensd2  = data.frame(emm.pairs)$odds.ratio
    
  } else{
    
    for (iter in 1:max(imputed.analysis.data$.imp)){
      # ANCOVA
      emm_iter <- emmeans::emmeans(primary.model[[iter]], "Treatment") # estimate, SE, df, z, p
      
      # pairs or pairwise
      emm.pairs_iter = pairs(emmeans(primary.model[[iter]], "Treatment")) # T1 - T2 estiamte SD df z p
      
      contrast = data.frame(emm.pairs_iter)
      effect_size2[iter, "cohensd2"] <- data.frame(eff_size(emm_iter, 
                                                            sigma = sigma(primary.model[[iter]]), 
                                                            edf = contrast[, "df"]))$effect.size
    }
  }
  
  
  n_participants <- mean(sapply(s.resids, length))
  
  
  # Save differently for different models:
  if (out %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", 
                 "achieve_10_percent_wl")){
    # logistic
    #emm <- emmeans::emmeans(emm.model, "Treatment", type = "response")  # prob, SE, df, asymp.LCL asymp.UCL
    
    # pairs or pairwise
    #emm.pairs = pairs(emmeans(emm.model, "Treatment", type = "response")) # T1 / T2,  OR SE df null z p 
    
    output_sens[which(outcomes == out),] =
      c(out, outcome_pairs$outcome_labels[which(outcome_pairs$outcome == out)],
        summary(emm)$prob[1], summary(emm)$SE[1], # prob and SE X
        summary(emm)$prob[2], summary(emm)$SE[2], # prob and SE Y
        # difference in groups treatment groups:
        c(summary(emm.pairs)$odds.ratio, emm.pairs.CI$lower.CL, emm.pairs.CI$upper.CL, summary(emm.pairs)$SE),
        unlist(summary(pool(primary.model))[which(summary(pool(primary.model))$term == "Treatment2"),2:6]),
        skewness.mean, skewness.min, skewness.max, 
        kurtosis.mean, kurtosis.min, kurtosis.max, 
        levene.pval, levene.min, levene.max, 
        variance.residual.ratio.mean, variance.residual.ratio.min, variance.residual.ratio.max,
        variance.outcome.ratio.mean, variance.outcome.ratio.min, variance.outcome.ratio.max,
        n_participants,
        mean(effect_size2$cohensd), mean(effect_size2$cohensd2) # cohens d
      )
    
  } else{
    # ANCOVA
    #emm <- emmeans::emmeans(emm.model, "Treatment") # estimate, SE, df, z, p
    
    # pairs or pairwise
    #emm.pairs = pairs(emmeans(emm.model, "Treatment")) # T1 - T2 estiamte SD df z p
    
    output_sens[which(outcomes == out),] =
      c(out, outcome_pairs$outcome_labels[which(outcome_pairs$outcome == out)],
        summary(emm)$emmean[1], summary(emm)$SE[1], # mean and SE X
        summary(emm)$emmean[2], summary(emm)$SE[2], # mean and SE Y
        # difference in groups treatment groups:
        c(summary(emm.pairs)$estimate, emm.pairs.CI$lower.CL, emm.pairs.CI$upper.CL, summary(emm.pairs)$SE),
        unlist(summary(pool(primary.model))[which(summary(pool(primary.model))$term == "Treatment2"),2:6]),
        skewness.mean, skewness.min, skewness.max, 
        kurtosis.mean, kurtosis.min, kurtosis.max, 
        levene.pval, levene.min, levene.max, 
        variance.residual.ratio.mean, variance.residual.ratio.min, variance.residual.ratio.max,
        variance.outcome.ratio.mean, variance.outcome.ratio.min, variance.outcome.ratio.max,
        n_participants,
        mean(effect_size2$cohensd), mean(effect_size2$cohensd2) # cohens d
      )
    
  }
  
  # Optionl returns while loop running:
  if(print == "yes"){
    #print(paste(out, formula))
    print(paste0(out, " outcome ", which(outcomes == out), " of ", length(outcomes),"."))
  }
}

# Combined model results
output_sens = as.data.frame(output_sens)

# save output table:
save(output_sens, residual_list,
     file = paste0("WINS_Main_Analysis_outlier_", Sys.Date(), ".RData"))

```


```{r}
# load saved output from chunk above:
load("WINS_Main_Analysis_outlier_2025-01-28.RData")

output_sens_saved <- output_sens
output_sens[,3:ncol(output_sens)] = apply(output_sens[,3:ncol(output_sens)], 2, as.numeric)

# format p-values:
output_sens <- output_sens %>% 
  mutate(
    p_value = case_when(.data[["p_value"]] < 0.001 ~ sub(" ", "", format.pval(.data[["p_value"]], eps = 0.001, digits = 3, nsmall=3)),
                        TRUE ~ formatC(.data[["p_value"]], digits = 3, format = "f")),
    Levene_Pvalue = case_when(.data[["Levene_Pvalue"]] < 0.001 ~ sub(" ", "", format.pval(.data[["Levene_Pvalue"]], eps = 0.001, digits = 3, nsmall=3)),
                              TRUE ~ formatC(.data[["Levene_Pvalue"]], digits = 3, format = "f")),
    Min_Levene = case_when(.data[["Min_Levene"]] < 0.001 ~ sub(" ", "", format.pval(.data[["Min_Levene"]], eps = 0.001, digits = 3, nsmall=3)),
                           TRUE ~ formatC(.data[["Min_Levene"]], digits = 3, format = "f")),
    Max_Levene = case_when(.data[["Max_Levene"]] < 0.001 ~ sub(" ", "", format.pval(.data[["Max_Levene"]], eps = 0.001, digits = 3, nsmall=3)),
                           TRUE ~ formatC(.data[["Max_Levene"]], digits = 3, format = "f"))
    
  )

# round non-pvalues to 2 decimal places
p_values = which(cols %in% c("p_value", "Levene_Pvalue",
                             "Min_Levene", "Max_Levene"))
log_output_sens <- output_sens
non_pvals <- setdiff(3:ncol(output_sens), p_values)
output_sens[,non_pvals] = apply(output_sens[,non_pvals], 2, function(x) sprintf("%.2f", x))

rownames(output_sens) = NULL

# to keep outcome pairs indices, combine CI:
temp = outcome_pairs %>% dplyr::rename(Outcome = outcome) %>% 
  dplyr::rename(Outcome_label = outcome_labels)

output_sens <- merge(temp, output_sens, by = c("Outcome", "Outcome_label"), sort = FALSE) #all = TRUE,
output_sens <- output_sens %>% mutate(
  Mean_Diff_CI = paste0("(", Mean_Diff_LB, ", ", Mean_Diff_UB, ")")
)  %>%
  select(-Mean_Diff_LB, -Mean_Diff_UB) %>%
  select(
    Outcome, Outcome_label, Mean1, SE1, Mean2, SE2, Mean_Diff, 
    Mean_Diff_CI, SE_Diff, Estimate, SE, t, df, p_value, 
    Mean_Skewness, Min_Skewness, Max_Skewness, Mean_Kurtosis, Min_Kurtosis, 
    Max_Kurtosis, Levene_Pvalue, Min_Levene, Max_Levene, 
    Variance_Residual_Ratio, Variance_Residual_Ratio_Min, 
    Variance_Residual_Ratio_Max, Variance_Outcome_Ratio, 
    Variance_Outcome_Ratio_Min, Variance_Outcome_Ratio_max, 
    `Number of Participants`, Cohens_d_unadjusted, Cohens_d_adjusted
  )


```

### Model Results

#### Dietary quality

```{r}
kable(output_sens[1:14,-c(10, 11, 15:(ncol(output_sens)-2))],
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"),
      caption = "Change in ASA24 HEI Diet Quality Scores (Total and Subscores)") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))

```


```{r}
temp <- output_sens[15,-c(10, 11, 15:(ncol(output_sens)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), 
      caption = "Other Dietary Quality Measures") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))
```

```{r}
temp <- output_sens[16:24,-c(10, 11, 15:(ncol(output_sens)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), 
      caption = "Change in Average Micro and Macro Nutrients Between Endline and Baseline") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))
```

These measurements were averaged across the ASA24 recalls at endline and baseline, and then the difference was taken (endline - baseline).


#### Weight loss 


Outliers for significant weight loss were more often found in the Weight Watchers group (and in some cases, participants with significant weight gain were flagged as outliers from the Control group). When we remove these for the sensitivity analysis, the difference between the two groups are sometimes less significant. 

```{r}
temp <- output_sens[25:27,-c(10, 11, 15:(ncol(output_sens)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), caption = "Weight Loss Measures") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))

```

For the three logistic outcomes (achievement of a certain percentage of weight loss), since it's binary there weren't any outliers flagged with |standardized residuals|>3. As a result, we flagged outliers for these variables using the same outliers determined by the Percent Body Weight Change outcome.

```{r}
temp <- output_sens[28:30,-c(10, 11, 15:(ncol(output_sens)))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Probability", "SE", "Probability", "SE", "OR", "95% CI", "SE", "z", "df", "p-value"), caption = "Logisitc Weight Loss Measures") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3))

```




#### Behavioral 


```{r}
temp <- output_sens[31:34,-c(10, 11, 15:(ncol(output_sens)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), caption = "Change in Physical Activity") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))

```


```{r}
temp <- output_sens[35:37,-c(10, 11, 15:(ncol(output_sens)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), caption = "Change in Self-Reported Sleep") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))
```


For sleep quality, lower numbers are better where 1 is very good sleep quality and 5 is very poor sleep quality so higher number of change in sleep quality is worse. Recall for sleep amount 1 is more than usual, 2 is usual, and 3 is much less sleep than usual.


```{r}
temp <- output_sens[38:52,-c(10, 11, 15:(ncol(output_sens)-2))]
rownames(temp) = NULL
kable(temp,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value", "unadjusted", "adjusted"), caption = "Change in Habit Strength (for each behavior assessed, then grouped healthy and unhealthy)") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference"=3, "Model Statistics" = 3, "Cohen's d" = 2))
```


#### Comparison


```{r}
# Compare raw p-values:
comparison <- merge(primary_results[,c("Outcome_label", "p_value")], output_sens_saved[,c("Outcome_label", "p_value")], 
                    by = "Outcome_label", suffixes = c(".primary", ".sens"), sort = FALSE)

# make p-values numeric
comparison$p_value.primary = as.numeric(comparison$p_value.primary)
comparison$p_value.sens = as.numeric(comparison$p_value.sens)

comparison <- comparison %>% mutate(
  change = case_when(p_value.primary < 0.05 & p_value.sens < 0.05 ~ "No Change",
                     p_value.primary > 0.05 & p_value.sens > 0.05 ~ "No Change",
                     p_value.primary < 0.05 & p_value.sens > 0.05 ~ "Change",
                     p_value.primary > 0.05 & p_value.sens < 0.05 ~ "Change")
)

table(comparison$change)
```


All `r sum(comparison$change == "No Change")` of the 52 outcomes did not change in level of significance between the primary and outlier removed sensitivity analysis. 


### Model Assumption Checks

Model assumptions of normality and equal variance of residuals will be evaluated for each outcome. Normality of residuals will be considered satisfied with a skewness <|2| given large sample sizes and; and equal variance between groups will be considered satisfied with (0.5<(Var1/Var2)<2) with approximately balanced group sizes. Significance tests for baseline differences will not be conducted per CONSORT guidelines. A sensitivity analysis excluding observations with standardized residuals >|3| will be conducted to assess the impact of outliers.

### Histograms

Histograms of residuals from the model of one selected imputation.

#### Dietary quality

Change in ASA24 HEI Diet Quality Scores (Total and Subscores) 

```{r}
# Plot residuals from first imputation
colnames(outcome_pairs)[which(colnames(outcome_pairs) == "outcomes")] = "outcome"

residual_hist_df <- subset(residual_list, .imp == 1) %>% dplyr::select("WINS.ID","residuals", "outcome", "Treatment")

# Unblind treatment groups:
residual_hist_df$Treatment <- as.character(residual_hist_df$Treatment)
residual_hist_df$Treatment[residual_hist_df$Treatment == "1"] = "Weight Watchers"
residual_hist_df$Treatment[residual_hist_df$Treatment == "2"] = "Control"

residual_hist_df <- merge(outcome_pairs, residual_hist_df, by = "outcome", sort = FALSE)

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[1:14])

hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

# remove NAs so dont get warning when plotting hist:
hist1 <- hist1[-which(is.na(hist1$residuals)),]

# highlight values 3 away from 0 as outliers
hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

# histogram
ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")


# table of outliers
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 

```


Other Dietary Quality Measures

```{r}

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[15])


hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

# remove NAs so dont get warning when plotting hist:
hist1 <- hist1[-which(is.na(hist1$residuals)),]

# highlight values 3 away from 0 as outliers
hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

# histogram
ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")

# table of outliers
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 


```

Change in Average Micro and Macro Nutrients Between Endline and Baseline

```{r}

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[16:24])


hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

# remove NAs so dont get warning when plotting hist:
hist1 <- hist1[-which(is.na(hist1$residuals)),]

# highlight values 3 away from 0 as outliers
hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

# histogram
ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")

# table of outliers
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 

```


#### Weight loss

```{r}

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[25:30])


hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

# remove NAs so dont get warning when plotting hist:
hist1 <- hist1[-which(is.na(hist1$residuals)),]

# highlight values 3 away from 0 as outliers
hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

# histogram
ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")

# table of outliers
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 

```

#### Behavioral


Change in Physical Activity

```{r}

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[31:34])


hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

# remove NAs so dont get warning when plotting hist:
hist1 <- hist1[-which(is.na(hist1$residuals)),]

# highlight values 3 away from 0 as outliers
hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

# histogram
ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")

# table of outliers
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 

```

Change in Self-Reported Sleep


```{r}

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[35:37])

hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

# remove NAs so dont get warning when plotting hist:
hist1 <- hist1[-which(is.na(hist1$residuals)),]

# highlight values 3 away from 0 as outliers
hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

# histogram
ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")

```


For sleep quality, lower numbers are better where 1 is very good sleep quality and 5 is very poor sleep quality so higher number of change in sleep quality is worse. Recall for sleep amount 1 is more than usual, 2 is usual, and 3 is much less sleep than usual. 

```{r}
# table of outliers
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 
```



Change in Habit Strength (for each behavior assessed, then grouped healthy and unhealthy)

```{r}

hist1 <- subset(residual_hist_df, outcome %in% outcome_pairs$outcome[38:52])

hist1 <- hist1 %>% dplyr::group_by(outcome) %>%
  mutate(Mean = base::mean(residuals, na.rm = TRUE),
         UB = 3,
         LB = -3)

# remove NAs so dont get warning when plotting hist:
hist1 <- hist1[-which(is.na(hist1$residuals)),]

# highlight values 3 away from 0 as outliers
hist1$outliers = 0
hist1$outliers[hist1$residuals > hist1$UB] = 1
hist1$outliers[hist1$residuals < hist1$LB] = 1
hist1$outliers <- factor(hist1$outliers)

# histogram
ggplot(hist1, aes(x = residuals, fill = outliers)) +
  theme_bw() + geom_histogram(bins = 30) +
  theme(legend.position = "none") +
  facet_wrap(~outcome, scales = "free", ncol = 3) + 
  ggtitle("|Stand. Resid| > 3 in Red") + 
  scale_fill_manual(values = c("blue", "red")) + 
  geom_vline(aes(xintercept = Mean), color = "#000000", linewidth = 0.5) +
  geom_vline(aes(xintercept = UB), color = "#000000", linewidth = 0.5, linetype = "dashed") +
  geom_vline(aes(xintercept = LB), color = "#000000", linewidth = 0.5, linetype = "dashed")

# highlight values 3 away from 0 as outliers
hist1$residuals <- round(hist1$residuals, 3)

hist1 %>% dplyr::group_by(WINS.ID) %>% arrange(WINS.ID) %>%
  subset(!is.na(residuals) & outliers == 1) %>% 
  dplyr::select(WINS.ID, outcome, outcome_labels, residuals, Treatment) %>% kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() 


```

### Diagnostics

Table of diagnostic statistics of model residuals

```{r}
imput_diag_tab = output_sens %>% 
  dplyr::select(Outcome, Outcome_label, 
                Mean_Skewness,
                #Min_Skewness,
                Max_Skewness,
                Mean_Kurtosis,
                #Min_Kurtosis, 
                Max_Kurtosis,
                Levene_Pvalue, 
                Min_Levene,
                #Max_Levene, 
                Variance_Residual_Ratio,
                Variance_Residual_Ratio_Min,
                Variance_Residual_Ratio_Max)
#Variance_Outcome_Ratio,
#Variance_Outcome_Ratio_Min,
#Variance_Outcome_Ratio_max) 

imput_diag_tab <- imput_diag_tab %>% dplyr::filter(!outcomes %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl")) 

kable(imput_diag_tab,
      row.names = FALSE,
      col.names = c("Outcome", "Label", 
                    "Mean", "Max", #skew
                    "Mean", "Max", #kurt
                    "Mean", "Min", #"Max", #levene
                    "Mean", "Min", "Max" # var resid ratio
      )) %>% # var outcome ratio
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Skewness" = 2, "Kurtosis" = 2, "Levene's P-value"=2,
                     "Ratio of Variance" = 3)) %>%
  pack_rows(index = c("Change ASA24 in HEI Diet Quality Scores" = 14,
                      "Other Dietary Quality Measures" = 1,
                      "Change in Micro and Macro Nutrients" = 9,
                      "Weight Loss Measures" = 3,
                      "Change in Physical Activity" = 4,
                      "Change Self-Reported Sleep" = 3,
                      "Change in Habit Strength" = 15)) 
```

Maximum skewness is maximum |skewness|.

The three logistic models for binary outcomes percent body weight loss achieved are not included in this table.








## LMM


$$
Original \space score = baseline + Sex + Age + Race + Ethnicity + Education + \\
Treatment + Time + Treatment*Time + (1|WINS.ID)
$$

```{r}
# Thank you to Xiwei Chen for this code:

#######################
## Data prep for LMM ##
#######################

df.bl <- raw_data %>%
  dplyr::select(WINS.ID, ends_with("_bl")) %>%
  dplyr::rename_with(~str_remove(., '_bl')) %>%
  dplyr::mutate(Time = "baseline")

df.el <- raw_data %>%
  dplyr::select(WINS.ID, ends_with("_el")) %>%
  dplyr::rename_with(~str_remove(., '_el')) %>%
  dplyr::mutate(Time = "endline")

df.other <- raw_data %>% 
  dplyr::select(-c(ends_with("_el")))

df_long <- df.other %>% full_join(dplyr::bind_rows(df.bl, df.el), by = join_by(WINS.ID)) %>%
  arrange(WINS.ID, Time)
```

### Model Results


```{r, message=FALSE, warning=FALSE}

# LMM on continuous outcomes with longitudinal data:
yvars = setdiff(outcomes, c("achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl", "changekg_percent_body_wt"))
output_lmm = NULL
output_lmm_raw = NULL

for (yvar in yvars){
  # Model
  formula = as.formula(paste0(gsub("_change", "", yvar), " ~ ", gsub("_change", "_bl", yvar), 
                              " + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment*Time + (1|WINS.ID)"))
  mod = lmer(formula, data = df_long)
  
  
  # Estimated means and contrasts
  em = emmeans(mod, revpairwise ~ Time|Treatment)
  contrast = data.frame(em$contrasts)
  did = data.frame(pairs(pairs(emmeans(mod, ~ Time|Treatment), reverse = TRUE), by = NULL))
  did_CI = confint(pairs(pairs(emmeans(mod, ~ Time|Treatment), reverse = TRUE), by = NULL))
  out = data.frame(Outcomes = yvar,
                   group1_mean = round(contrast[contrast$Treatment == "Weight Watchers", "estimate"], 2),
                   group1_se = round(contrast[contrast$Treatment == "Weight Watchers", "SE"], 2),
                   group2_mean = round(contrast[contrast$Treatment == "Control", "estimate"], 2),
                   group2_se = round(contrast[contrast$Treatment == "Control", "SE"], 2),
                   diff_mean = round(did[, "estimate"], 2),
                   diff_CI = paste0("(", sprintf("%.2f", did_CI[, "lower.CL"]), ", ", sprintf("%.2f", did_CI[, "upper.CL"]), ")"),
                   diff_se = round(did[, "SE"], 2),
                   diff_t = round(did[, "t.ratio"], 2),
                   diff_df = round(did[, "df"], 2),
                   diff_p = did[, "p.value"])
  
    out_raw = data.frame(Outcomes = yvar,
                   group1_mean = contrast[contrast$Treatment == "Weight Watchers", "estimate"],
                   group1_se = contrast[contrast$Treatment == "Weight Watchers", "SE"],
                   group2_mean = contrast[contrast$Treatment == "Control", "estimate"],
                   group2_se = contrast[contrast$Treatment == "Control", "SE"],
                   diff_mean = did[, "estimate"],
                   diff_LB = did_CI[, "lower.CL"],
                   diff_UB = did_CI[, "upper.CL"],
                   diff_se = did[, "SE"],
                   diff_t = did[, "t.ratio"],
                   diff_df = did[, "df"],
                   diff_p = did[, "p.value"])
  
  output_lmm = rbind(output_lmm, out)
  
  output_lmm_raw = rbind(output_lmm_raw, out_raw)
  
  # Optionl returns while loop running:
  #print(paste0(yvar, " outcome ", which(yvars == yvar), " of ", length(yvars),"."))
}

output_lmm_saved <- output_lmm

# combine output with labels, select desired columns, and remove _change from outcome names
output_lmm = output_lmm  %>% 
  dplyr::rename("outcome" = "Outcomes") %>% 
  left_join(outcome_pairs, by = "outcome") %>% 
  dplyr::select(1,12,2:11) %>% 
  mutate(outcome = gsub("_change", "", outcome))

output_lmm_raw = output_lmm_raw  %>% 
  dplyr::rename("outcome" = "Outcomes") %>% 
  left_join(outcome_pairs, by = "outcome") %>% 
  dplyr::select(1,13,2:12) %>% 
  mutate(outcome = gsub("_change", "", outcome))

# round to 2 places and keep both places:
non_pvals = c("group1_mean", "group1_se", "group2_mean", "group2_se", 
              "diff_mean", "diff_se", "diff_t", "diff_df")
output_lmm[,non_pvals] = apply(output_lmm[, non_pvals], 2, function(x) sprintf("%.2f", x))

# save for table 3 usage where round p-values differently:
output_lmm2 <- output_lmm

# round p-values to 3 places:
output_lmm2 <- output_lmm2 %>% 
  mutate(
    diff_p = case_when(.data[["diff_p"]] < 0.001 ~ sub(" ", "", format.pval(.data[["diff_p"]], eps = 0.001, digits = 3, nsmall=3)),
                        TRUE ~ formatC(.data[["diff_p"]], digits = 3, format = "f")))

# table of results
kable(output_lmm2,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value"),
      caption = "LMM on all people") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference" = 3, "Model Statistics" = 3)) %>%
  pack_rows(index = c("Change in Dietary Quality Measures (including HEI subscores)" = 15,
                      "Change in Micro and Macro Nutrients" = 9,
                      "Weight Loss Measures" = 6-4,
                      "Change in Physical Activity" = 4,
                      "Change Self-Reported Sleep" = 3,
                      "Change in Habit Strength" = 15)) 


```


Note: there are four weight loss outcomes missing from the LMM Sensitivity analysis because they did not have an endline and baseline measure for longitudinal modeling. 

### Comparison

```{r}

# let's merge the raw lmm output with the primary output to compare p-values
colnames(output_lmm)[2] = "Outcome_label"
comparison <- merge(primary_results[,c("Outcome_label", "p_value")], 
                    output_lmm[,c("Outcome_label", "diff_p")],
                    by = "Outcome_label", sort = FALSE)

# make p-values numeric
comparison$p_value = as.numeric(comparison$p_value)
comparison$diff_p = as.numeric(comparison$diff_p)
# add a variable indicating if p-values changed significance level
comparison <- comparison %>%  mutate(
  change = case_when(p_value < 0.05 & diff_p < 0.05 ~ "No Change",
                     p_value > 0.05 & diff_p > 0.05 ~ "No Change",
                     p_value < 0.05 & diff_p > 0.05 ~ "Change",
                     p_value > 0.05 & diff_p < 0.05 ~ "Change")
)

# format table to display changes
colnames(comparison) =c("Outcome", "Primary p-value", "LMM p-value", "Change")
comparison[,2:3] = round(comparison[,2:3], 3)

table(comparison$Change)
```


`r sum(comparison$Change == "No Change")` of the 48 outcomes did not change in level of significance between the primary and LMM sensitivity analysis.

The `r sum(comparison$Change == "Change")` outcomes that did result in a level of significant change are as follows:

```{r}
comparison.flips <- comparison[which(comparison$Change == "Change"), -4]
comparison.flips$color = 0
comparison.flips$color[comparison.flips$`Primary p-value` < comparison.flips$`LMM p-value`] = 1
rownames(comparison.flips) = NULL
kable(comparison.flips[,-4]) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal()  %>%
  row_spec(which(comparison.flips$color >0), color = "red") %>%
  row_spec(which(comparison.flips$color <1), color = "blue")
```
 
 
## Bayes Factor 

We are calculating the Bayes Factor for Total Sugars and Added Sugars because these two outcomes switched to being no longer significant in the LMM.

Bayes Factor is a metric to indicate the support of the null effect for no differences between groups. The Bayes Factor is an alternative to using p-values to quantify the level of support of the null hypothesis of no differences. It is calculated using a ratio of the likelihood of the model including group as a factor to the model not including group, where larger values indicate less evidence of the null effect. (see Andraszewicz, S., Scheibehenne, B., Rieskamp, J., Grasman, R., Verhagen, J., & Wagenmakers, E. J. (2015). An introduction to Bayesian hypothesis testing for management research. Journal of Management, 41(2), 521-543., and BayesFactor: Computation of Bayes Factors for Common Designs. https://cran.r-project.org/web/packages/BayesFactor/index.html)

Interpretation of Bayes factor (from Andraszewicz et al 2015):\

| Bayes factor | Label |
|--------------|:-------:|
| >100 | Extreme evidence for H1 |
| 30-100 | Very strong evidence for H1 |
| 10-30 | Strong evidence for H1 |
| 3-10 | Moderate evidence for H1 |
| 1-3 | Anecdotal evidence for H1 |
| 1 | No evidence |
| 1/3 - 1 | Anecdotal evidence for H0 |
| 1/10 - 1/3 | Moderate evidence for H0 |
| 1/30 - 1/10 | Strong evidence for H0 |
| 1/100 - 1/30 | Very strong evidence for H0 |
| <1/100 | Extreme evidence evidence for H0 |

H$_0$: Null hypothesis that states the absence of the effect\
H$_1$: Alternative hypothesis that states the presence of the effect\
Ratio = H$_1$/H$_0$\

A BF=10 indicates that the data is 10 times more likely under H$_1$ than H$_0$, while a BF=0.2 means that the data is 5 times more likely under H$_0$ than H$_1$.


### ANCOVA+MI

Showing the Bayes Factor results for change in average total sugars and change in average added sugars from ANCOVA+MI.

```{r}


outcome_list2 <- colnames(imputed_long_2[,15:16])


miBF_OUT2 <- NULL
for (i in 1:length(outcome_list2)){
  
 # i=1
  nimp=41 #max(imputed_long_2$.imp)
  vbf=bf=rep(0,nimp)
  
  for (j in 1:nimp){
  
#    j=1
    
    temp2 <- imputed_long_2[imputed_long_2$`.imp` == j,]
    temp2 <- temp2[,c("Sex_bcf","Age_years","Race2_bcf","Ethnicity_bcf","Education_grouped","Treatment",gsub("_change", "_bl", outcome_list2[i]),outcome_list2[i])]
    names(temp2)[names(temp2) == outcome_list2[i]] <- "outcome"
    names(temp2)[names(temp2) == gsub("_change", "_bl", outcome_list2[i])] <- "outcome_pre"
  
    # Bayes factor of full model against null
    bfFull = lmBF(outcome ~ Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + outcome_pre + Treatment, data = temp2)
    # Bayes factor of covariates only against null
    bfCov = lmBF(outcome ~ Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + outcome_pre, data = temp2)
    # Compare the two models
#    ratio = bfCov / bfFull #Xiweis code from APRE had it this way, but I think it should be this way 
    #https://richarddmorey.github.io/BayesFactor/#fixed
    #https://www.statisticshowto.com/bayes-factor-definition/
    ratio = bfFull / bfCov
    effect=extractBF(ratio)
    bf[j]=effect$bf
    vbf[j]=(nrow(temp2)-2)*effect$error^2
  }
  
  bf.bar=mean(bf)
  vbf.bar=mean(vbf)
  B=var(bf)
  S=vbf.bar+(1+(1/nimp))*B
  out2=data.frame(t(c(Outcome=outcome_list2[i], round((c(miBF=bf.bar, miError=sqrt(S))),2))))
  
  miBF_OUT2 <- rbind(miBF_OUT2,out2)
}

miBF_OUT2



```

Bayes Factor here is the ratio of the full model (covariates plus treatment group) divided by the covariate-only model: both Bayes factors are between 1 and 3 and thus there is only anecdotal evidence for treatment group.


### LMM


Showing the Bayes Factor results for Average total sugars and average added sugars from LMM.


```{r}
#Preparing the data for next chunk

#total sugar
df_long_sugar <- df_long %>% 
  drop_na(SUGR_ave) %>%
  select(SUGR_ave, SUGR_ave_bl, Sex_bcf, Age_years, Race2_bcf, Ethnicity_bcf, Education_grouped, Treatment, Time, WINS.ID)

df_long_sugar$Sex_bcf <- as.factor(df_long_sugar$Sex_bcf)  
df_long_sugar$Race2_bcf <- as.factor(df_long_sugar$Race2_bcf)  
df_long_sugar$Ethnicity_bcf <- as.factor(df_long_sugar$Ethnicity_bcf) 
df_long_sugar$Education_grouped <- as.factor(df_long_sugar$Education_grouped)  
df_long_sugar$Time <- as.factor(df_long_sugar$Time)  
df_long_sugar$WINS.ID <- as.factor(df_long_sugar$WINS.ID)  

#added sugar
df_long_add_sugar <- df_long %>% 
  drop_na(ADD_SUGARS_ave) %>%
  select(ADD_SUGARS_ave, ADD_SUGARS_ave_bl, Sex_bcf, Age_years, Race2_bcf, Ethnicity_bcf, Education_grouped, Treatment, Time, WINS.ID)

df_long_add_sugar$Sex_bcf <- as.factor(df_long_add_sugar$Sex_bcf)  
df_long_add_sugar$Race2_bcf <- as.factor(df_long_add_sugar$Race2_bcf)  
df_long_add_sugar$Ethnicity_bcf <- as.factor(df_long_add_sugar$Ethnicity_bcf) 
df_long_add_sugar$Education_grouped <- as.factor(df_long_add_sugar$Education_grouped)  
df_long_add_sugar$Time <- as.factor(df_long_add_sugar$Time)  
df_long_add_sugar$WINS.ID <- as.factor(df_long_add_sugar$WINS.ID)  


```


```{r, eval = FALSE}

### Note: running this chunk takes around 8-10 hours !!!!

# References for Bayes Factor
#https://rpubs.com/mabbott/bayes
#https://richarddmorey.github.io/BayesFactor/
#https://www.statisticshowto.com/bayes-factor-definition/ --> this one is alternative over null
#https://www.r-bloggers.com/2015/01/what-does-a-bayes-factor-feel-like/ --> this one has BF > 1 favoring alternative


#Bayes Factor for total sugar
#Bayes Factor for total sugar
#Bayes Factor for total sugar

#mod_sugar <- lmer(SUGR_ave ~ SUGR_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment*Time + (1|WINS.ID), data = df_long)

#this next line is running all different combinations of all covariates and saves into bfsObject
bfsObject <- generalTestBF(SUGR_ave ~ SUGR_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment*Time + WINS.ID,
                           whichRandom = c('WINS.ID'), data = df_long_sugar, whichModels = "all")



#Bayes Factor for added sugar
#Bayes Factor for added sugar
#Bayes Factor for added sugar

#this next line is running all different combinations of all covariates and saves into bfsObject2
bfsObject2 <- generalTestBF(ADD_SUGARS_ave ~ ADD_SUGARS_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment*Time + WINS.ID,
                           whichRandom = c('WINS.ID'), data = df_long_add_sugar, whichModels = "all")


save(bfsObject, bfsObject2,
     file = paste0("WINS_BayesFactor_LMM_", Sys.Date(), ".RData"))



```
 
 
```{r}
# load in results from chunk above:
load("WINS_BayesFactor_LMM_2024-07-26.RData")

bfs <- bfsObject@bayesFactor
ln_bf_sugar <- 
  bfs["SUGR_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment + Time + WINS.ID + Treatment:Time", 1]  - 
  bfs["SUGR_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment + Time + WINS.ID", 1]


bf_sugar <- exp(ln_bf_sugar)
#bf_sugar


bfs2 <- bfsObject2@bayesFactor
ln_bf_add_sugar <- 
  bfs2["ADD_SUGARS_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment + Time + WINS.ID + Treatment:Time", 1] -
  bfs2["ADD_SUGARS_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment + Time + WINS.ID", 1]

bf_add_sugar <- exp(ln_bf_add_sugar)
#bf_add_sugar

bt_names <- c("Total sugars", "Added sugars")
bt_values <- c(round(bf_sugar, digits=3), round(bf_add_sugar, digits=3))
bayestableLMM <- data.frame(bt_names, bt_values)
names(bayestableLMM) <- c("Outcomes", "Bayes Factor")
print(bayestableLMM)


#second way of doing this (slightly different numbers but way faster)
sugar_bf_int <- lmBF(SUGR_ave ~ SUGR_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment + Time + Treatment*Time + WINS.ID,
                           whichRandom = c('WINS.ID'), data = df_long_sugar)
sugar_bf_main <- lmBF(SUGR_ave ~ SUGR_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment + Time + WINS.ID,
                           whichRandom = c('WINS.ID'), data = df_long_sugar)
sugar_bf_int/sugar_bf_main

addsugar_bf_int <- lmBF(ADD_SUGARS_ave ~ ADD_SUGARS_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment + Time + Treatment*Time + WINS.ID,
                           whichRandom = c('WINS.ID'), data = df_long_add_sugar)
addsugar_bf_main <- lmBF(ADD_SUGARS_ave ~ ADD_SUGARS_ave_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment + Time + WINS.ID,
                           whichRandom = c('WINS.ID'), data = df_long_add_sugar)
addsugar_bf_int/addsugar_bf_main


```
 
Bayes Factor here is the ratio of the full model (covariates, treatment, time plus treatment*time interaction) divided by the covariate-only model (covariates, treatment, time): both Bayes factors are between 0.1 and 0.33 and thus there is moderate evidence for the model without the treatment by time interaction.


 
## Bootstrap

In the case that model assumptions may not be satisfied for all models, we performed a non-parametric median bootstrap method described by Wilcox (Wilcox 2023). Note that these analyses don't include covariates so may not be as powerful as the ANCOVA or LMM.
 
```{r, eval = FALSE}
# Adapted from WINS_Sensitivity_Bootstrap_2024-03-06.R Code:
# Thank you to Xiwei Chen for this analysis!

library(openxlsx)
library(dplyr)
library(janitor)
library(stringr)
library(kableExtra)
library(foreach); library(doParallel)

`%notin%` <- Negate(`%in%`)

###############
## Load Data ##
###############

imputed_long_1 <- read.csv("../Data/11 MI Runs - February/DQ 1 MI/imputed_39_long_by_Trt_DQ1_2024-02-19.csv")
imputed_long_2 <- read.csv("../Data/11 MI Runs - February/DQ 2 MI/imputed_41_long_by_Trt_DQ2_2024-02-20.csv") 
imputed_long_3 <- read.csv("../Data/11 MI Runs - February/WL MI/imputed_38_long_by_Trt_WL_2024-02-20.csv") 
imputed_long_4 <- read.csv("../Data/May MI Runs/Behavioral 1 MI/imputed_35_long_by_Trt_B1_2024-05-26.csv") 
imputed_long_5 <- read.csv("../Data/11 MI Runs - February/Behavioral 2 MI/imputed_57_long_by_Trt_B2_2024-02-20.csv") 
imputed_long_6 <- read.csv("../Data/11 MI Runs - February/Behavioral 3 MI/imputed_187_long_by_Trt_B3_2024-02-20.csv")


###############
## Treatment ##
###############

imputed_long_1$Treatment <- relevel(factor(imputed_long_1$Treatment, levels = c(1,2), labels = c("Weight Watchers", "Control")), ref = "Weight Watchers")
imputed_long_2$Treatment <- relevel(factor(imputed_long_2$Treatment, levels = c(1,2), labels = c("Weight Watchers", "Control")), ref = "Weight Watchers")
imputed_long_3$Treatment <- relevel(factor(imputed_long_3$Treatment, levels = c(1,2), labels = c("Weight Watchers", "Control")), ref = "Weight Watchers")
imputed_long_4$Treatment <- relevel(factor(imputed_long_4$Treatment, levels = c(1,2), labels = c("Weight Watchers", "Control")), ref = "Weight Watchers")
imputed_long_5$Treatment <- relevel(factor(imputed_long_5$Treatment, levels = c(1,2), labels = c("Weight Watchers", "Control")), ref = "Weight Watchers")
imputed_long_6$Treatment <- relevel(factor(imputed_long_6$Treatment, levels = c(1,2), labels = c("Weight Watchers", "Control")), ref = "Weight Watchers")


##############
## Outcomes ##
##############

yvars_1 = colnames(imputed_long_1 %>% select(ends_with("_change")))
yvars_2 = colnames(imputed_long_2 %>% select(ends_with("_change")))
yvars_3 = colnames(imputed_long_3 %>% select(ends_with("_change"),"changekg_percent_body_wt"))
yvars_4 = colnames(imputed_long_4 %>% select(ends_with("_change")))
yvars_5 = colnames(imputed_long_5 %>% select(ends_with("_change")))
yvars_6 = colnames(imputed_long_6 %>% select(ends_with("_change")))


###############
## Bootstrap ##
###############

# Setup parallel backend to use many processors
# cores = detectCores()
cl = makeCluster(28) ##not to overload your computer cores[1]-1
registerDoParallel(cl)

result_1 = 
  foreach(i = 1:length(unique(imputed_long_1$.imp)), .errorhandling = "remove", .combine='rbind') %dopar% {
    library(dplyr); library(janitor); library(stringr)
    
    set.seed(1234)
    
    imputed_data = imputed_long_1 %>% filter(.imp == i)
    
    OUT.median = NULL
    for (j in 1:10000){
      id_boot_trt = sample(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"]), 
                           length(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"])), 
                           replace = TRUE)
      id_boot_ctrl = sample(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"]), 
                            length(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"])), 
                            replace = TRUE)
      id_boot = data.frame(WINS.ID = c(id_boot_trt, id_boot_ctrl))
      df = merge(id_boot, imputed_data, by = "WINS.ID")
      
      out = df %>%
        group_by(Treatment) %>%
        summarise_at(vars(yvars_1), median, na.rm = TRUE) %>%
        t %>% ##Transpose
        as.data.frame() %>% 
        row_to_names(1) %>% ##First row to be column name
        mutate_at(c("Weight Watchers", "Control"), as.numeric) %>%
        mutate(Outcome = row.names(.), 
               Diff = `Weight Watchers` - Control,
               iter = j) %>%
        select(iter, Outcome, `Weight Watchers`, Control, Diff)
      OUT.median = rbind(OUT.median, out)
    }
    
    out = OUT.median %>%
      group_by(Outcome) %>%
      summarise_at(vars(c("Weight Watchers", "Control", "Diff")), list(mean = mean, sd = sd), na.rm = TRUE) %>%
      mutate(.imp = i) %>%
      select(.imp, Outcome, `Weight Watchers_mean`, `Weight Watchers_sd`, Control_mean, Control_sd, Diff_mean, Diff_sd)
    
    out
  }

result_2 = 
  foreach(i = 1:length(unique(imputed_long_2$.imp)), .errorhandling = "remove", .combine='rbind') %dopar% {
    library(dplyr); library(janitor); library(stringr)
    
    set.seed(1234)
    
    imputed_data = imputed_long_2 %>% filter(.imp == i)
    
    OUT.median = NULL
    for (j in 1:10000){
      id_boot_trt = sample(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"]), 
                           length(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"])), 
                           replace = TRUE)
      id_boot_ctrl = sample(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"]), 
                            length(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"])), 
                            replace = TRUE)
      id_boot = data.frame(WINS.ID = c(id_boot_trt, id_boot_ctrl))
      df = merge(id_boot, imputed_data, by = "WINS.ID")
      
      out = df %>%
        group_by(Treatment) %>%
        summarise_at(vars(yvars_2), median, na.rm = TRUE) %>%
        t %>% ##Transpose
        as.data.frame() %>% 
        row_to_names(1) %>% ##First row to be column name
        mutate_at(c("Weight Watchers", "Control"), as.numeric) %>%
        mutate(Outcome = row.names(.), 
               Diff = `Weight Watchers` - Control,
               iter = j) %>%
        select(iter, Outcome, `Weight Watchers`, Control, Diff)
      OUT.median = rbind(OUT.median, out)
    }
    
    out = OUT.median %>%
      group_by(Outcome) %>%
      summarise_at(vars(c("Weight Watchers", "Control", "Diff")), list(mean = mean, sd = sd), na.rm = TRUE) %>%
      mutate(.imp = i) %>%
      select(.imp, Outcome, `Weight Watchers_mean`, `Weight Watchers_sd`, Control_mean, Control_sd, Diff_mean, Diff_sd)
    
    out
  }

result_3 = 
  foreach(i = 1:length(unique(imputed_long_3$.imp)), .errorhandling = "remove", .combine='rbind') %dopar% {
    library(dplyr); library(janitor); library(stringr)
    
    set.seed(1234)
    
    imputed_data = imputed_long_3 %>% filter(.imp == i)
    
    OUT.median = NULL
    for (j in 1:10000){
      id_boot_trt = sample(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"]), 
                           length(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"])), 
                           replace = TRUE)
      id_boot_ctrl = sample(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"]), 
                            length(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"])), 
                            replace = TRUE)
      id_boot = data.frame(WINS.ID = c(id_boot_trt, id_boot_ctrl))
      df = merge(id_boot, imputed_data, by = "WINS.ID")
      
      out = df %>%
        group_by(Treatment) %>%
        summarise_at(vars(yvars_3), median, na.rm = TRUE) %>%
        t %>% ##Transpose
        as.data.frame() %>% 
        row_to_names(1) %>% ##First row to be column name
        mutate_at(c("Weight Watchers", "Control"), as.numeric) %>%
        mutate(Outcome = row.names(.), 
               Diff = `Weight Watchers` - Control,
               iter = j) %>%
        select(iter, Outcome, `Weight Watchers`, Control, Diff)
      OUT.median = rbind(OUT.median, out)
    }
    
    out = OUT.median %>%
      group_by(Outcome) %>%
      summarise_at(vars(c("Weight Watchers", "Control", "Diff")), list(mean = mean, sd = sd), na.rm = TRUE) %>%
      mutate(.imp = i) %>%
      select(.imp, Outcome, `Weight Watchers_mean`, `Weight Watchers_sd`, Control_mean, Control_sd, Diff_mean, Diff_sd)
    
    out
  }

result_4 = 
  foreach(i = 1:length(unique(imputed_long_4$.imp)), .errorhandling = "remove", .combine='rbind') %dopar% {
    library(dplyr); library(janitor); library(stringr)
    
    set.seed(1234)
    
    imputed_data = imputed_long_4 %>% filter(.imp == i)
    
    OUT.median = NULL
    for (j in 1:10000){
      id_boot_trt = sample(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"]), 
                           length(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"])), 
                           replace = TRUE)
      id_boot_ctrl = sample(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"]), 
                            length(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"])), 
                            replace = TRUE)
      id_boot = data.frame(WINS.ID = c(id_boot_trt, id_boot_ctrl))
      df = merge(id_boot, imputed_data, by = "WINS.ID")
      
      out = df %>%
        group_by(Treatment) %>%
        summarise_at(vars(yvars_4), median, na.rm = TRUE) %>%
        t %>% ##Transpose
        as.data.frame() %>% 
        row_to_names(1) %>% ##First row to be column name
        mutate_at(c("Weight Watchers", "Control"), as.numeric) %>%
        mutate(Outcome = row.names(.), 
               Diff = `Weight Watchers` - Control,
               iter = j) %>%
        select(iter, Outcome, `Weight Watchers`, Control, Diff)
      OUT.median = rbind(OUT.median, out)
    }
    
    out = OUT.median %>%
      group_by(Outcome) %>%
      summarise_at(vars(c("Weight Watchers", "Control", "Diff")), list(mean = mean, sd = sd), na.rm = TRUE) %>%
      mutate(.imp = i) %>%
      select(.imp, Outcome, `Weight Watchers_mean`, `Weight Watchers_sd`, Control_mean, Control_sd, Diff_mean, Diff_sd)
    
    out
  }

result_5 = 
  foreach(i = 1:length(unique(imputed_long_5$.imp)), .errorhandling = "remove", .combine='rbind') %dopar% {
    library(dplyr); library(janitor); library(stringr)
    
    set.seed(1234)
    
    imputed_data = imputed_long_5 %>% filter(.imp == i)
    
    OUT.median = NULL
    for (j in 1:10000){
      id_boot_trt = sample(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"]), 
                           length(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"])), 
                           replace = TRUE)
      id_boot_ctrl = sample(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"]), 
                            length(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"])), 
                            replace = TRUE)
      id_boot = data.frame(WINS.ID = c(id_boot_trt, id_boot_ctrl))
      df = merge(id_boot, imputed_data, by = "WINS.ID")
      
      out = df %>%
        group_by(Treatment) %>%
        summarise_at(vars(yvars_5), median, na.rm = TRUE) %>%
        t %>% ##Transpose
        as.data.frame() %>% 
        row_to_names(1) %>% ##First row to be column name
        mutate_at(c("Weight Watchers", "Control"), as.numeric) %>%
        mutate(Outcome = row.names(.), 
               Diff = `Weight Watchers` - Control,
               iter = j) %>%
        select(iter, Outcome, `Weight Watchers`, Control, Diff)
      OUT.median = rbind(OUT.median, out)
    }
    
    out = OUT.median %>%
      group_by(Outcome) %>%
      summarise_at(vars(c("Weight Watchers", "Control", "Diff")), list(mean = mean, sd = sd), na.rm = TRUE) %>%
      mutate(.imp = i) %>%
      select(.imp, Outcome, `Weight Watchers_mean`, `Weight Watchers_sd`, Control_mean, Control_sd, Diff_mean, Diff_sd)
    
    out
  }

result_6 = 
  foreach(i = 1:length(unique(imputed_long_6$.imp)), .errorhandling = "remove", .combine='rbind') %dopar% {
    library(dplyr); library(janitor); library(stringr)
    
    set.seed(1234)
    
    imputed_data = imputed_long_6 %>% filter(.imp == i)
    
    OUT.median = NULL
    for (j in 1:10000){
      id_boot_trt = sample(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"]), 
                           length(unique(imputed_data[imputed_data$Treatment == "Weight Watchers", "WINS.ID"])), 
                           replace = TRUE)
      id_boot_ctrl = sample(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"]), 
                            length(unique(imputed_data[imputed_data$Treatment == "Control", "WINS.ID"])), 
                            replace = TRUE)
      id_boot = data.frame(WINS.ID = c(id_boot_trt, id_boot_ctrl))
      df = merge(id_boot, imputed_data, by = "WINS.ID")
      
      out = df %>%
        group_by(Treatment) %>%
        summarise_at(vars(yvars_6), median, na.rm = TRUE) %>%
        t %>% ##Transpose
        as.data.frame() %>% 
        row_to_names(1) %>% ##First row to be column name
        mutate_at(c("Weight Watchers", "Control"), as.numeric) %>%
        mutate(Outcome = row.names(.), 
               Diff = `Weight Watchers` - Control,
               iter = j) %>%
        select(iter, Outcome, `Weight Watchers`, Control, Diff)
      OUT.median = rbind(OUT.median, out)
    }
    
    out = OUT.median %>%
      group_by(Outcome) %>%
      summarise_at(vars(c("Weight Watchers", "Control", "Diff")), list(mean = mean, sd = sd), na.rm = TRUE) %>%
      mutate(.imp = i) %>%
      select(.imp, Outcome, `Weight Watchers_mean`, `Weight Watchers_sd`, Control_mean, Control_sd, Diff_mean, Diff_sd)
    
    out
  }

# Stop cluster
stopCluster(cl)


# Save output
result = rbind(result_1,result_2,result_3,result_4,result_5,result_6) %>% arrange(Outcome, .imp)
write.csv(result, "../Output/WINS_Sensitivity_Bootstrap_2024-03-06.csv", row.names = FALSE)
```

```{r}
# WINS_Sensitivity_Bootstrap_Tables Code:

###############
## Load Data ##
###############

bootstrap_df <- read.csv("../Output/WINS_Sensitivity_Bootstrap_2024-06-07.csv")


#######################
## Homemade Function ##
#######################

Mult_Imp_Template <- function(Means, SEs, m){
  Group <- data.frame(Imputation = 1:m,
                              Mean = Means,
                              SE = SEs)
  Group$Var = Group$SE * Group$SE
  
  mean_Qbar = colMeans(Group[,-1])
  
  variance_B = c(var(Group$Mean), sqrt(var(Group$Mean)))
  
  total_var_T = mean_Qbar[3] + (1+(1/m)) * variance_B[1]
  
  SE_sqrtT = sqrt(total_var_T)
  
  test_stat_t = abs(mean_Qbar[1] / sqrt(total_var_T))
  
  df = (m-1)*(1+(m*mean_Qbar[3])/((m+1)*variance_B[1]))^2
  
  p.value = pt(-abs(test_stat_t), df)*2
  
  tab <- data.frame(Imputation = c(1:m, "mean (Qbar)", "", "variance (B)", "m=", 
                                   "Total Var (T)", "SE = sqrt(T)", "test stat (t)",
                                   "df", "", "p-value"),
                    Mean = c(Means, 
                             round(mean_Qbar[1], 2), "", round(variance_B[1],2), m, 
                             round(total_var_T, 2), 
                             round(SE_sqrtT, 2), 
                             round(test_stat_t, 2), 
                             round(df, 2), "", 
                             round(p.value, 2)),
                    SE = c(SEs,
                           round(mean_Qbar[2], 2),
                           "", round(variance_B[2],2), "", "=Ubar+(1+1/M)*B", 
                           rep("", 5)),
                    Var = c(Group$Var, 
                            round(mean_Qbar[3], 2), "=Ubar", rep("", 8))
  )
return(tab)
}

Mult_Imp_row <- function(Means, SEs, m){
  Group <- data.frame(Imputation = 1:m,
                              Mean = Means,
                              SE = SEs)
  Group$Var = Group$SE * Group$SE
  
  mean_Qbar = colMeans(Group[,-1])
  
  variance_B = c(var(Group$Mean), sqrt(var(Group$Mean)))
  
  total_var_T = mean_Qbar[3] + (1+(1/m)) * variance_B[1]
  
  SE_sqrtT = sqrt(total_var_T)
  
  test_stat_t = abs(mean_Qbar[1] / sqrt(total_var_T))
  names(test_stat_t) <- "test_stat_t"
  
  df = (m-1)*(1+(m*mean_Qbar[3])/((m+1)*variance_B[1]))^2
  names(df) <- "df"
  
  p.value = pt(-abs(test_stat_t), df)*2
  names(p.value) <- "p_value"
  
  row <- c(mean_Qbar[1:2], test_stat_t, df, p.value)
  
return(row)
}


## different outcomes in main outcome paper vs bootstrap results
#######################################################################
# setdiff(unique(bootstrap_df$Outcome), outcomes)
# setdiff(outcomes, unique(bootstrap_df$Outcome))
# remove 3 acheive from here outcome_pairs
bootstrap_pairs <- outcome_pairs %>% subset(outcomes %in% setdiff(outcome_pairs$outcome, setdiff(outcomes, unique(bootstrap_df$Outcome))))
bootstrap_outcomes <- bootstrap_pairs$outcome
#remove 2 extra from bootstrap_df
bootstrap_df <- bootstrap_df %>% subset(Outcome %in% bootstrap_outcomes)

# indices:
# 1:15, 16:24, 25:30, 31:34, 35:37, 38:52

# make output shell table to save results for each outcome in the analysis loop
cols <- c("Outcome", "Outcome_label", "Mean1", "SE1", "Mean2", "SE2", "Mean_Diff",
          "SE_Diff", "t", "df", "p_value")
output = matrix(nrow = length(bootstrap_outcomes), ncol = length(cols))
colnames(output) = cols

# save unrounded for primary comparison
output_raw <- output

```

Wilcox median bootstrap method results for outcomes in WINS main outcomes paper, excluding 3 binary percent weight loss achieved outcomes. 

### Results 

```{r}
# Putting bootstrap results through MI template

for (out in bootstrap_outcomes){
  # Mult_Imp_Template <- function(Means, SEs, m)
  
  data_df <- subset(bootstrap_df, Outcome == out)
  iters <- max(data_df$.imp)
  
  # Treatment Group:
  tab_trt <- formatC(Mult_Imp_row(data_df$Weight.Watchers_mean, data_df$Weight.Watchers_sd, iters)[1:2], digits = 2, format = "f") 
  # round(Mult_Imp_row(data_df$Weight.Watchers_mean, 
  #                    data_df$Weight.Watchers_sd, iters)[1:2],2)
  
  # Control Group:
  tab_control <- formatC(Mult_Imp_row(data_df$Control_mean, data_df$Control_sd, iters)[1:2], digits = 2, format = "f")
    # round(Mult_Imp_row(data_df$Control_mean,
    #                    data_df$Control_sd, iters)[1:2],2)
  
  # Difference:
  tab_diff <- Mult_Imp_row(data_df$Diff_mean,
                           data_df$Diff_sd, iters)
  tab_diff[1:4] <- formatC(tab_diff[1:4], digits = 2, format = "f") #round(tab_diff[1:4], 2)
  tab_diff[5] <- case_when(as.numeric(tab_diff[5]) < 0.001 ~ format.pval(as.numeric(tab_diff[5]), eps = 0.001, digits = 3, nsmall=3),
                        TRUE ~ formatC(as.numeric(tab_diff[5]), digits = 3, format = "f"))
    #round(tab_diff[5], 3)
  
  index = which(out == bootstrap_pairs$outcome)
  output[index, 1] = bootstrap_pairs[which(out == bootstrap_pairs$outcome),1]
  output[index, 2] = bootstrap_pairs[which(out == bootstrap_pairs$outcome),2]
  output[index, 3:4] = c(tab_trt)
  output[index, 5:6] = tab_control
  output[index, 7:11] = tab_diff
  
  output_raw[index, 1] = bootstrap_pairs[which(out == bootstrap_pairs$outcome),1]
  output_raw[index, 2] = bootstrap_pairs[which(out == bootstrap_pairs$outcome),2]
  output_raw[index, 3:4] = c(Mult_Imp_row(data_df$Weight.Watchers_mean, data_df$Weight.Watchers_sd, iters)[1:2])
  output_raw[index, 5:6] = c(Mult_Imp_row(data_df$Control_mean, data_df$Control_sd, iters)[1:2])
  output_raw[index, 7:11] =  Mult_Imp_row(data_df$Diff_mean, data_df$Diff_sd, iters)
}

# for comparison tables later
output_bootstrap <- output_raw
output_bootstrap <- as.data.frame(output_bootstrap)

kable(output, col.names = c("Variable", "Outcome Label", "Mean", "SE", "Mean", "SE", "Mean", "SE", "t", "df", "p-value")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2, "Weight Watchers" = 2,  "Control" = 2, "Difference" = 2, "Model Statistics" = 3)) %>%
    pack_rows(index = c("Change ASA24 in HEI Diet Quality Scores" = 14,
                      "Other Dietary Quality Measures" = 1,
                      "Change in Micro and Macro Nutrients" = 9,
                      "Weight Loss Measures" = 6-3,
                      "Change in Physical Activity" = 4,
                      "Change Self-Reported Sleep" = 3,
                      "Change in Habit Strength" = 15))
```

### Comparison

Let's compare results from the Wilcox bootstrap method with the primary:

```{r}

# merge primary and sensitivity raw p-values:
comparison <- merge(primary_results[,c("Outcome_label", "p_value")], output_raw[,c("Outcome_label", "p_value")], 
                    by = "Outcome_label", suffixes = c(".primary", ".sens"), sort = FALSE)

# make p-values numeric
comparison$p_value.primary = as.numeric(comparison$p_value.primary)
comparison$p_value.sens = as.numeric(comparison$p_value.sens)

comparison <- comparison %>% mutate(
  change = case_when(p_value.primary < 0.05 & p_value.sens < 0.05 ~ "No Change",
                     p_value.primary > 0.05 & p_value.sens > 0.05 ~ "No Change",
                     p_value.primary < 0.05 & p_value.sens > 0.05 ~ "Change",
                     p_value.primary > 0.05 & p_value.sens < 0.05 ~ "Change")
)

table(comparison$change)
```

Note: one outcome (Total Protein Foods) didn't have a Bootstrap p-value so it can't be compared against the Primary analysis. 

`r sum(comparison$change == "No Change", na.rm = TRUE)` of the `r nrow(output_raw)` outcomes did not change in level of significance between the primary and Wilcox Bootstrap sensitivity analysis.

The `r sum(comparison$change == "Change", na.rm = TRUE)` outcomes that did result in a level of significant change are as follows:

```{r}
colnames(comparison) =c("Outcome", "Primary p-value", "Bootstrap p-value", "Change")
comparison[,2:3] = round(comparison[,2:3], 3)

# Display results that changed in significance
comparison.flips <- comparison[which(comparison$Change == "Change"), -4]
comparison.flips$color = 0
comparison.flips$color[comparison.flips$`Primary p-value` < comparison.flips$`Bootstrap p-value`] = 1
rownames(comparison.flips) = NULL
kable(comparison.flips[,-4]) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal()  %>%
  row_spec(which(comparison.flips$color >0), color = "red") %>%
  row_spec(which(comparison.flips$color <1), color = "blue")
```


Outcomes with standardized residuals from the primary analysis showing skewness <-2 or >2 or ratio of variance <0.67 or >1.5 (using means across imputations) are considered potentially problematic, and the Bootstrap analysis  should be considered to better satisfy assumptions. (See Blanca 2018, Casella & Berger 2021, Glass & Hopkins 1996, Glass, Peckham, Sanders 1972).

```{r}

# of all the outcomes, which ones violated model assumptions for the primary models
violators = as.data.frame(outcomes <- rbind(
  # # Dietary quality
  # # Change in ASA24 HEI Diet Quality Scores (Total and Subscores)  1:14
  # c("HEI2015_TOTAL_SCORE_change",  "HEI Total Score"),
  # c("HEI2015C1_TOTALVEG_change", "Total Vegetable"),
  # c("HEI2015C2_GREEN_AND_BEAN_change",  "Greens and Beans"),
  # c("HEI2015C3_TOTALFRUIT_change","Total Fruit"),
  # c("HEI2015C4_WHOLEFRUIT_change", "Whole Fruit"),
  # c("HEI2015C5_WHOLEGRAIN_change", "Whole Grains"),
  # c("HEI2015C6_TOTALDAIRY_change", "Total Dairy"),
  c("HEI2015C7_TOTPROT_change", "Total Protein Foods", "yes (-2.39)", "no"),
  # c("HEI2015C8_SEAPLANT_PROT_change", "Seafood and Plant Proteins"),
  # c("HEI2015C9_FATTYACID_change", "Fatty Acids"),
  # c("HEI2015C10_SODIUM_change", "Sodium"),
  # c("HEI2015C11_REFINEDGRAIN_change", "Refined Grains"),
  # c("HEI2015C12_SFAT_change","Saturated Fats"),
  # c("HEI2015C13_ADDSUG_change","Added Sugars"),
  # # Other Dietary Quality Measures 15:16
  # c("DIETIDHEI_change", "Diet ID Total Score"),
  # c("amed_change", "AMED Score"),
  # # Change in Average Micro and Macro Nutrients Between Endline and Baseline 17:25
  # c("KCAL_ave_change", "Average Total Energy"),
  # c("TFAT_ave_change", "Average Total Fat"),
  # c("CARB_ave_change", "Average Total Carbohydrates"),
  # c("SODI_ave_change", "Average Sodium"),
  # c("SFAT_ave_change", "Average Saturated Fats"),
  # c("SUGR_ave_change", "Average Total Sugars"),
  # c("ADD_SUGARS_ave_change", "Average Added Sugars"),
  # c("CHOLE_ave_change", "Average Total Cholesterol"),
  # c("FIBE_ave_change", "Average Fiber"),
  # # Weight loss
  # # Weight Loss Measures 26:31
  # c("weightkg_change", "Body Weight (kg)"),
  # c("BMI_change", "BMI"),
  # c("changekg_percent_body_wt", "Percent Body Weight Change"),
  # c("achieve_3_percent_wl", "Achieved 3% Weight Loss"),
  # c("achieve_5_percent_wl", "Achieved 5% Weight Loss"),
  # c("achieve_10_percent_wl","Achieved 10% Weight Loss"),
  # # Behavioral
  # # Change in Physical Activity 32:35
  # c("METS_change","Total Physical Activity MET"),
  # c("sendentary_change", "Sedentary"),
  c("moderate_change", "Moderate", "yes (2.29)", "no"),
  c("vigorous_change", "Vigorous", "yes (3.14)", "no"),
  # # Change in Self Reported Sleep 36:38
  # c("sleep_quality_change", "Sleep Quality"),
  # c("sleep_amount_change",  "Usual Sleep Amount"),
  c("wake_episodes_change","Wake Episodes", "yes (2.21)", "no")
  # # Change in Habit Strength (for each behavior assessed, then grouped healthy and unhealthy) 39:53
  # c("SRBAI_change", "SRBAI Habit Strength"),
  # c("Avg1_change", "Considering Portion Sizes"),
  # c("Avg2_change", "Tracking Food Consumption"),
  # c("Avg3_change", "Consider WW Points"),
  # c("Avg4_change", "Frequency of Eating Vegetables"),
  # c("Avg5_change", "Frequency of Weighting Self"),
  # c("Avg6_change", "Frequency of Physical Activity"),
  # c("Avg7_change", "Talking Kindly to Self After Setback"),
  # c("Avg8_change", "Arranging Healthy Foods for Easy Access"),
  # c("Avg9_change", "Frequency of Fried Foods"),
  # c("Avg10_change", "Frequency of Sweets"),
  # c("Avg11_change", "Frequency of Sugary Beverages"),
  # c("Avg12_change", "Snacking When Not Hungry"),
  # c("UnhSRBAI_change", "Unhealthy Grouped"),
  # c("healSRBAI_change","Healthy Grouped")
))

colnames(violators) = c("Outcomes", "Outcome Labels", "Skewness >2", "Ratio of Variance >1.5")
violators_vec <- violators$Outcomes

kable(violators) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% 
  kable_minimal() #%>%
 # add_header_above(c(" " = 2,  "Violations" = 2))


```


Four outcomes (HEI total protein, moderate activity, vigorous activity, and wake episodes) violated primary analysis model assumption criteria (as specified above), but results of significance tests were consistent with the Wilcox median bootstrap method:

```{r}
comparison_short <- subset(comparison, Outcome %in% violators$`Outcome Labels`)[,-4]

rownames(comparison_short) <- NULL

kable(comparison_short, col.names = c("Outcome Label", "Primary p-value", "Bootstrap p-value")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal()

```


Looking back at the outcomes that did switch in significance between the primary and bootstrap results, there are none that violated assumptions and switched significance between the primary and bootstrap results.

 
 
\


## Dropout


Per an AJCN reviewer's request, a sensitivity analysis has been added to address differential loss to follow-up between treatment arms. A logistic model was built using baseline data to predict loss to follow-up (based on variables listed in table below). The resulting predicted log-odds were included as a covariate in the main LMM analysis. Results from this adjusted LMM were then compared to the original to assess differences.



### Tables {.tabset}


Table of candidate covariates, stratified by follow-up status, for the logistic regression model predicting the likelihood of dropout.


```{r}
# Using raw_data, saved as data_tab with nice labels.
follow_up_tab <- data_tab


# pull lost to follow up IDs from a larger data set with variables across
# all the data collection platforms (Diet ID, ASA24, and Qualtrics)
# As some variables not in this analysis (Diet ID) have been redacted from this report.
larger_raw_data <- read.csv("../Data/analytic_raw_data_2024-06-07.csv")
# ^ not necessary and sufficient.

# Step 1: Create Follow-up Status Variable
# Pull all endline variables (those ending in _el)
endline_vars <- grep("_el$", names(larger_raw_data), value = TRUE)

# Create follow-up status: if ALL endline vars are NA = "Lost", else = "Completed"
# and followup_status in the table above coded as 0/1:

larger_raw_data <- larger_raw_data %>%
  mutate(dropout = if_else(rowSums(!is.na(across(all_of(endline_vars)))) == 0, 1, 0),
         followup_status = ifelse(rowSums(!is.na(across(all_of(endline_vars)))) == 0,
                                   "Lost to Follow-up", "Completed"))

follow_up_tab <- follow_up_tab %>% left_join(larger_raw_data %>% 
                                               select(WINS.ID, followup_status, dropout),
                                             by = "WINS.ID") %>%
  # remove duplicates
  select(-c(Race_bcf, Income_bcf, Education_bcf, weight_bl)) 
# check results match consort diagram numbers
# table(follow_up_tab$followup_status)

# Step 2: Create a Combined Grouping Variable
# Create combined group ("Arm_Completed", "Arm_Lost to Follow-up")
follow_up_tab$group <- paste(follow_up_tab$Treatment, follow_up_tab$followup_status, sep = "_")

# Step 3: Select Baseline Variables
# Pull all relevant baseline variables
baseline_vars_all <- grep("^Age_years$|^Sex_bcf$|^Gender_grouped$|^Race|^Ethnicity|^Income|^Education|^foodinsec|_bl$", 
                      names(follow_up_tab), value = TRUE)

# 3b: Define your desired demographic order explicitly
demographic_vars <- c("Age_years", "Sex_bcf", "Gender_grouped", 
                      "Race2_bcf", "Ethnicity_bcf", "Income_grouped",
                      "foodinsec", "Education_grouped")

# Identify the remaining outcome vars (those ending in _bl, but not demographics)
outcome_vars <- setdiff(baseline_vars_all, c(demographic_vars, "amed_bl", "weight_bl"))

# Combine in your desired order
baseline_vars <- c(demographic_vars, outcome_vars)

# Subset data to relevant variables
follow_up_tab <- follow_up_tab[, c("group", baseline_vars, "followup_status", "dropout", "Treatment", "WINS.ID")]

# Pull outcome labels:
outcome_labels <- outcome_pairs
outcome_labels$outcome <- gsub("_change$", "_bl", outcome_labels$outcome)
# add extra:
new_labels <- data.frame(
  outcome = c("Gender_grouped", "Race2_bcf", "Ethnicity_bcf", 
              "Income_grouped", "Education_grouped", "foodinsec", "group"),
  outcome_labels = c("Gender", "Race", "Hispanic, Latinx, or Spanish",
                     "Household Income, USD", "Highest level of education", 
                     "Food insecurity",  "Follow-up Status"),
  stringsAsFactors = FALSE
)

# Append the new labels to the existing outcome_labels data frame
outcome_labels <- rbind(outcome_labels, new_labels)
# Create named list for rename
label_list <- as.list(setNames(outcome_labels$outcome_labels, outcome_labels$outcome))


# rename column headers:
follow_up_tab$group <- factor(follow_up_tab$group, 
                             levels = c("Weight Watchers_Completed",
                                        "Weight Watchers_Lost to Follow-up",
                                        "Control_Completed",
                                        "Control_Lost to Follow-up"),
                             labels = c(
                               "Weight Watchers - Completed",
                               "Weight Watchers - Lost to Follow-up",
                               "Control - Completed",
                               "Control - Lost to Follow-up"
                             ))

```


#### Demographics

```{r}

 follow_up_tab %>%
  select(all_of(demographic_vars), followup_status) %>%
  tbl_summary(by = followup_status,
              #missing = "no",
              statistic = list(all_continuous() ~ "{mean} ({sd})",
                               all_categorical() ~ "{n} ({p}%)"),
              digits = list(Age_years = c(0, 1)),
              percent = "row",
              label = label_list,
              type = all_dichotomous() ~ "categorical") %>%
  add_overall(last = TRUE) %>%
  modify_header(label = "**Baseline Demographics**") %>%
  bold_labels()

```


#### Outcomes

```{r}
follow_up_tab %>%
  select(all_of(outcome_vars), followup_status) %>%
  tbl_summary(by = followup_status, 
              #missing = "no", 
              statistic = list(all_continuous() ~ "{mean} ({sd})",
                               all_categorical() ~ "{n} ({p}%)"),
              type = list(sleep_amount_bl ~ "continuous"),
              digits = list(everything() ~ c(1)),
              label = label_list) %>%
  add_overall(last = TRUE) %>%
  modify_header(label = "**Baseline Outcomes**") %>%
  bold_labels()
```



### Logistic {.tabset}

#### Univariable

Unadjusted model results for all baseline demographic and outcome measures, excluding the four binary weight loss variables, with one model per variable ($dropout = variable$).


```{r, warning=F, message=F}

follow_up_data <- follow_up_tab %>%
  # redo levels so they'll appear in table
  mutate(Race2_bcf = case_when(Race2_bcf == "Black or African-American" ~ "Black",
                               Race2_bcf == "Native Hawaiian or other Pacific Islander, Multiracial, Other or Prefer not to say" ~ "Other", 
                               TRUE ~ Race2_bcf),
         Treatment = case_when(Treatment == "Weight Watchers" ~ "WW", 
                               TRUE ~ Treatment),
         Income_grouped = case_when(Income_grouped == " $59,999 or under" ~ "Low",
                                    Income_grouped == "Between $60,000 and $99,999" ~ "Medium",
                                    Income_grouped == "$100,000 or above" ~ "High"), 
         Education_grouped = case_when(Education_grouped == "Associate degree or below" ~ "Low",
                                       Education_grouped == "Bachelor’s degree and some graduate school" ~ "Medium",
                                       Education_grouped == "Masters or above" ~ "High")
         
  ) %>%
  select(all_of(demographic_vars), all_of(outcome_vars), Treatment, dropout, "WINS.ID")


t_unadjusted <- 
  tbl_uvregression(
    method = glm,
    y = dropout,
    data = follow_up_data %>% select(-c("WINS.ID")),
    method.args = list(family = binomial),
    exponentiate = TRUE, 
    pvalue_fun = ~ style_pvalue(.x, digits = 3), 
    estimate_fun =  ~ style_number(.x, digits = 2),
    label = label_list
  ) 

t_unadjusted %>%
  add_global_p() %>% 
  modify_table_styling(
    column = estimate, 
    rows = !is.na(estimate),
    cols_merge_pattern = "{estimate} ({conf.low})",
    label = "**Estimate (95% CI)**"
  )


```

\

Note: The model for food insecurity does not converge, because there are no instances of food insecurity in the loss to follow-up group, with quite a bit of missingness.

\

Next step is the Multivariable tab. 

\
\


#### Multivariable

For multivariable model building, forward stepwise selection was applied to a binary logistic regression model (dropout = 1 vs. 0), starting with the most significant variable from the univariable models (treatment). Additional variables were sequentially added based on significance until all included predictors were significant and no further variables met the inclusion criterion (p < 0.1). The resulting logistic model was then used to generate predicted log-odds, which served as a covariate in the subsequent linear mixed model (LMM) analysis.


**Forward selection step 1 (only showing most significant set of model results):**

$$Dropout = Treatment + Variable$$

```{r, warning=F, message=F}
# Forward selection setup:

# setup variables:
# save as a new vector so selected variables can be removed from future candidate selections:
candidate.variables <- baseline_vars

# setup model equation:
baseform <- "dropout ~ Treatment"

# vector for pvalues to be saved:
v1 <- c()


# Forward selection step 1:
# forward selection loop across all candidate variables for selection of second variable:
for (var in candidate.variables) {

  df.temp <- filter(follow_up_data, !is.na(follow_up_data[[var]]))

  # Reduced model: base (Treatment only)
  m.reduced <- glm(as.formula(baseform),
                  data = df.temp, 
                  family = binomial(link = "logit"))
  
  # Full model: base + candidate variable  
  m.full <-glm(formula = as.formula(
      paste(baseform,
            var, sep = " + ")),
                  data = df.temp, 
      family = binomial(link = "logit"))

    # Likelihood ratio test
  test <- anova(m.reduced, m.full, test = "LRT")
  p_val <- test$`Pr(>Chi)`[2]  # p-value for added variable
  
  v1 <- c(v1, p_val)
  
}

# Combine into data frame
forward_results <- data.frame(variable = candidate.variables, p_value = v1)

# View top candidates
forward_results <- forward_results %>% arrange(p_value) 

kableExtra::kbl(forward_results[1:5,], col.names = c("Candidate Variable", "P value")) %>% 
  kable_minimal() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) 

selected.var.1 <- head(forward_results, 1)$variable # this is the selected variable

# remove selected variable from list of candidate variables for next step
candidate.variables <- setdiff(candidate.variables, selected.var.1)

# Update complete case data
follow_up_data <- follow_up_data[complete.cases(follow_up_data[,c("dropout",
                                                                  "Treatment",
                                                                  selected.var.1)]),]

# setup model equation:
baseform <- paste("dropout ~ Treatment", selected.var.1, sep = " + ")
```

Since `r selected.var.1` has the the smallest p-value overall, let's add it to the model and proceed. 

The model equation is now: `r baseform`

\

**Forward selection step 2 (only showing most significant set of model results):**

$$Dropout = Treatment + Age + Variable$$

```{r, warning=F, message=F}
# Forward selection step 2 :

# vector for pvalues to be saved:
v1 <- c()

# forward selection loop across all candidate variables for selection of second variable:
for (var in candidate.variables) {

  df.temp <- filter(follow_up_data, !is.na(follow_up_data[[var]]))

  # Reduced model: base (Treatment only)
  m.reduced <- glm(as.formula(baseform),
                  data = df.temp, 
                  family = binomial(link = "logit"))
  
  # Full model: base + candidate variable  
  m.full <-glm(formula = as.formula(
      paste(baseform,
            var, sep = " + ")),
                  data = df.temp, 
      family = binomial(link = "logit"))

    # Likelihood ratio test
  test <- anova(m.reduced, m.full, test = "LRT")
  p_val <- test$`Pr(>Chi)`[2]  # p-value for added variable
  
  v1 <- c(v1, p_val)
  
}

# Combine into data frame
forward_results <- data.frame(variable = candidate.variables, p_value = v1)

# View top candidates
forward_results <- forward_results %>% arrange(p_value) 

kableExtra::kbl(forward_results[1:5,], col.names = c("Candidate Variable", "P value")) %>% 
  kable_minimal() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) 

selected.var.2 <- head(forward_results, 1)$variable # this is the selected variable

# remove selected variable from list of candidate variables
candidate.variables <- setdiff(candidate.variables, selected.var.2)

# Update complete case data
follow_up_data <- follow_up_data[complete.cases(follow_up_data[,c("dropout",
                                                                  "Treatment",
                                                                  selected.var.1,
                                                                  selected.var.2)]),]

# setup model equation:
baseform <- paste("dropout ~ Treatment", selected.var.1,
                  selected.var.2, sep = " + ")
```

Since `r selected.var.2` has the the smallest p-value overall, let's add it to the model and proceed.

The model equation is now: `r baseform`

\

**Forward selection step 3 (only showing most significant set of model results):**

$$Dropout = Treatment + Age + Sex + Variable$$


```{r, warning=F, message=F}
# Forward selection step 3:

# vector for pvalues to be saved:
v1 <- c()

# forward selection loop across all candidate variables for selection of second variable:
for (var in candidate.variables) {

  df.temp <- filter(follow_up_data, !is.na(follow_up_data[[var]]))

  # Reduced model: base (Treatment only)
  m.reduced <- glm(as.formula(baseform),
                  data = df.temp, 
                  family = binomial(link = "logit"))
  
  # Full model: base + candidate variable  
  m.full <-glm(formula = as.formula(
      paste(baseform,
            var, sep = " + ")),
                  data = df.temp, 
      family = binomial(link = "logit"))

    # Likelihood ratio test
  test <- anova(m.reduced, m.full, test = "LRT")
  p_val <- test$`Pr(>Chi)`[2]  # p-value for added variable
  
  v1 <- c(v1, p_val)
  
}

# Combine into data frame
forward_results <- data.frame(variable = candidate.variables, p_value = v1)

# View top candidates
forward_results <- forward_results %>% arrange(p_value) 

kableExtra::kbl(forward_results[1:5,], col.names = c("Candidate Variable", "P value")) %>% 
  kable_minimal() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) 

selected.var.3 <- head(forward_results, 1)$variable # this is the selected variable

# remove previously selected variable from list of candidate variables
candidate.variables <- setdiff(candidate.variables, selected.var.3)

# Update complete case data
follow_up_data <- follow_up_data[complete.cases(follow_up_data[,c("dropout",
                                                                  "Treatment",
                                                                  selected.var.1,
                                                                  selected.var.2,
                                                                  selected.var.3)]),]

# setup model equation:
baseform <- paste("dropout ~ Treatment", selected.var.1,
                  selected.var.2, selected.var.3, sep = " + ")
```

Since `r selected.var.3` has the the smallest p-value overall, let's add it to the model and proceed.

The model equation is now: `r baseform`

\

**Forward selection step 4 (only showing most significant set of model results):**

$$Dropout = Treatment + Age + Sex + Average \space Saturated \space Fats + Variable$$

```{r, warning=F, message=F}
# Forward selection step 4:

# vector for pvalues to be saved:
v1 <- c()

# forward selection loop across all candidate variables for selection of second variable:
for (var in candidate.variables) {

  df.temp <- filter(follow_up_data, !is.na(follow_up_data[[var]]))

  # Reduced model: base (Treatment only)
  m.reduced <- glm(as.formula(baseform),
                  data = df.temp, 
                  family = binomial(link = "logit"))
  
  # Full model: base + candidate variable  
  m.full <-glm(formula = as.formula(
      paste(baseform,
            var, sep = " + ")),
                  data = df.temp, 
      family = binomial(link = "logit"))

    # Likelihood ratio test
  test <- anova(m.reduced, m.full, test = "LRT")
  p_val <- test$`Pr(>Chi)`[2]  # p-value for added variable
  
  v1 <- c(v1, p_val)
  
}

# Combine into data frame
forward_results <- data.frame(variable = candidate.variables, p_value = v1)

# View top candidates
forward_results <- forward_results %>% arrange(p_value) 

kableExtra::kbl(forward_results[1:5,], col.names = c("Candidate Variable", "P value")) %>% 
  kable_minimal() %>%
  kable_styling(bootstrap_options = "striped", full_width = F) 

selected.var.4 <- head(forward_results, 1)$variable # this is the selected variable

# variables no longer statistically significant and worthwhile for the model
# # remove previously selected variable from list of candidate variables
# candidate.variables <- setdiff(candidate.variables, selected.var.4)
# 
# # Update complete case data
# follow_up_data <- follow_up_data[complete.cases(follow_up_data[,c("dropout",
#                                                                   "Treatment",
#                                                                   selected.var.1,
#                                                                   selected.var.2,
#                                                                   selected.var.3,
#                                                                   selected.var.4)]),]
# 
# # setup model equation:
# baseform <- paste("dropout ~ Treatment", selected.var.1,
#                   selected.var.2, selected.var.3, selected.var.4, sep = " + ")
```

At the fourth iteration in the forward selection process, no variables have p<0.1 to add to the model. Let's check the final model and ensure all variables selected remain statistically significant. 

$$
Dropout = Treatment + Age + Sex + Saturated \space fats
$$


**Final Logistic Model**

```{r}
  
# Fit logistic regression model
dropout_model <- glm(as.formula(baseform),
                     data = follow_up_data, 
                     family = binomial(link = "logit"))
# family = binomial(link = "logit") is equivalent to family = binomial

# View summary of the model
# summary(dropout_model)


tbl_regression(dropout_model,
    exponentiate = TRUE,
    pvalue_fun = ~ style_pvalue(.x, digits = 3),
    estimate_fun =  ~ style_number(.x, digits = 2),
    #label = label_list
  ) %>%
  add_global_p() %>%
  modify_table_styling(
    column = estimate,
    rows = !is.na(estimate),
    cols_merge_pattern = "{estimate} ({conf.low})",
    label = "**Estimate (95% CI)**"
  )

# Get predicted probabilities or log-odds
follow_up_data$predicted_log_odds <- predict(dropout_model, type = "link")     # log-odds
follow_up_data$predicted_probabilities <- predict(dropout_model, type = "response")  # probabilities
#likelihood_dropout

```


```{r, eval = F, echo = F, include = F}
# predicted probabilities or predicted log odds?



# predicted_log_odds

hist(follow_up_data$predicted_log_odds)

temp <- merge(follow_up_data, 
              raw_data[,c("WINS.ID", "HEI2015_TOTAL_SCORE_el")], 
              by = "WINS.ID")

ggplot(temp, aes(x = predicted_log_odds, y = HEI2015_TOTAL_SCORE_bl)) +
  geom_point(alpha = 0.6, color = "darkblue") +  # scatterplot
  geom_smooth(method = "loess", se = FALSE, color = "forestgreen", size = 1.2) +  # loess line
  geom_smooth(method = "lm", se = FALSE, color = "firebrick", linetype = "dashed", size = 1.2) + # linear regression
  theme_minimal()

ggplot(temp, aes(x = predicted_log_odds, y = HEI2015_TOTAL_SCORE_el)) +
  geom_point(alpha = 0.6, color = "darkblue") +  # scatterplot
  geom_smooth(method = "loess", se = FALSE, color = "forestgreen", size = 1.2) +  # loess line
  geom_smooth(method = "lm", se = FALSE, color = "firebrick", linetype = "dashed", size = 1.2) +  # linear regression
  theme_minimal()




#predicted_probabilities

hist(follow_up_data$predicted_probabilities)

ggplot(temp, aes(x = predicted_probabilities, y = HEI2015_TOTAL_SCORE_bl)) +
  geom_point(alpha = 0.6, color = "darkblue") +  # scatterplot
  geom_smooth(method = "loess", se = FALSE, color = "forestgreen", size = 1.2) +  # loess line
  geom_smooth(method = "lm", se = FALSE, color = "firebrick", linetype = "dashed", size = 1.2) +  # linear regression
  theme_minimal()

ggplot(temp, aes(x = predicted_probabilities, y = HEI2015_TOTAL_SCORE_el)) +
  geom_point(alpha = 0.6, color = "darkblue") +  # scatterplot
  geom_smooth(method = "loess", se = FALSE, color = "forestgreen", size = 1.2) +  # loess line
  geom_smooth(method = "lm", se = FALSE, color = "firebrick", linetype = "dashed", size = 1.2) +  # linear regression
  theme_minimal()

# Decision: Add log-odds to the subsequent model because they're more spread out and it's what the reviewer requested. 

```



\


We use this model to calculate predicted probabilities and log odds. Log odds are used as a covariate in the LMM model in the next section. 
 
 
$$\text{log-odds} = \text{log} \bigg(\frac{\text{probability}}{1 - \text{probability}} \bigg)$$


 \
 \


### LMM


$$
Original \space score = baseline + Sex + Age + Race + Ethnicity + Education + Dropout \space log \text{-}  odds + \\
Treatment + Time + Treatment:Time + (1|WINS.ID)
$$

```{r}
#######################
## Data prep for LMM ##
#######################

# add predicted log-odds to the data:

temp <- merge(raw_data, 
              follow_up_data[,c("WINS.ID", "predicted_log_odds")],
              by = "WINS.ID")

df.bl <- temp %>%
  dplyr::select(WINS.ID, ends_with("_bl")) %>%
  dplyr::rename_with(~str_remove(., '_bl')) %>%
  dplyr::mutate(Time = "baseline")

df.el <- temp %>%
  dplyr::select(WINS.ID, ends_with("_el")) %>%
  dplyr::rename_with(~str_remove(., '_el')) %>%
  dplyr::mutate(Time = "endline")

df.other <- temp %>% 
  dplyr::select(-c(ends_with("_el")))

df_long <- df.other %>% full_join(dplyr::bind_rows(df.bl, df.el), by = join_by(WINS.ID)) %>%
  arrange(WINS.ID, Time)
```

```{r, message=FALSE, warning=FALSE}

# LMM on continuous outcomes with longitudinal data:
outcomes <- outcome_pairs$outcome
yvars = setdiff(outcomes, c("achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl", "changekg_percent_body_wt"))
output_dropout = NULL
output_dropout_raw = NULL

for (yvar in yvars){
  # Model
  formula = as.formula(paste0(gsub("_change", "", yvar), " ~ ", gsub("_change", "_bl", yvar), 
                              " + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + 
                              Education_grouped + predicted_log_odds +  Treatment*Time + (1|WINS.ID)"))
  mod = lmer(formula, data = df_long)
  
  
  # Estimated means and contrasts
  em = emmeans(mod, revpairwise ~ Time|Treatment)
  contrast = data.frame(em$contrasts)
  did = data.frame(pairs(pairs(emmeans(mod, ~ Time|Treatment), reverse = TRUE), by = NULL))
  did_CI = confint(pairs(pairs(emmeans(mod, ~ Time|Treatment), reverse = TRUE), by = NULL))
  out = data.frame(Outcomes = yvar,
                   group1_mean = round(contrast[contrast$Treatment == "Weight Watchers", "estimate"], 2),
                   group1_se = round(contrast[contrast$Treatment == "Weight Watchers", "SE"], 2),
                   group2_mean = round(contrast[contrast$Treatment == "Control", "estimate"], 2),
                   group2_se = round(contrast[contrast$Treatment == "Control", "SE"], 2),
                   diff_mean = round(did[, "estimate"], 2),
                   diff_CI = paste0("(", sprintf("%.2f", did_CI[, "lower.CL"]), ", ", sprintf("%.2f", did_CI[, "upper.CL"]), ")"),
                   diff_se = round(did[, "SE"], 2),
                   diff_t = round(did[, "t.ratio"], 2),
                   diff_df = round(did[, "df"], 2),
                   diff_p = did[, "p.value"])
  
    out_raw = data.frame(Outcomes = yvar,
                   group1_mean = contrast[contrast$Treatment == "Weight Watchers", "estimate"],
                   group1_se = contrast[contrast$Treatment == "Weight Watchers", "SE"],
                   group2_mean = contrast[contrast$Treatment == "Control", "estimate"],
                   group2_se = contrast[contrast$Treatment == "Control", "SE"],
                   diff_mean = did[, "estimate"],
                   diff_LB = did_CI[, "lower.CL"],
                   diff_UB = did_CI[, "upper.CL"],
                   diff_se = did[, "SE"],
                   diff_t = did[, "t.ratio"],
                   diff_df = did[, "df"],
                   diff_p = did[, "p.value"])
  
  output_dropout = rbind(output_dropout, out)
  
  output_dropout_raw = rbind(output_dropout_raw, out_raw)
  
  # Optionl returns while loop running:
  #print(paste0(yvar, " outcome ", which(yvars == yvar), " of ", length(yvars),"."))
}

output_dropout_saved <- output_dropout

# combine output with labels, select desired columns, and remove _change from outcome names
output_dropout = output_dropout  %>% 
  dplyr::rename("outcome" = "Outcomes") %>% 
  left_join(outcome_pairs, by = "outcome") %>% 
  dplyr::select(1,12,2:11) %>% 
  mutate(outcome = gsub("_change", "", outcome))

output_dropout_raw = output_dropout_raw  %>% 
  dplyr::rename("outcome" = "Outcomes") %>% 
  left_join(outcome_pairs, by = "outcome") %>% 
  dplyr::select(1,13,2:12) %>% 
  mutate(outcome = gsub("_change", "", outcome))

# round to 2 places and keep both places:
non_pvals = c("group1_mean", "group1_se", "group2_mean", "group2_se", 
              "diff_mean", "diff_se", "diff_t", "diff_df")
output_dropout[,non_pvals] = apply(output_dropout[, non_pvals], 2, function(x) sprintf("%.2f", x))

# save for table 3 usage where round p-values differently:
output_dropout2 <- output_dropout

# round p-values to 3 places:
output_dropout2 <- output_dropout2 %>% 
  mutate(
    diff_p = case_when(.data[["diff_p"]] < 0.001 ~ sub(" ", "", format.pval(.data[["diff_p"]], eps = 0.001, digits = 3, nsmall=3)),
                        TRUE ~ formatC(.data[["diff_p"]], digits = 3, format = "f")))

# table of results
kable(output_dropout2,
      col.names = c("Variable", "Outcome", "Mean", "SE", "Mean", "SE", "Mean", "95% CI", "SE", "t", "df", "p-value"),
      caption = "LMM on all people") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 2,  "Weight Watchers" = 2, "Control" = 2, "Difference" = 3, "Model Statistics" = 3)) %>%
  pack_rows(index = c("Change in Dietary Quality Measures (including HEI subscores)" = 15,
                      "Change in Micro and Macro Nutrients" = 9,
                      "Weight Loss Measures" = 6-4,
                      "Change in Physical Activity" = 4,
                      "Change Self-Reported Sleep" = 3,
                      "Change in Habit Strength" = 15)) 


```


Note: there are four weight loss outcomes missing from the LMM Sensitivity analysis because they did not have an endline and baseline measure for longitudinal modeling. 

### Comparison

Comparing main analysis LMMs against the LMM with predicted log-odds for dropout added as a covariate.

```{r}

# let's merge the raw lmm output with the primary output to compare p-values
colnames(output_dropout)[2] = "Outcome_label"
comparison <- merge(output_lmm[,c("Outcome_label", "diff_mean", "diff_p")], 
                    output_dropout[,c("Outcome_label", "diff_mean", "diff_p")],
                    by = "Outcome_label", sort = FALSE, suffixes = c(".LMM",".Dropout"))

# make p-values numeric
comparison$diff_mean.LMM = as.numeric(comparison$diff_mean.LMM)
comparison$diff_mean.Dropout = as.numeric(comparison$diff_mean.Dropout)
comparison$diff_p.LMM = as.numeric(comparison$diff_p.LMM)
comparison$diff_p.Dropout = as.numeric(comparison$diff_p.Dropout)
# add a variable indicating if p-values changed significance level
comparison <- comparison %>%  mutate(
  change = case_when(diff_p.LMM < 0.05 & diff_p.Dropout < 0.05 ~ "No Change",
                     diff_p.LMM > 0.05 & diff_p.Dropout > 0.05 ~ "No Change",
                     diff_p.LMM < 0.05 & diff_p.Dropout > 0.05 ~ "Change",
                     diff_p.LMM > 0.05 & diff_p.Dropout < 0.05 ~ "Change")
)

# format table to display changes
colnames(comparison) =c("Outcome", "LMM Difference", "LMM p-value", "Dropout Difference", "Dropout p-value", "Change")

table(comparison$Change)
```


`r sum(comparison$Change == "No Change")` of the 48 outcomes did not change in level of significance between the main LMM and sensitivity Dropout analysis.

The `r sum(comparison$Change == "Change")` outcomes that did result in a level of significant change are as follows:

```{r}
comparison.flips <- comparison[which(comparison$Change == "Change"), -6]
comparison.flips$color = 0
comparison.flips$color[comparison.flips$`LMM p-value` < comparison.flips$`Dropout p-value`] = 1
rownames(comparison.flips) = NULL

comparison.flips[,2] = formatC(comparison.flips[,2], digits = 3, format = "f")
comparison.flips[,3] = formatC(comparison.flips[,3], digits = 3, format = "f")
comparison.flips[,4] = formatC(comparison.flips[,4], digits = 3, format = "f")
comparison.flips[,5] = formatC(comparison.flips[,5], digits = 3, format = "f")

kable(comparison.flips[,-c(2, 4, 6)]) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal()  %>%
  row_spec(which(comparison.flips$color >0), color = "red") %>%
  row_spec(which(comparison.flips$color <1), color = "blue")
```

\

With the entire list of outcomes below:


```{r}
comparison$color = 0
comparison$color[comparison$Change == "Change"] = 1
rownames(comparison) = NULL

comparison[,2] = formatC(comparison[,2], digits = 3, format = "f")
comparison[,3] = formatC(comparison[,3], digits = 3, format = "f")
comparison[,4] = formatC(comparison[,4], digits = 3, format = "f")
comparison[,5] = formatC(comparison[,5], digits = 3, format = "f")

kable(comparison[,c(1, 2, 4, 3, 5)]) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal()  %>%
  row_spec(which(comparison$color >0), color = "red") %>%
  row_spec(which(comparison$color <1), color = "blue")
```







\
\


# Complete-Case Analysis

Secondary analysis for “completers only” analysis

$$
Outcome = Baseline + Sex + Age + Race + Ethnicity + Education + Treatment 
$$

```{r, message=FALSE, warning=FALSE}

# Thank you to Xiwei Chen for this code:

yvars = outcome_pairs$outcome
output.glm = output.lm = NULL

for (yvar in yvars){
  # Model
  if (yvar %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl")){
    formula = as.formula(paste0(yvar, 
                                " ~ weightkg_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment"))
    mod = glm(formula, data = raw_data, family = "binomial")
  } else if (yvar == "changekg_percent_body_wt"){
    formula = as.formula(paste0(yvar, 
                                " ~ weightkg_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment"))
    mod = lm(formula, data = raw_data)
  } else if (yvar %in% c("FCITotal_change", "FCIFat_change", "FCISweet_change", "FCICarb_change", "FCIFFF_change", "FCIFrVeg_change",
                         "hunger_change", "IWQOL_change", "PhysicalFx_change", "selfesteem_change", "SexualLife_change", 
                         "Publicdistress_change", "work_change", "Selfcomp_change", "human_change", "kindness_change", 
                         "mindfulness_change", "judge_change", "isolation_change", "overident_change", "wellbeing_change",
                         "Perstress_change", "wbis_change", "Selfdev_change", "Distress_change", "PEMS_change", "EDEQ_change",
                         "restraintTFEQ_change", "dishinibitionTFEQ_change", "bodyapp_change")){
    formula = as.formula(paste0(yvar, " ~ ", gsub("_change", "_bl", yvar), 
                                " + BMI_bl + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment"))
    mod = lm(formula, data = raw_data)
  } else {
    formula = as.formula(paste0(yvar, " ~ ", gsub("_change", "_bl", yvar), 
                                " + Sex_bcf + Age_years + Race2_bcf + Ethnicity_bcf + Education_grouped + Treatment"))
    mod = lm(formula, data = raw_data)
  }
  
  # Estimated means and contrasts
  if (yvar %in% c("achieve_3_percent_wl", "achieve_5_percent_wl", "achieve_10_percent_wl")){
    em = emmeans(mod, pairwise ~ Treatment, type = "response")
    emmean = data.frame(em$emmeans); contrast = data.frame(em$contrasts)
    em_CI = confint( pairs(emmeans(em, "Treatment", type = "response")))
    out = data.frame(Outcomes = yvar,
                     n = nrow(mod$model),
                     # group1_prob, group2_prob, diff_or
                     group1_mean = round(emmean[emmean$Treatment == "Weight Watchers", "prob"], 2),
                     group1_se = round(emmean[emmean$Treatment == "Weight Watchers", "SE"], 2),
                     group2_mean = round(emmean[emmean$Treatment == "Control", "prob"], 2),
                     group2_se = round(emmean[emmean$Treatment == "Control", "SE"], 2),
                     diff_mean = round(contrast[, "odds.ratio"], 2),
                     diff_LB = round(em_CI[, "asymp.LCL"], 2),
                     diff_UB = round(em_CI[, "asymp.UCL"], 2),
                     diff_se = round(contrast[, "SE"], 2),
                     diff_stat = round(contrast[, "z.ratio"], 2),
                     diff_df = round(contrast[, "df"], 2),
                     diff_p = contrast[, "p.value"],
                     Cohens_d = NA)
    
    output.glm = rbind(output.glm, out)
  } else {
    em = emmeans(mod, pairwise ~ Treatment)
    emmean = data.frame(em$emmeans); contrast = data.frame(em$contrasts)
    em_CI = confint( pairs(emmeans(em, "Treatment")))
    effect_size = data.frame(eff_size(em$emmeans, sigma = sigma(mod), edf = contrast[, "df"]))
    out = data.frame(Outcomes = yvar,
                     n = nrow(mod$model),
                     group1_mean = round(emmean[emmean$Treatment == "Weight Watchers", "emmean"], 2),
                     group1_se = round(emmean[emmean$Treatment == "Weight Watchers", "SE"], 2),
                     group2_mean = round(emmean[emmean$Treatment == "Control", "emmean"], 2),
                     group2_se = round(emmean[emmean$Treatment == "Control", "SE"], 2),
                     diff_mean = round(contrast[, "estimate"], 2),
                     diff_LB = round(em_CI[, "lower.CL"], 2),
                     diff_UB = round(em_CI[, "upper.CL"], 2),
                     diff_se = round(contrast[, "SE"], 2),
                     diff_stat = round(contrast[, "t.ratio"], 2),
                     diff_df = round(contrast[, "df"], 2),
                     diff_p = contrast[, "p.value"],
                     Cohens_d = round(effect_size[, "effect.size"], 2))
    
    output.lm = rbind(output.lm, out)
  }
}
```

## Model Results


```{r, message=FALSE, warning=FALSE}

# Combine glm and lm results in one table
completers_df <- rbind(output.lm, output.glm)

completers_df = completers_df %>% dplyr::rename("outcome" = "Outcomes") %>% left_join(outcome_pairs, by = "outcome") %>% dplyr::select(1,15,2:14)

# order for labels:
completers_df <- completers_df[match(outcome_pairs$outcome, completers_df$outcome), ]
rownames(completers_df) <- NULL

# format p-values
completers_df2 <- completers_df %>% 
  mutate(
    diff_p = case_when(.data[["diff_p"]] < 0.001 ~ sub(" ", "", format.pval(.data[["diff_p"]], eps = 0.001, digits = 3, nsmall=3)),
                        TRUE ~ formatC(.data[["diff_p"]], digits = 3, format = "f")),
    diff_CI = paste0("(", formatC(diff_LB, digits = 2, format = "f"), ", ", 
                           formatC(diff_UB, digits = 2, format = "f"), ")")
    
  ) %>% select(
     outcome, outcome_labels, n, group1_mean, group1_se, group2_mean, group2_se, 
     diff_mean, diff_CI, diff_se, diff_stat, diff_df, diff_p, Cohens_d
  )

# let's identify 3 binary outcomes
completers_df2$outcome_labels[grep("Achieved", completers_df2$outcome_labels)] = paste0(completers_df2$outcome_labels[grep("Achieved", completers_df2$outcome_labels)], "*")

kable(completers_df2,
      col.names = c("Variable", "Outcome", "N", "Mean", "SE", "Mean", "SE", "Mean" ,"95% CI", "SE", "Statistic", "df", "p-value", "Cohen's d"),
      caption = "ANCOVA on complete-cases") %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  add_header_above(c(" " = 3,  "Weight Watchers" = 2, "Control" = 2, "Difference" = 3, "Model Statistics" = 3, " " = 1)) %>%
  pack_rows(index = c("Change in Dietary Quality Measures (including HEI subscores)" = 15,
                      "Change in Micro and Macro Nutrients" = 9,
                      "Weight Loss Measures" = 6,
                      "Change in Physical Activity" = 4,
                      "Change Self-Reported Sleep" = 3,
                      "Change in Habit Strength" = 15)) 
```

$^*$ These are binary outcomes with probabilities for group means and OR for mean difference.

## Comparison

```{r}
# Compare p-values of raw output, unrounded p-values:
colnames(completers_df)[2] = "Outcome_label"
comparison <- merge(primary_results[,c("Outcome_label", "p_value")], completers_df[,c("Outcome_label", "diff_p")], 
                    by = "Outcome_label", sort = FALSE)

# make p-values numeric
comparison$p_value = as.numeric(comparison$p_value)
comparison$diff_p = as.numeric(comparison$diff_p)

comparison <- comparison %>% mutate(
  change = case_when(p_value < 0.05 & diff_p < 0.05 ~ "No Change",
                     p_value > 0.05 & diff_p > 0.05 ~ "No Change",
                     p_value < 0.05 & diff_p > 0.05 ~ "Change",
                     p_value > 0.05 & diff_p < 0.05 ~ "Change")
)

#table(comparison$change)
colnames(comparison) =c("Outcome", "Primary p-value", "Completers p-value", "Change")
comparison[,2:3] = round(comparison[,2:3], 3)

table(comparison$Change)
```


`r sum(comparison$Change == "No Change")` of the 52 outcomes did not change in level of significance between the primary and complete case sensitivity analysis. 

The `r sum(comparison$Change == "Change")` outcomes that did result in a level of significant change are as follows:

```{r}
# Display results that changed in significance
comparison.flips <- comparison[which(comparison$Change == "Change"), -4]
comparison.flips$color = 0
comparison.flips$color[comparison.flips$`Primary p-value` < comparison.flips$`Completers p-value`] = 1
rownames(comparison.flips) = NULL
kable(comparison.flips[,-4]) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal()  %>%
  row_spec(which(comparison.flips$color >0), color = "red") %>%
  row_spec(which(comparison.flips$color <1), color = "blue")
```


# Comparison Table

A table to compare model results between the primary, secondary complete case analysis, and three sensitivity analysis (outliers removed, LMM, bootstrap).

Let's <span style="color: salmon;">highlight</span> the outcomes where primary p-value<0.05 and completers, outliers, or LMM p-value>0.05 (ignoring the Bootstrap p-values since none of the Bootstrap results that switch significance also violated the primary model assumptions).

We also <span style="color: blue;">highlighted</span> the outcomes where primary p-value>0.05 and at least one of completers, outliers, or LMM p-value<0.05.


```{r}
# Rename some columns for smooth merging:

# primary: primary_results
colnames(primary_results)[which(colnames(primary_results) == "p_value")] = "Primary P-value"

# complete case: completers_df
colnames(completers_df)[which(colnames(completers_df) == "diff_p")] = "Completers P-value"

# outliers removed: output_sens_saved
colnames(output_sens_saved)[which(colnames(output_sens_saved) == "p_value")] = "Outliers P-value"

# LMM: output_lmm_saved
colnames(output_lmm_saved)[which(colnames(output_lmm_saved) == "Outcomes")] = "Outcome"
colnames(output_lmm_saved)[which(colnames(output_lmm_saved) == "diff_p")] = "LMM P-value"

# Bootstrap: output_bootstrap
colnames(output_bootstrap)[which(colnames(output_bootstrap) == "p_value")] = "Bootstrap P-value"


# merging results into one:
comparison <- primary_results[,c("Outcome", "Outcome_label", "Primary P-value")] %>% # 52
  left_join(completers_df[,c("Outcome_label", "Completers P-value")], by = "Outcome_label") %>% # 83
  left_join(output_sens_saved[,c("Outcome_label", "Outliers P-value")], by = "Outcome_label") %>% # 83
  left_join(output_lmm_saved[,c("Outcome", "LMM P-value")], by = "Outcome") %>% # 79
  left_join(output_bootstrap[,c("Outcome_label", "Bootstrap P-value")], by = "Outcome_label") # 50

# format numeric
comparison_num <- comparison
comparison_num[,3:ncol(comparison_num)] = apply(comparison_num[,3:ncol(comparison_num)], 2, as.numeric)


# column names with spacing causing issues in dplyr so let's rename columns:
colnames(comparison_num) = c("Outcome",
                               "Outcome_label",
                               "Primary_pvalue",
                               "Completers_pvalue",
                               "Outliers_pvalue",
                               "LMM_pvalue",
                               "Bootstrap_pvalue")


# remove bootstrap from consideration and color by flips
comparison_num <- comparison_num %>% dplyr::group_by(Outcome) %>%
  dplyr::mutate(color = case_when(
    (Primary_pvalue < 0.05)  &
      max(Completers_pvalue, 
          Outliers_pvalue, 
          LMM_pvalue, na.rm = T) > 0.05 ~ 1,
    TRUE ~ 0
  ))
comparison_num <- comparison_num %>% dplyr::group_by(Outcome) %>%
  dplyr::mutate(color2 = case_when(
    (Primary_pvalue > 0.05)  &
      min(Completers_pvalue, 
          Outliers_pvalue, 
          LMM_pvalue, na.rm = T) < 0.05 ~ 1,
    TRUE ~ 0
  ))
#comparison.flips[,3:7] = round(comparison.flips[,3:7], 3)
comparison_num$Primary_pvalue = case_when(comparison_num$Primary_pvalue < 0.001 ~ sub(" ", "", format.pval(comparison_num$Primary_pvalue, eps = 0.001, digits = 3, nsmall=3)),TRUE ~ formatC(comparison_num$Primary_pvalue, digits = 3, format = "f"))
comparison_num$Completers_pvalue = case_when(comparison_num$Completers_pvalue < 0.001 ~ sub(" ", "", format.pval(comparison_num$Completers_pvalue, eps = 0.001, digits = 3, nsmall=3)),TRUE ~ formatC(comparison_num$Completers_pvalue, digits = 3, format = "f"))
comparison_num$Outliers_pvalue = case_when(comparison_num$Outliers_pvalue < 0.001 ~ sub(" ", "", format.pval(comparison_num$Outliers_pvalue, eps = 0.001, digits = 3, nsmall=3)),TRUE ~ formatC(comparison_num$Outliers_pvalue, digits = 3, format = "f"))
comparison_num$LMM_pvalue = case_when(comparison_num$LMM_pvalue < 0.001 ~ sub(" ", "", format.pval(comparison_num$LMM_pvalue, eps = 0.001, digits = 3, nsmall=3)),TRUE ~ formatC(comparison_num$LMM_pvalue, digits = 3, format = "f"))
comparison_num$Bootstrap_pvalue = case_when(comparison_num$Bootstrap_pvalue < 0.001 ~ sub(" ", "", format.pval(comparison_num$Bootstrap_pvalue, eps = 0.001, digits = 3, nsmall=3)),TRUE ~ formatC(comparison_num$Bootstrap_pvalue, digits = 3, format = "f"))

rownames(comparison_num) = NULL

kable(comparison_num[,-c(8,9)], 
      col.names = c("Variable", "Outcome", "Primary P-value", "Completers P-value", "Outliers P-value", "LMM P-value", "Bootstrap P-value")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% kable_minimal() %>%
  row_spec(which(comparison_num$color >0), color = "salmon") %>%
  row_spec(which(comparison_num$color2 >0), color = "blue") %>%
  pack_rows(index = c("Change ASA24 in HEI Diet Quality Scores" = 14,
                      "Other Dietary Quality Measures" = 1,
                      "Change in Micro and Macro Nutrients" = 9,
                      "Weight Loss Measures" = 6,
                      "Change in Physical Activity" = 4,
                      "Change Self-Reported Sleep" = 3,
                      "Change in Habit Strength" = 15))

```


Footnote: Four outcomes (HEI total protein, moderate activity, vigorous activity, and wake episodes) showed possible concerns for non-normality or unequal variance in the primary analysis model assumptions based on the criteria established above. Out of these four outcomes, results of significance tests between the primary analysis and Wilcox median bootstrap method remained consistent.



# Tables for journal 

These tables exist above in the report, but are rounded to one decimal except p-values that are rounded to three decimals without leading zero and Cohen's D which is rounded to 2 decimals. 

## Table 1 one decimal

```{r}
save_tab1 <- table1(~ Age_years + Sex_bcf + Gender_grouped + Race2_bcf + Ethnicity_bcf + Income_grouped + foodinsec+ Education_grouped + BMI_bl + HEI2015_TOTAL_SCORE_bl | Treatment, data = data_tab,
       render.continuous = for.cont.variables1)

save_tab1
```


## Table 2 one decimal

```{r}
save_tab2 <- datasummary(
  (`HEI Total Score` + 
    `Average Total Energy`+`Average Total Fat`+`Average Total Carbohydrates` +
     `Average Sodium` + `Average Saturated Fats` + `Average Total Sugars` + 
    `Average Added Sugars` +  `Average Total Cholesterol` + `Average Fiber` + 
     `Body Weight (kg)` + `BMI`
   )*Timepoint ~ Treatment * (N + Mean * Arguments(fmt = "%.1f") + SD * Arguments(fmt = "%.1f")),
  data = outcomes_tab_data_wide,
  output = 'data.frame'
)


# remove negative sign in instances of -0.0
save_tab2 <- change_negative_zero(save_tab2)


kable(save_tab2,
      caption = "Table 2") %>% 
  kable_styling()


save_etab2 <- datasummary(
  (  `Total Physical Activity MET`+`Sedentary`+`Moderate`+`Vigorous` +
       
         `Sleep Quality`+`Usual Sleep Amount`+`Wake Episodes`
     +`SRBAI Habit Strength` + `Considering Portion Sizes` + `Tracking Food Consumption`+`Consider WW Points`+
     `Frequency of Eating Vegetables`+`Frequency of Weighing Self`+`Frequency of Physical Activity`+
     `Talking Kindly to Self After Setback`+`Arranging Healthy Foods for Easy Access`+`Frequency of Fried Foods`+
     `Frequency of Sweets`+`Frequency of Sugary Beverages`+ `Snacking When Not Hungry`+`Unhealthy Grouped`+`Healthy Grouped`
   )*Timepoint ~ Treatment * (N + Mean * Arguments(fmt = "%.1f") + SD * Arguments(fmt = "%.1f")),
  data = outcomes_tab_data_wide,
  output = 'data.frame'
)


# remove negative sign in instances of -0.0
save_etab2 <- change_negative_zero(save_etab2)

kable(save_etab2,
      caption = "eTable 2") %>% 
  kable_styling()



```


## Table 3 one decimal


```{r}
# Re-round p-values for journal submission:
output3 <- primary_results

rownames(output3) = NULL
output3[,3:ncol(output3)] = apply(output3[,3:ncol(output3)], 2, as.numeric)

# Combine Mean (SE) and format p-values
table3 <- output3 %>% dplyr::select(Outcome_label, Mean1, SE1, Mean2, SE2, Mean_Diff, SE_Diff, Mean_Diff_LB, Mean_Diff_UB, `Primary P-value`, Cohens_d_unadjusted) %>%
  dplyr::rename(p_value = `Primary P-value`) %>%
  reframe(Outcome = Outcome_label, 
          WW = paste0(formatC(Mean1, digits = 1, format = "f"), " (", formatC(SE1, digits = 1, format = "f"),  ")"),
          Control = paste0(formatC(Mean2, digits = 1, format = "f"), " (", formatC(SE2, digits = 1, format = "f"),  ")"),
          Diff = paste0(formatC(Mean_Diff, digits = 1, format = "f"), " (", formatC(SE_Diff, digits = 1, format = "f"),  ")"),
          Diff_CI = paste0("(", formatC(Mean_Diff_LB, digits = 1, format = "f"), ", ", 
                           formatC(Mean_Diff_UB, digits = 1, format = "f"), ")"),
          p_value_journal = case_when(
            p_value < 0.001 ~ "<.001",
            p_value > 0.001 & p_value < 0.01 ~ leading_zeros(formatC(p_value, digits = 3, format = "f")),
            p_value >= 0.01 ~ leading_zeros(formatC(p_value, digits = 3, format = "f")),
            p_value > 0.99 ~ ">.99"),
          Cohens_d = formatC(Cohens_d_unadjusted, digits = 2, format = "f") 
  )


table3_n <- unique(output3$`Number of Participants`)

# reorder for grouping
table3 <- table3[match(outcome_pairs$outcome_labels, table3$Outcome), ]
rownames(table3) <- NULL

# let's identify 3 binary outcomes
table3$Outcome[grep("Achieved", table3$Outcome)] = paste0(table3$Outcome[grep("Achieved", table3$Outcome)], "*")


# remove negative sign in instances of -0.0
table3 <- change_negative_zero(table3)


# export to excel
save_tab3 <- table3[c(1,16:24,25:30),]
save_tab3$Cohens_d <- formatC(save_tab3$Cohens_d, digits = 2, format = "f") # to preserve digits
colnames(save_tab3) <- c("Outcome", "WW Mean (SE)", "Control Mean (SE)", "Mean Difference (SE)", "95% CI of Mean Difference",  
                    "p-value", "Cohen's d")

rownames(save_tab3) = NULL
kable(save_tab3,
      caption = "Table 3 Analysis Results (ANCOVA with MI, N=376)", 
      col.names = c("Outcome", "WW Mean (SE)", "Control Mean (SE)", "Mean Difference (SE)", "95% CI of Mean Difference",  
                    "p-value", "Cohen's d")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% 
  kable_minimal() 

```

Sample size for the above table is `r table3_n` participants.

```{r}



save_etab3 <- table3[c(2:14,31:34,35:37,38:52),]
colnames(save_etab3) <- c("Outcome", "WW Mean (SE)", "Control Mean (SE)", "Mean Difference (SE)",  "95% CI of Mean Difference",  
                    "p-value", "Cohen's d")
save_etab3 <- rbind(c("Healthy-Eating Index subscales)", "", "", "", "", "", ""),
                   save_etab3[1:13,],
                   c("Change in Physical Activity", "", "", "", "", "", ""),
                   save_etab3[14:17,],
                   c("Change Self-Reported Sleep", "", "", "", "", "", ""),
                   save_etab3[18:20,],
                   c("Change in Habit Strength", "", "", "", "", "", ""),
                   save_etab3[21:35,]
                   )

rownames(save_etab3) = NULL

kable(save_etab3,
      caption = "eTable 3 Analysis Results (ANCOVA with MI)", 
      col.names = c("Outcome", "WW Mean (SE)", "Control Mean (SE)", "Mean Difference (SE)", 
                     "95% CI of Mean Difference",  
                    "p-value", "Cohen's d")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% 
  kable_minimal() 


```

$^*$ These are binary outcomes with probabilities for group means and OR for mean difference.

Sample size for the above table is `r table3_n` participants.

## Complete-Case one decimal

ANCOVA on complete-case data

```{r}

completers_df3 <- completers_df
rownames(completers_df3) = NULL

# Combine Mean (SE) and format p-values
supp1 <- completers_df3 %>% dplyr::select(Outcome_label, n, group1_mean, group1_se, group2_mean, group2_se, diff_mean, diff_se, diff_LB, diff_UB, `Completers P-value`, Cohens_d) %>%
  dplyr::rename(diff_p = `Completers P-value`) %>%
  reframe(Outcome = Outcome_label, 
          N = n,
          WW = paste0(formatC(group1_mean, digits = 1, format = "f"), " (", formatC(group1_se, digits = 1, format = "f"),  ")"),
          Control = paste0(formatC(group2_mean, digits = 1, format = "f"), " (", formatC(group2_se, digits = 1, format = "f"),  ")"),
          Diff = paste0(formatC(diff_mean, digits = 1, format = "f"), " (", formatC(diff_se, digits = 1, format = "f"),  ")"),
          diff_CI = paste0("(", formatC(diff_LB, digits = 1, format = "f"), ", ", 
                           formatC(diff_UB, digits = 1, format = "f"), ")"),
          p_value_journal = case_when(
            diff_p < 0.001 ~ "<.001",
            diff_p > 0.001 & diff_p < 0.01 ~ leading_zeros( formatC(diff_p, digits = 3, format = "f") ),
            diff_p >= 0.01 ~ leading_zeros( formatC(diff_p, digits = 3, format = "f") ),
            diff_p > 0.99 ~ ">.99"),
          Cohens_d = formatC(Cohens_d, digits = 2, format = "f")
  )

# reorder for grouping
supp1 <- supp1[match(outcome_pairs$outcome_labels, supp1$Outcome), ]

# remove negative sign in instances of -0.0
supp1 <- change_negative_zero(supp1)

rownames(supp1) <- NULL

# let's identify 3 binary outcomes
supp1$Outcome[grep("Achieved", supp1$Outcome)] = paste0(supp1$Outcome[grep("Achieved", supp1$Outcome)], "*")


kable(supp1,
      caption = "Supplemental Table: Sensitivity Complete-Case Analysis", 
      col.names = c("Outcome", "N", "WW Mean (SE)", "Control Mean (SE)", "Mean Difference (SE)", 
                    "95% CI of Mean Difference", "p-value", "Cohen's d")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% 
  kable_minimal() %>%
  add_header_above(c(" " = 2,  "Sensitivity Analysis (Complete-Case)" = 6)) %>%
  pack_rows(index = c("Change in Dietary Quality Measures (including HEI subscores)" = 15,
                      "Change in Micro and Macro Nutrients" = 9,
                      "Weight Loss Measures" = 6,
                      "Change in Physical Activity" = 4,
                      "Change Self-Reported Sleep" = 3,
                      "Change in Habit Strength" = 15)) 

# export to excel
save_etab4 <- supp1[-c(15),]
colnames(save_etab4) <- c("Outcome", "N", "WW Mean (SE)", "Control Mean (SE)", "Mean Difference (SE)", 
                    "95% CI of Mean Difference", "p-value", "Cohen's d")
save_etab4 <- rbind(c("Change in Dietary Quality Measures (including HEI subscores)", "","", "", "", "", "", ""),
                   save_etab4[1:14,],
                   c("Change in Micro and Macro Nutrients","", "", "", "", "", "", ""),
                   save_etab4[15:23,],
                   c("Weight Loss Measures","", "", "", "", "", "", ""),
                   save_etab4[24:29,],
                   c("Change in Physical Activity","", "", "", "", "", "", ""),
                   save_etab4[30:33,],
                   c("Change Self-Reported Sleep","", "", "", "", "", "", ""),
                   save_etab4[34:36,],
                   c("Change in Habit Strength","", "", "", "", "", "", ""),
                   save_etab4[37:51,]
                   )


```

$^*$ These are binary outcomes with probabilities for group means and OR for mean difference.






## LMM one decimal

LMM on all study participants.


```{r}

# Combine Mean (SE) and format p-values
table_lmm_one <- output_lmm_raw %>% dplyr::select(outcome_labels, group1_mean, group1_se, group2_mean, group2_se, diff_mean, 
                                                  diff_LB, diff_UB, diff_se, diff_p) %>%
  dplyr::rename(p_value = diff_p) %>%
  reframe(Outcome = outcome_labels, 
          WW = paste0(formatC(group1_mean, digits = 1, format = "f"), " (", 
                      formatC(group1_se, digits = 1, format = "f"),  ")"),
          Control = paste0(formatC(group2_mean, digits = 1, format = "f"), " (", 
                           formatC(group2_se, digits = 1, format = "f"),  ")"),
          Diff = paste0(formatC(diff_mean, digits = 1, format = "f"), " (", 
                        formatC(diff_se, digits = 1, format = "f"),  ")"),
          diff_CI = paste0("(", formatC(diff_LB, digits = 1, format = "f"), ", ", 
                           formatC(diff_UB, digits = 1, format = "f"), ")"),
          p_value_journal = case_when(
            p_value < 0.001 ~ "<.001",
            p_value > 0.001 & p_value < 0.01 ~ leading_zeros(formatC(p_value, digits = 3, format = "f")),
            p_value >= 0.01 ~ leading_zeros(formatC(p_value, digits = 3, format = "f")),
            p_value > 0.99 ~ ">.99")
  )

# reorder for grouping
table_lmm_one <- table_lmm_one[match(setdiff(outcome_pairs$outcome_labels, c("Percent Body Weight Change", "Achieved 3% Weight Loss", "Achieved 5% Weight Loss", "Achieved 10% Weight Loss")), table_lmm_one$Outcome), ]

# remove negative sign in instances of -0.0
table_lmm_one <- change_negative_zero(table_lmm_one)

rownames(table_lmm_one) <- NULL

kable(table_lmm_one,
      caption = "Sensitivity LMM Analysis (N=376)", 
      col.names = c("Outcome", "WW Mean (SE)", "Control Mean (SE)", "Mean Difference (SE)", 
                    "95% CI of Mean Difference", "p-value")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% 
  kable_minimal() %>%
  add_header_above(c(" " = 1,  "Sensitivity Analysis (LMM)" = 5)) %>%
  pack_rows(index = c("Change in Dietary Quality Measures (including HEI subscores)" = 15,
                      "Change in Micro and Macro Nutrients" = 9,
                      "Weight Loss Measures" = 6-4,
                      "Change in Physical Activity" = 4,
                      "Change Self-Reported Sleep" = 3,
                      "Change in Habit Strength" = 15))


# export to excel
save_etab5 <- table_lmm_one[-c(15),]
colnames(save_etab5) <- c("Outcome", "WW Mean (SE)", "Control Mean (SE)", "Mean Difference (SE)", 
                    "95% CI of Mean Difference", "p-value")
save_etab5 <- rbind(c("Change in Dietary Quality Measures (including HEI subscores)", "", "", "", "", ""),
                   save_etab5[1:14,],
                   c("Change in Micro and Macro Nutrients", "", "", "", "", ""),
                   save_etab5[15:23,],
                   c("Weight Loss Measures", "", "", "", "", ""),
                   save_etab5[24:25,],
                   c("Change in Physical Activity", "", "", "", "", ""),
                   save_etab5[26:29,],
                   c("Change Self-Reported Sleep", "", "", "", "", ""),
                   save_etab5[30:32,],
                   c("Change in Habit Strength", "", "", "", "", ""),
                   save_etab5[33:47,]
                   )

```

## Loss to Follow-up

This table exists in response to a reviewer request. 



```{r}

save_etab6 <- follow_up_tab %>%
  select(all_of(demographic_vars), group) %>% 
  table1(~ Age_years + Sex_bcf + Gender_grouped + Race2_bcf + Ethnicity_bcf + Income_grouped + Education_grouped + foodinsec | group, data = .,
       render.continuous = for.cont.variables1)
save_etab6

save_etab7 <- follow_up_tab %>%
  select(all_of(outcome_vars), group) %>%
  tbl_summary(by = group, 
              missing = "no", 
              statistic = list(all_continuous() ~ "{mean} ({sd})",
                               all_categorical() ~ "{n} ({p}%)"),
              type = list(sleep_amount_bl ~ "continuous"),
              digits = list(everything() ~ c(1)),
              label = label_list) %>%
  add_overall(last = TRUE) %>%
  modify_header(label = "**Baseline Outcomes**") %>%
  bold_labels()
save_etab7


save_etab6 <- as.data.frame(save_etab6, stringsAsFactors = FALSE)
rownames(save_etab6) = NULL

save_etab7 <- save_etab7 %>% gtsummary::as_tibble()
rownames(save_etab7) = NULL
# Clean up the column names
colnames(save_etab7) <- gsub("^\\*\\*", "", colnames(save_etab7))
colnames(save_etab7) <- gsub("\\n", "", colnames(save_etab7))
colnames(save_etab7) <- gsub("\\*\\* | \\*\\*|\\*\\*$", "", colnames(save_etab7))
colnames(save_etab7)  <- gsub("N = (\\d+)", "(N = \\1)", colnames(save_etab7))
# Clean up the variable names
save_etab7$`Baseline Outcomes` <- gsub("|__", "", save_etab7$`Baseline Outcomes`)

```




\






## Dropout one decimal 


This table exists in response to a reviewer request. 



```{r}

# Combine Mean (SE) and format p-values
table_dropout_one <- output_lmm_raw %>% dplyr::select(outcome_labels, group1_mean, group1_se, group2_mean, group2_se, diff_mean, 
                                                  diff_LB, diff_UB, diff_se, diff_p) %>%
  dplyr::rename(p_value = diff_p) %>%
  reframe(Outcome = outcome_labels, 
          WW = paste0(formatC(group1_mean, digits = 1, format = "f"), " (", 
                      formatC(group1_se, digits = 1, format = "f"),  ")"),
          Control = paste0(formatC(group2_mean, digits = 1, format = "f"), " (", 
                           formatC(group2_se, digits = 1, format = "f"),  ")"),
          Diff = paste0(formatC(diff_mean, digits = 1, format = "f"), " (", 
                        formatC(diff_se, digits = 1, format = "f"),  ")"),
          diff_CI = paste0("(", formatC(diff_LB, digits = 1, format = "f"), ", ", 
                           formatC(diff_UB, digits = 1, format = "f"), ")"),
          p_value_journal = case_when(
            p_value < 0.001 ~ "<.001",
            p_value > 0.001 & p_value < 0.01 ~ leading_zeros(formatC(p_value, digits = 3, format = "f")),
            p_value >= 0.01 ~ leading_zeros(formatC(p_value, digits = 3, format = "f")),
            p_value > 0.99 ~ ">.99")
  )

# reorder for grouping
table_dropout_one <- table_dropout_one[match(setdiff(outcome_pairs$outcome_labels, c("Percent Body Weight Change", "Achieved 3% Weight Loss", "Achieved 5% Weight Loss", "Achieved 10% Weight Loss")), table_dropout_one$Outcome), ]

# remove negative sign in instances of -0.0
table_dropout_one <- change_negative_zero(table_dropout_one)

rownames(table_dropout_one) <- NULL

kable(table_dropout_one,
      caption = "Sensitivity Dropout Analysis (N=376)", 
      col.names = c("Outcome", "WW Mean (SE)", "Control Mean (SE)", "Mean Difference (SE)", 
                    "95% CI of Mean Difference", "p-value")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>% 
  kable_minimal() %>%
  add_header_above(c(" " = 1,  "Sensitivity Analysis (Dropout LMM)" = 5)) %>%
  pack_rows(index = c("Change in Dietary Quality Measures (including HEI subscores)" = 15,
                      "Change in Micro and Macro Nutrients" = 9,
                      "Weight Loss Measures" = 6-4,
                      "Change in Physical Activity" = 4,
                      "Change Self-Reported Sleep" = 3,
                      "Change in Habit Strength" = 15))


# export to excel
save_etab8 <- table_dropout_one[-c(15),]
colnames(save_etab8) <- c("Outcome", "WW Mean (SE)", "Control Mean (SE)", "Mean Difference (SE)", 
                    "95% CI of Mean Difference", "p-value")
save_etab8 <- rbind(c("Change in Dietary Quality Measures (including HEI subscores)", "", "", "", "", ""),
                   save_etab8[1:14,],
                   c("Change in Micro and Macro Nutrients", "", "", "", "", ""),
                   save_etab8[15:23,],
                   c("Weight Loss Measures", "", "", "", "", ""),
                   save_etab8[24:25,],
                   c("Change in Physical Activity", "", "", "", "", ""),
                   save_etab8[26:29,],
                   c("Change Self-Reported Sleep", "", "", "", "", ""),
                   save_etab8[30:32,],
                   c("Change in Habit Strength", "", "", "", "", ""),
                   save_etab8[33:47,]
                   )

```




\

```{r, echo = FALSE}
# Save tables to excel for formatting:
# Remove -0.0 with homemade function at beginning of code:
save_etab2 <- change_negative_zero(save_etab2)
save_etab3 <- change_negative_zero(save_etab3)
save_etab4 <- change_negative_zero(save_etab4)
save_etab5 <- change_negative_zero(save_etab5)
save_etab8 <- change_negative_zero(save_etab8)


# add headers to table 1:
# Convert the table to a data frame if it's not one already
save_tab1 <- as.data.frame(save_tab1, stringsAsFactors = FALSE)
rownames(save_tab1) = NULL
  
# create workbook
wb = createWorkbook()
# add sheets
sheet1 = addWorksheet(wb, "Table 1")
sheet2 = addWorksheet(wb, "Table 2")
sheet3 = addWorksheet(wb, "eTable 2")
sheet4 = addWorksheet(wb, "Table 3")
sheet5 = addWorksheet(wb, "eTable 3")
sheet6 = addWorksheet(wb, "eTable 4")
sheet7 = addWorksheet(wb, "eTable 5")
sheet8 = addWorksheet(wb, "eTable 6a")
sheet9 = addWorksheet(wb, "eTable 6b")
sheet10 = addWorksheet(wb, "eTable 7")

# save tables to sheets
xl_write(save_tab1, wb, sheet1)
xl_write(save_tab2, wb, sheet2)
xl_write(save_etab2, wb, sheet3)
xl_write(save_tab3, wb, sheet4)
xl_write(save_etab3, wb, sheet5)
xl_write(save_etab4, wb, sheet6)
xl_write(save_etab5, wb, sheet7)
xl_write(save_etab6, wb, sheet8)
xl_write(save_etab7, wb, sheet9)
xl_write(save_etab8, wb, sheet10)


# save workbook with table to the xlsx file.
saveWorkbook(wb, paste0("../Output/Main_outcomes_rounded_tables_", Sys.Date(), ".xlsx"), overwrite = TRUE)
# save as 2 if want to not overwrite one that may have already been formatted
```




# References 

Allison, P. (2009). Missing data. In The SAGE Handbook of Quantitative Methods in Psychology (pp. 72-90). SAGE Publications Ltd, https://doi.org/10.4135/9780857020994

Austin, P. C., White, I. R., Lee, D. S., & van Buuren, S. (2021). Missing Data in Clinical Research: A Tutorial on Multiple Imputation. The Canadian journal of cardiology, 37(9), 1322–1331. https://doi.org/10.1016/j.cjca.2020.11.010

Blanca MJ, Alarcón R, Arnau J, Bono R, Bendayan R. Effect of variance ratio on ANOVA robustness: Might 1.5 be the limit? Behav Res Methods 2018;50(3):937-62. doi: 10.3758/s13428-017-0918-2.

Casella G, Berger R. Statistical Inference. Second ed. USA, 2021.

Glass G, Hopkins KD. Statistical methods in psychology and education. Third ed. Needham Heights, MA: Allyn & Bacon, 1996.

Glass, G.V., Peckham, P.D., & Sanders, J.R. (1972). Consequences of Failure to Meet Assumptions Underlying the Fixed Effects Analyses of Variance and Covariance. Review of Educational Research, 42, 237 - 288. https://doi.org/10.3102/00346543042003237 

Hardt, J., Herke, M. & Leonhart, R. Auxiliary variables in multiple imputation in regression with missing X: a warning against including too many in small sample research. BMC Med Res Methodol 12, 184 (2012). https://doi.org/10.1186/1471-2288-12-184

Lenth R (2023). emmeans: Estimated Marginal Means, aka Least-Squares Means. R package version 1.8.9, https://CRAN.R-project.org/package=emmeans

Madley-Dowd, P., Curnow, E., Hughes, R.A., Cornish, R., Tilling, K., Heron, J. “Analyses Using Multiple Imputation Need to Consider Missing Data in Auxiliary Variables.” MedRxiv (Cold Spring Harbor Laboratory), 11 Dec. 2023, https://doi.org/10.1101/2023.12.11.23299810.

Schulz KF, Altman DG, Moher D. CONSORT 2010 statement: updated guidelines for reporting parallel group randomized trials. Ann Intern Med 2010;152(11):726-32. doi: 10.7326/0003-4819-152-11-201006010-00232.

Stef van Buuren, Karin Groothuis-Oudshoorn (2011). mice: Multivariate Imputation by Chained Equations in R. Journal of Statistical Software, 45(3), 1-67. DOI 10.18637/jss.v045.i03. 

von Hippel, Paul T. "How Many Imputations Do You Need? A Two-stage Calculation Using a Quadratic Rule." Sociological Methods & Research. 2020;49(3):699-718. doi:10.1177/0049124117747303  

Wilcox, R. R., & Rousselet, G. A. (2023). An updated guide to robust statistical methods in neuroscience. Current Protocols, 3, e719. doi: 10.1002/cpz1.719 https://currentprotocols.onlinelibrary.wiley.com/doi/epdf/10.1002/cpz1.719

Wrzecionkowska, D. & Calleja, N. (2022). Impact of Weight on Quality-of-Life Questionnaire-Lite, Mexican Version. Reliability and Validity Evidence. Revista de Psicología, 31(1), 1-13.
http://dx.doi.org/10.5354/0719-0581.2022.64335



